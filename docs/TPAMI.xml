<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://jamesyu.me/feed/TPAMI.rss</id>
    <title>IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
    <updated>2023-06-09T16:14:35.888Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="http://jamesyu.me/feed/TPAMI.rss"/>
    <subtitle>IEEE Transactions on Pattern Analysis and Machine Intelligence</subtitle>
    <rights>Copyright reserved</rights>
    <entry>
        <title type="html"><![CDATA[C2F-TCN: A Framework for Semi- and Fully-Supervised Temporal Action Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10147035</id>
        <link href="https://ieeexplore.ieee.org/document/10147035"/>
        <updated>2023-06-09T01:11:37.370Z</updated>
        <summary type="html"><![CDATA[Temporal action segmentation tags action labels for every frame in an input untrimmed video containing multiple actions in a sequence. For the task of temporal action segmentation, we propose an encoder-decoder style architecture named C2F-TCN featuring a “coarse-to-fine” ensemble of decoder outputs. The C2F-TCN framework is enhanced with a novel model agnostic temporal feature augmentation strate...]]></summary>
        <author>
            <name>Dipika Singhania</name>
        </author>
        <author>
            <name>Rahul Rahaman</name>
        </author>
        <author>
            <name>Angela Yao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blind Image Deconvolution Using Variational Deep Image Prior]]></title>
        <id>https://ieeexplore.ieee.org/document/10146429</id>
        <link href="https://ieeexplore.ieee.org/document/10146429"/>
        <updated>2023-06-09T01:11:37.370Z</updated>
        <summary type="html"><![CDATA[Conventional deconvolution methods utilize hand-crafted image priors to constrain the optimization. While deep-learning-based methods have simplified the optimization by end-to-end training, they fail to generalize well to blurs unseen in the training dataset. Thus, training image-specific models is important for higher generalization. Deep image prior (DIP) provides an approach to optimize the we...]]></summary>
        <author>
            <name>Dong Huo</name>
        </author>
        <author>
            <name>Abbas Masoumzadeh</name>
        </author>
        <author>
            <name>Rafsanjany Kushol</name>
        </author>
        <author>
            <name>Yee-Hong Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering]]></title>
        <id>https://ieeexplore.ieee.org/document/10146482</id>
        <link href="https://ieeexplore.ieee.org/document/10146482"/>
        <updated>2023-06-09T01:11:37.370Z</updated>
        <summary type="html"><![CDATA[Existing visual question answering methods often suffer from cross-modal spurious correlations and oversimplified event-level reasoning processes that fail to capture event temporality, causality, and dynamics spanning over the video. In this work, to address the task of event-level visual question answering, we propose a framework for cross-modal causal relational reasoning. In particular, a set ...]]></summary>
        <author>
            <name>Yang Liu</name>
        </author>
        <author>
            <name>Guanbin Li</name>
        </author>
        <author>
            <name>Liang Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GP-UNIT: Generative Prior for Versatile Unsupervised Image-to-Image Translation]]></title>
        <id>https://ieeexplore.ieee.org/document/10146459</id>
        <link href="https://ieeexplore.ieee.org/document/10146459"/>
        <updated>2023-06-09T01:11:37.370Z</updated>
        <summary type="html"><![CDATA[Recent advances in deep learning have witnessed many successful unsupervised image-to-image translation models that learn correspondences between two visual domains without paired data. However, it is still a great challenge to build robust mappings between various domains especially for those with drastic visual discrepancies. In this paper, we introduce a novel versatile framework, Generative Pr...]]></summary>
        <author>
            <name>Shuai Yang</name>
        </author>
        <author>
            <name>Liming Jiang</name>
        </author>
        <author>
            <name>Ziwei Liu</name>
        </author>
        <author>
            <name>Chen Change Loy</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MO-MIX: Multi-Objective Multi-Agent Cooperative Decision-Making With Deep Reinforcement Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10145811</id>
        <link href="https://ieeexplore.ieee.org/document/10145811"/>
        <updated>2023-06-08T01:09:06.638Z</updated>
        <summary type="html"><![CDATA[Deep reinforcement learning (RL) has been applied extensively to solve complex decision-making problems. In many real-world scenarios, tasks often have several conflicting objectives and may require multiple agents to cooperate, which are the multi-objective multi-agent decision-making problems. However, only few works have been conducted on this intersection. Existing approaches are limited to se...]]></summary>
        <author>
            <name>Tianmeng Hu</name>
        </author>
        <author>
            <name>Biao Luo</name>
        </author>
        <author>
            <name>Chunhua Yang</name>
        </author>
        <author>
            <name>Tingwen Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Hidden Graphs from Samples]]></title>
        <id>https://ieeexplore.ieee.org/document/10145799</id>
        <link href="https://ieeexplore.ieee.org/document/10145799"/>
        <updated>2023-06-08T01:09:06.638Z</updated>
        <summary type="html"><![CDATA[Several real-world problems, like molecular biology and chemical reactions, have hidden graphs, and we need to learn the hidden graph using edge-detecting samples. In this problem, the learner receives examples explaining whether a set of vertices induces an edge of the hidden graph. This paper examines the learnability of this problem using the PAC and Agnostic PAC learning models. By computing t...]]></summary>
        <author>
            <name>Ahmad Abniki</name>
        </author>
        <author>
            <name>Hamid Beigy</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MURF: Mutually Reinforcing Multi-modal Image Registration and Fusion]]></title>
        <id>https://ieeexplore.ieee.org/document/10145843</id>
        <link href="https://ieeexplore.ieee.org/document/10145843"/>
        <updated>2023-06-08T01:09:06.638Z</updated>
        <summary type="html"><![CDATA[Existing image fusion methods are typically limited to aligned source images and have to “tolerate” parallaxes when images are unaligned. Simultaneously, the large variances between different modalities pose a significant challenge for multi-modal image registration. This study proposes a novel method called MURF, where for the first time, image registration and fusion are mutually reinforced rath...]]></summary>
        <author>
            <name>Han Xu</name>
        </author>
        <author>
            <name>Jiteng Yuan</name>
        </author>
        <author>
            <name>Jiayi Ma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MLink: Linking Black-Box Models from Multiple Domains for Collaborative Inference]]></title>
        <id>https://ieeexplore.ieee.org/document/10145800</id>
        <link href="https://ieeexplore.ieee.org/document/10145800"/>
        <updated>2023-06-08T01:09:06.638Z</updated>
        <summary type="html"><![CDATA[The cost efficiency of model inference is critical to real-world machine learning (ML) applications, especially for delay-sensitive tasks and resource-limited devices. A typical dilemma is: in order to provide complex intelligent services (e.g. smart city), we need inference results of multiple ML models, but the cost budget (e.g. GPU memory) is not enough to run all of them. In this work, we stud...]]></summary>
        <author>
            <name>Mu Yuan</name>
        </author>
        <author>
            <name>Lan Zhang</name>
        </author>
        <author>
            <name>Zimu Zheng</name>
        </author>
        <author>
            <name>Yi-Nan Zhang</name>
        </author>
        <author>
            <name>Xiang-Yang Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Temporal Perceiver: A General Architecture for Arbitrary Boundary Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10144649</id>
        <link href="https://ieeexplore.ieee.org/document/10144649"/>
        <updated>2023-06-07T01:11:34.944Z</updated>
        <summary type="html"><![CDATA[Generic Boundary Detection (GBD) aims at locating the general boundaries that divide videos into semantically coherent and taxonomy-free units, and could serve as an important pre-processing step for long-form video understanding. Previous works often separately handle these different types of generic boundaries with specific designs of deep networks from simple CNN to LSTM. Instead, in this paper...]]></summary>
        <author>
            <name>Jing Tan</name>
        </author>
        <author>
            <name>Yuhong Wang</name>
        </author>
        <author>
            <name>Gangshan Wu</name>
        </author>
        <author>
            <name>Limin Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UniFormer: Unifying Convolution and Self-Attention for Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10143709</id>
        <link href="https://ieeexplore.ieee.org/document/10143709"/>
        <updated>2023-06-06T01:10:27.893Z</updated>
        <summary type="html"><![CDATA[It is a challenging task to learn discriminative representation from images and videos, due to large local redundancy and complex global dependency in these visual data. Convolution neural networks (CNNs) and vision transformers (ViTs) have been two dominant frameworks in the past few years. Though CNNs can efficiently decrease local redundancy by convolution within a small neighborhood, the limit...]]></summary>
        <author>
            <name>Kunchang Li</name>
        </author>
        <author>
            <name>Yali Wang</name>
        </author>
        <author>
            <name>Junhao Zhang</name>
        </author>
        <author>
            <name>Peng Gao</name>
        </author>
        <author>
            <name>Guanglu Song</name>
        </author>
        <author>
            <name>Yu Liu</name>
        </author>
        <author>
            <name>Hongsheng Li</name>
        </author>
        <author>
            <name>Yu Qiao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Constrained Structure Learning for Scene Graph Generation]]></title>
        <id>https://ieeexplore.ieee.org/document/10143704</id>
        <link href="https://ieeexplore.ieee.org/document/10143704"/>
        <updated>2023-06-06T01:10:27.893Z</updated>
        <summary type="html"><![CDATA[As a structured prediction task, scene graph generation aims to build a visually-grounded scene graph to explicitly model objects and their relationships in an input image. Currently, the mean field variational Bayesian framework is the de facto methodology used by the existing methods, in which the unconstrained inference step is often implemented by a message passing neural network. However, suc...]]></summary>
        <author>
            <name>Daqi Liu</name>
        </author>
        <author>
            <name>Miroslaw Bober</name>
        </author>
        <author>
            <name>Josef Kittler</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LARNeXt: End-to-End Lie Algebra Residual Network for Face Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10143393</id>
        <link href="https://ieeexplore.ieee.org/document/10143393"/>
        <updated>2023-06-03T01:07:22.108Z</updated>
        <summary type="html"><![CDATA[Face recognition has always been courted in computer vision and is especially amenable to situations with significant variations between frontal and profile faces. Traditional techniques make great strides either by synthesizing frontal faces from sizable datasets or by empirical pose invariant learning. In this paper, we propose a completely integrated embedded end-to-end Lie algebra residual arc...]]></summary>
        <author>
            <name>Xiaolong Yang</name>
        </author>
        <author>
            <name>Xiaohong Jia</name>
        </author>
        <author>
            <name>Dihong Gong</name>
        </author>
        <author>
            <name>Dong-Ming Yan</name>
        </author>
        <author>
            <name>Zhifeng Li</name>
        </author>
        <author>
            <name>Wei Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Human Interaction Understanding with Consistency-Aware Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10138446</id>
        <link href="https://ieeexplore.ieee.org/document/10138446"/>
        <updated>2023-05-30T01:02:29.518Z</updated>
        <summary type="html"><![CDATA[Compared with the progress made on human activity classification, much less success has been achieved on human interaction understanding (HIU). Apart from the latter task is much more challenging, the main causation is that recent approaches learn human interactive relations via shallow graphical representations, which are inadequate to model complicated human interactive-relations. This paper pro...]]></summary>
        <author>
            <name>Jiajun Meng</name>
        </author>
        <author>
            <name>Zhenhua Wang</name>
        </author>
        <author>
            <name>Kaining Ying</name>
        </author>
        <author>
            <name>Jianhua Zhang</name>
        </author>
        <author>
            <name>Dongyan Guo</name>
        </author>
        <author>
            <name>Zhen Zhang</name>
        </author>
        <author>
            <name>Javen Qinfeng Shi</name>
        </author>
        <author>
            <name>Shengyong Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Zero-Shot Hyperspectral Sharpening]]></title>
        <id>https://ieeexplore.ieee.org/document/10137388</id>
        <link href="https://ieeexplore.ieee.org/document/10137388"/>
        <updated>2023-05-27T01:01:52.973Z</updated>
        <summary type="html"><![CDATA[Fusing hyperspectral images (HSIs) with multispectral images (MSIs) of higher spatial resolution has become an effective way to sharpen HSIs. Recently, deep convolutional neural networks (CNNs) have achieved promising fusion performance. However, these methods often suffer from the lack of training data and limited generalization ability. To address the above problems, we present a zero-shot learn...]]></summary>
        <author>
            <name>Renwei Dian</name>
        </author>
        <author>
            <name>Anjing Guo</name>
        </author>
        <author>
            <name>Shutao Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ZITS++: Image Inpainting by Improving the Incremental Transformer on Structural Priors]]></title>
        <id>https://ieeexplore.ieee.org/document/10136788</id>
        <link href="https://ieeexplore.ieee.org/document/10136788"/>
        <updated>2023-05-27T01:01:52.973Z</updated>
        <summary type="html"><![CDATA[Image inpainting involves filling missing areas of a corrupted image. Despite impressive results have been achieved recently, restoring images with both vivid textures and reasonable structures remains a significant challenge. Previous methods have primarily addressed regular textures while disregarding holistic structures due to the limited receptive fields of Convolutional Neural Networks (CNNs)...]]></summary>
        <author>
            <name>Chenjie Cao</name>
        </author>
        <author>
            <name>Qiaole Dong</name>
        </author>
        <author>
            <name>Yanwei Fu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Discourse-Aware Graph Networks for Textual Logical Reasoning]]></title>
        <id>https://ieeexplore.ieee.org/document/10136812</id>
        <link href="https://ieeexplore.ieee.org/document/10136812"/>
        <updated>2023-05-27T01:01:52.973Z</updated>
        <summary type="html"><![CDATA[Textual logical reasoning, especially question-answering (QA) tasks with logical reasoning, requires awareness of particular logical structures. The passage-level logical relations represent entailment or contradiction between propositional units (e.g., a concluding sentence). However, such structures are unexplored as current QA systems focus on entity-based relations. In this work, we propose lo...]]></summary>
        <author>
            <name>Yinya Huang</name>
        </author>
        <author>
            <name>Lemao Liu</name>
        </author>
        <author>
            <name>Kun Xu</name>
        </author>
        <author>
            <name>Meng Fang</name>
        </author>
        <author>
            <name>Liang Lin</name>
        </author>
        <author>
            <name>Xiaodan Liang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentiable Histogram Loss Functions for Intensity-based Image-to-Image Translation]]></title>
        <id>https://ieeexplore.ieee.org/document/10133915</id>
        <link href="https://ieeexplore.ieee.org/document/10133915"/>
        <updated>2023-05-25T01:00:46.817Z</updated>
        <summary type="html"><![CDATA[We introduce the HueNet - a novel deep learning framework for a differentiable construction of intensity (1D) and joint (2D) histograms and present its applicability to paired and unpaired image-to-image translation problems. The key idea is an innovative technique for augmenting a generative neural network by histogram layers appended to the image generator. These histogram layers allow us to def...]]></summary>
        <author>
            <name>Mor Avi-Aharon</name>
        </author>
        <author>
            <name>Assaf Arbelle</name>
        </author>
        <author>
            <name>Tammy Riklin Raviv</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Novel Normalized-Cut Solver with Nearest Neighbor Hierarchical Initialization]]></title>
        <id>https://ieeexplore.ieee.org/document/10132543</id>
        <link href="https://ieeexplore.ieee.org/document/10132543"/>
        <updated>2023-05-25T01:00:46.817Z</updated>
        <summary type="html"><![CDATA[Normalized-Cut (N-Cut) is a famous model of spectral clustering. The traditional N-Cut solvers are two-stage: 1) calculating the continuous spectral embedding of normalized Laplacian matrix; 2) discretization via $K$-means or spectral rotation. However, this paradigm brings two vital problems: 1) two-stage methods solve a relaxed version of the original problem, so they cannot obtain good solution...]]></summary>
        <author>
            <name>Feiping Nie</name>
        </author>
        <author>
            <name>Jitao Lu</name>
        </author>
        <author>
            <name>Danyang Wu</name>
        </author>
        <author>
            <name>Rong Wang</name>
        </author>
        <author>
            <name>Xuelong Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ranking-Based Color Constancy With Limited Training Samples]]></title>
        <id>https://ieeexplore.ieee.org/document/10130607</id>
        <link href="https://ieeexplore.ieee.org/document/10130607"/>
        <updated>2023-05-23T01:00:18.753Z</updated>
        <summary type="html"><![CDATA[Computational color constancy is an important component of Image Signal Processors (ISP) for white balancing in many imaging devices. Recently, deep convolutional neural networks (CNN) have been introduced for color constancy. They achieve prominent performance improvements comparing with those statistics or shallow learning-based methods. However, the need for a large number of training samples, ...]]></summary>
        <author>
            <name>Bing Li</name>
        </author>
        <author>
            <name>Haina Qin</name>
        </author>
        <author>
            <name>Weihua Xiong</name>
        </author>
        <author>
            <name>Yangxi Li</name>
        </author>
        <author>
            <name>Songhe Feng</name>
        </author>
        <author>
            <name>Weiming Hu</name>
        </author>
        <author>
            <name>Stephen Maybank</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sensing Diversity and Sparsity Models for Event Generation and Video Reconstruction from Events]]></title>
        <id>https://ieeexplore.ieee.org/document/10130595</id>
        <link href="https://ieeexplore.ieee.org/document/10130595"/>
        <updated>2023-05-23T01:00:18.753Z</updated>
        <summary type="html"><![CDATA[Events-to-video (E2V) reconstruction and video-to-events (V2E) simulation are two fundamental research topics in event-based vision. Current deep neural networks for E2V reconstruction are usually complex and difficult to interpret. Moreover, existing event simulators are designed to generate realistic events, but research on how to improve the event generation process has been so far limited. In ...]]></summary>
        <author>
            <name>Siying Liu</name>
        </author>
        <author>
            <name>Pier Luigi Dragotti</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prototype Completion for Few-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10130710</id>
        <link href="https://ieeexplore.ieee.org/document/10130710"/>
        <updated>2023-05-23T01:00:18.753Z</updated>
        <summary type="html"><![CDATA[Few-shot learning (FSL) aims to recognize novel classes with few examples. Pre-training based methods effectively tackle the problem by pre-training a feature extractor and then fine-tuning it through the nearest centroid based meta-learning. However, results show that the fine-tuning step makes marginal improvements. In this paper, 1) we figure out the reason, i.e., in the pre-trained feature spa...]]></summary>
        <author>
            <name>Baoquan Zhang</name>
        </author>
        <author>
            <name>Xutao Li</name>
        </author>
        <author>
            <name>Yunming Ye</name>
        </author>
        <author>
            <name>Shanshan Feng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalized Parametric Contrastive Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10130611</id>
        <link href="https://ieeexplore.ieee.org/document/10130611"/>
        <updated>2023-05-23T01:00:18.753Z</updated>
        <summary type="html"><![CDATA[In this paper, we propose the Generalized Parametric Contrastive Learning (GPaCo/PaCo) which works well on both imbalanced and balanced data. Based on theoretical analysis, we observe supervised contrastive loss tends to bias on high-frequency classes and thus increases the difficulty of imbalanced learning. We introduce a set of parametric class-wise learnable centers to rebalance from an optimiz...]]></summary>
        <author>
            <name>Jiequan Cui</name>
        </author>
        <author>
            <name>Zhisheng Zhong</name>
        </author>
        <author>
            <name>Zhuotao Tian</name>
        </author>
        <author>
            <name>Shu Liu</name>
        </author>
        <author>
            <name>Bei Yu</name>
        </author>
        <author>
            <name>Jiaya Jia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Instance Differentiation Learning for Active Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10129096</id>
        <link href="https://ieeexplore.ieee.org/document/10129096"/>
        <updated>2023-05-19T01:00:19.511Z</updated>
        <summary type="html"><![CDATA[Despite the substantial progress of active learning for image recognition, there lacks a systematic investigation of instance-level active learning for object detection. In this paper, we propose to unify instance uncertainty calculation with image uncertainty estimation for informative image selection, creating a multiple instance differentiation learning (MIDL) method for instance-level active l...]]></summary>
        <author>
            <name>Fang Wan</name>
        </author>
        <author>
            <name>Qixiang Ye</name>
        </author>
        <author>
            <name>Tianning Yuan</name>
        </author>
        <author>
            <name>Songcen Xu</name>
        </author>
        <author>
            <name>Jianzhuang Liu</name>
        </author>
        <author>
            <name>Xiangyang Ji</name>
        </author>
        <author>
            <name>Qingming Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey on Non-Autoregressive Generation for Neural Machine Translation and Beyond]]></title>
        <id>https://ieeexplore.ieee.org/document/10129160</id>
        <link href="https://ieeexplore.ieee.org/document/10129160"/>
        <updated>2023-05-19T01:00:19.511Z</updated>
        <summary type="html"><![CDATA[Non-autoregressive (NAR) generation, which is first proposed in neural machine translation (NMT) to speed up inference, has attracted much attention in both machine learning and natural language processing communities. While NAR generation can significantly accelerate inference speed for machine translation, the speedup comes at the cost of sacrificed translation accuracy compared to its counterpa...]]></summary>
        <author>
            <name>Yisheng Xiao</name>
        </author>
        <author>
            <name>Lijun Wu</name>
        </author>
        <author>
            <name>Junliang Guo</name>
        </author>
        <author>
            <name>Juntao Li</name>
        </author>
        <author>
            <name>Min Zhang</name>
        </author>
        <author>
            <name>Tao Qin</name>
        </author>
        <author>
            <name>Tie-Yan Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large-scale Clustering with Structured Optimal Bipartite Graph]]></title>
        <id>https://ieeexplore.ieee.org/document/10129060</id>
        <link href="https://ieeexplore.ieee.org/document/10129060"/>
        <updated>2023-05-19T01:00:19.511Z</updated>
        <summary type="html"><![CDATA[The widespread arising of data size gives rise to the necessity of undertaking large-scale data clustering tasks. To do so, the bipartite graph theory is frequently applied to design a scalable algorithm, which depicts the relations between samples and a few anchors, instead of binding pairwise samples. However, the bipartite graphs and existing spectral embedding methods ignore the explicit clust...]]></summary>
        <author>
            <name>Han Zhang</name>
        </author>
        <author>
            <name>Feiping Nie</name>
        </author>
        <author>
            <name>Xuelong Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Perceptual Measure for Deep Single Image Camera and Lens Calibration]]></title>
        <id>https://ieeexplore.ieee.org/document/10128718</id>
        <link href="https://ieeexplore.ieee.org/document/10128718"/>
        <updated>2023-05-18T00:59:17.326Z</updated>
        <summary type="html"><![CDATA[Image editing and compositing have become ubiquitous in entertainment, from digital art to AR and VR experiences. To produce beautiful composites, the camera needs to be geometrically calibrated, which can be tedious and requires a physical calibration target. In place of the traditional multi-image calibration process, we propose to infer the camera calibration parameters such as pitch, roll, fie...]]></summary>
        <author>
            <name>Yannick Hold-Geoffroy</name>
        </author>
        <author>
            <name>Dominique Piché-Meunier</name>
        </author>
        <author>
            <name>Kalyan Sunkavalli</name>
        </author>
        <author>
            <name>Jean-Charles Bazin</name>
        </author>
        <author>
            <name>François Rameau</name>
        </author>
        <author>
            <name>Jean-François Lalonde</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cross Domain Lifelong Learning Based on Task Similarity]]></title>
        <id>https://ieeexplore.ieee.org/document/10128736</id>
        <link href="https://ieeexplore.ieee.org/document/10128736"/>
        <updated>2023-05-18T00:59:17.326Z</updated>
        <summary type="html"><![CDATA[Humans gradually learn a sequence of cross-domain tasks and seldom experience catastrophic forgetting. In contrast, deep neural networks achieve good performance only in specific tasks within a single domain. To equip the network with lifelong learning capabilities, we propose a Cross-Domain Lifelong Learning (CDLL) framework that fully explores task similarities. Specifically, we employ a Dual Si...]]></summary>
        <author>
            <name>Shuojin Yang</name>
        </author>
        <author>
            <name>Zhanchuan Cai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge-based Embodied Question Answering]]></title>
        <id>https://ieeexplore.ieee.org/document/10128752</id>
        <link href="https://ieeexplore.ieee.org/document/10128752"/>
        <updated>2023-05-18T00:59:17.326Z</updated>
        <summary type="html"><![CDATA[In this paper, we propose a novel Knowledge-based Embodied Question Answering (K-EQA) task, in which the agent intelligently explores the environment to answer various questions with the knowledge. Different from explicitly specifying the target object in the question as existing EQA work, the agent can resort to external knowledge to understand more complicated question such as “Please tell me wh...]]></summary>
        <author>
            <name>Sinan Tan</name>
        </author>
        <author>
            <name>Mengmeng Ge</name>
        </author>
        <author>
            <name>Di Guo</name>
        </author>
        <author>
            <name>Huaping Liu</name>
        </author>
        <author>
            <name>Fuchun Sun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Part Mining for Robust Visual Tracking]]></title>
        <id>https://ieeexplore.ieee.org/document/10126096</id>
        <link href="https://ieeexplore.ieee.org/document/10126096"/>
        <updated>2023-05-17T01:02:18.256Z</updated>
        <summary type="html"><![CDATA[Visual tracking aims to estimate object state in a video sequence, which is challenging when facing drastic appearance changes. Most existing trackers conduct tracking with divided parts to handle appearance variations. However, these trackers commonly divide target objects into regular patches by a hand-designed splitting way, which is too coarse to align object parts well. Besides, a fixed part ...]]></summary>
        <author>
            <name>Yinchao Ma</name>
        </author>
        <author>
            <name>Jianfeng He</name>
        </author>
        <author>
            <name>Dawei Yang</name>
        </author>
        <author>
            <name>Tianzhu Zhang</name>
        </author>
        <author>
            <name>Feng Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GAIA-Universe: Everything is Super-Netify]]></title>
        <id>https://ieeexplore.ieee.org/document/10125046</id>
        <link href="https://ieeexplore.ieee.org/document/10125046"/>
        <updated>2023-05-17T01:02:18.256Z</updated>
        <summary type="html"><![CDATA[Pre-training on large-scale datasets has played an increasingly significant role in computer vision and natural language processing recently. However, as there exist numerous application scenarios that have distinctive demands such as certain latency constraints and specialized data distributions, it is prohibitively expensive to take advantage of large-scale pre-training for per-task requirements...]]></summary>
        <author>
            <name>Junran Peng</name>
        </author>
        <author>
            <name>Qing Chang</name>
        </author>
        <author>
            <name>Haoran Yin</name>
        </author>
        <author>
            <name>Xingyuan Bu</name>
        </author>
        <author>
            <name>Jiajun Sun</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Xiaopeng Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hong Kong World: Leveraging Structural Regularity for Line-based SLAM]]></title>
        <id>https://ieeexplore.ieee.org/document/10124374</id>
        <link href="https://ieeexplore.ieee.org/document/10124374"/>
        <updated>2023-05-16T01:00:40.659Z</updated>
        <summary type="html"><![CDATA[Manhattan and Atlanta worlds hold for the structured scenes with only vertical and horizontal dominant directions (DDs). To describe the scenes with additional sloping DDs, a mixture of independent Manhattan worlds seems plausible, but may lead to unaligned and unrelated DDs. By contrast, we propose a novel structural model called Hong Kong world. It is more general than Manhattan and Atlanta worl...]]></summary>
        <author>
            <name>Haoang Li</name>
        </author>
        <author>
            <name>Ji Zhao</name>
        </author>
        <author>
            <name>Jean-Charles Bazin</name>
        </author>
        <author>
            <name>Pyojin Kim</name>
        </author>
        <author>
            <name>Kyungdon Joo</name>
        </author>
        <author>
            <name>Zhenjun Zhao</name>
        </author>
        <author>
            <name>Yun-Hui Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual Compensation Residual Networks for Class Imbalanced Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10124024</id>
        <link href="https://ieeexplore.ieee.org/document/10124024"/>
        <updated>2023-05-13T00:57:30.061Z</updated>
        <summary type="html"><![CDATA[Learning generalizable representation and classifier for class-imbalanced data is challenging for data-driven deep models. Most studies attempt to re-balance the data distribution, which is prone to overfitting on tail classes and underfitting on head classes. In this work, we propose Dual Compensation Residual Networks to better fit both tail and head classes. Firstly, we propose dual Feature Com...]]></summary>
        <author>
            <name>Ruibing Hou</name>
        </author>
        <author>
            <name>Hong Chang</name>
        </author>
        <author>
            <name>Bingpeng Ma</name>
        </author>
        <author>
            <name>Shiguang Shan</name>
        </author>
        <author>
            <name>Xilin Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning an Invariant and Equivariant Network for Weakly Supervised Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10123080</id>
        <link href="https://ieeexplore.ieee.org/document/10123080"/>
        <updated>2023-05-12T00:59:08.107Z</updated>
        <summary type="html"><![CDATA[Weakly Supervised Object Detection (WSOD) is of increasing importance in the community of computer vision as its extensive applications and low manual cost. Most of the advanced WSOD approaches build upon an indefinite and quality-agnostic framework, leading to unstable and incomplete object detectors. This paper attributes these issues to the process of inconsistent learning for object variations...]]></summary>
        <author>
            <name>Xiaoxu Feng</name>
        </author>
        <author>
            <name>Xiwen Yao</name>
        </author>
        <author>
            <name>Hui Shen</name>
        </author>
        <author>
            <name>Gong Cheng</name>
        </author>
        <author>
            <name>Bin Xiao</name>
        </author>
        <author>
            <name>Junwei Han</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Robustness of Average Losses for Partial-Label Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10122995</id>
        <link href="https://ieeexplore.ieee.org/document/10122995"/>
        <updated>2023-05-12T00:59:08.107Z</updated>
        <summary type="html"><![CDATA[Partial-label learning (PLL) utilizes instances with PLs, where a PL includes several candidate labels but only one is the true label (TL). In PLL, identification-based strategy (IBS) purifies each PL on the fly to select the (most likely) TL for training; average-based strategy (ABS) treats all candidate labels equally for training and let trained models be able to predict TL. Although PLL resear...]]></summary>
        <author>
            <name>Jiaqi Lv</name>
        </author>
        <author>
            <name>Biao Liu</name>
        </author>
        <author>
            <name>Lei Feng</name>
        </author>
        <author>
            <name>Ning Xu</name>
        </author>
        <author>
            <name>Miao Xu</name>
        </author>
        <author>
            <name>Bo An</name>
        </author>
        <author>
            <name>Gang Niu</name>
        </author>
        <author>
            <name>Xin Geng</name>
        </author>
        <author>
            <name>Masashi Sugiyama</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Partial Multi-View Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10123043</id>
        <link href="https://ieeexplore.ieee.org/document/10123043"/>
        <updated>2023-05-12T00:59:08.107Z</updated>
        <summary type="html"><![CDATA[It is often the case that data are with multiple views in real-world applications. Fully exploring the information of each view is significant for making data more representative. However, due to various limitations and failures in data collection and pre-processing, it is inevitable for real data to suffer from view missing and data scarcity. The coexistence of these two issues makes it more chal...]]></summary>
        <author>
            <name>Yuan Zhou</name>
        </author>
        <author>
            <name>Yanrong Guo</name>
        </author>
        <author>
            <name>Shijie Hao</name>
        </author>
        <author>
            <name>Richang Hong</name>
        </author>
        <author>
            <name>Jiebo Luo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Single-path Bit Sharing for Automatic Loss-aware Model Compression]]></title>
        <id>https://ieeexplore.ieee.org/document/10122994</id>
        <link href="https://ieeexplore.ieee.org/document/10122994"/>
        <updated>2023-05-12T00:59:08.107Z</updated>
        <summary type="html"><![CDATA[Network pruning and quantization are proven to be effective ways for deep model compression. To obtain a highly compact model, most methods first perform network pruning and then conduct quantization based on the pruned model. However, this strategy may ignore that the pruning and quantization would affect each other and thus performing them separately may lead to sub-optimal performance. To addre...]]></summary>
        <author>
            <name>Jing Liu</name>
        </author>
        <author>
            <name>Bohan Zhuang</name>
        </author>
        <author>
            <name>Peng Chen</name>
        </author>
        <author>
            <name>Chunhua Shen</name>
        </author>
        <author>
            <name>Jianfei Cai</name>
        </author>
        <author>
            <name>Mingkui Tan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multimodal Learning With Transformers: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10123038</id>
        <link href="https://ieeexplore.ieee.org/document/10123038"/>
        <updated>2023-05-12T00:59:08.107Z</updated>
        <summary type="html"><![CDATA[Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and Big Data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey in...]]></summary>
        <author>
            <name>Peng Xu</name>
        </author>
        <author>
            <name>Xiatian Zhu</name>
        </author>
        <author>
            <name>David A. Clifton</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fixed Pattern Noise Removal Based on a Semi-Calibration Method]]></title>
        <id>https://ieeexplore.ieee.org/document/10122709</id>
        <link href="https://ieeexplore.ieee.org/document/10122709"/>
        <updated>2023-05-11T00:59:42.855Z</updated>
        <summary type="html"><![CDATA[Due to the manufacturing imperfections, nonuniformities are ubiquitous in digital sensors, causing the notorious Fixed Pattern Noise (FPN). The ability of modern digital cameras to take images under low-light environments is severely limited by the FPN. This paper proposes a novel semi-calibration-based method for the FPN removal that utilizes a pre-calibrated Noise Pattern. The key observation of...]]></summary>
        <author>
            <name>Lingfei Song</name>
        </author>
        <author>
            <name>Hua Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Influence-Driven Data Poisoning for Robust Recommender Systems]]></title>
        <id>https://ieeexplore.ieee.org/document/10122715</id>
        <link href="https://ieeexplore.ieee.org/document/10122715"/>
        <updated>2023-05-11T00:59:42.855Z</updated>
        <summary type="html"><![CDATA[Recent studies have shown that recommender systems are vulnerable, and it is easy for attackers to inject well-designed malicious profiles into the system, resulting in biased recommendations. We cannot deprive these data&#39;s injection right and deny their existence&#39;s rationality, making it imperative to study recommendation robustness. Despite impressive emerging work, threat assessment of the bi-l...]]></summary>
        <author>
            <name>Chenwang Wu</name>
        </author>
        <author>
            <name>Defu Lian</name>
        </author>
        <author>
            <name>Yong Ge</name>
        </author>
        <author>
            <name>Zhihao Zhu</name>
        </author>
        <author>
            <name>Enhong Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified Multimodal De- and Re-Coupling Framework for RGB-D Motion Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10122710</id>
        <link href="https://ieeexplore.ieee.org/document/10122710"/>
        <updated>2023-05-11T00:59:42.855Z</updated>
        <summary type="html"><![CDATA[Motion recognition is a promising direction in computer vision, but the training of video classification models is much harder than images due to insufficient data and considerable parameters. To get around this, some works strive to explore multimodal cues from RGB-D data. Although improving motion recognition to some extent, these methods still face sub-optimal situations in the following aspect...]]></summary>
        <author>
            <name>Benjia Zhou</name>
        </author>
        <author>
            <name>Pichao Wang</name>
        </author>
        <author>
            <name>Jun Wan</name>
        </author>
        <author>
            <name>Yanyan Liang</name>
        </author>
        <author>
            <name>Fan Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Trajectory Forecasting from Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10122126</id>
        <link href="https://ieeexplore.ieee.org/document/10122126"/>
        <updated>2023-05-10T00:58:40.464Z</updated>
        <summary type="html"><![CDATA[Trajectory forecasting for traffic participants (e.g., vehicles) is critical for autonomous platforms to make safe plans. Currently, most trajectory forecasting methods assume that object trajectories have been extracted and directly develop trajectory predictors based on the ground truth trajectories. However, this assumption does not hold in practical situations. Trajectories obtained from objec...]]></summary>
        <author>
            <name>Pu Zhang</name>
        </author>
        <author>
            <name>Lei Bai</name>
        </author>
        <author>
            <name>Yuning Wang</name>
        </author>
        <author>
            <name>Jianwu Fang</name>
        </author>
        <author>
            <name>Jianru Xue</name>
        </author>
        <author>
            <name>Nanning Zheng</name>
        </author>
        <author>
            <name>Wanli Ouyang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Making a Bird AI Expert Work for You and Me]]></title>
        <id>https://ieeexplore.ieee.org/document/10122150</id>
        <link href="https://ieeexplore.ieee.org/document/10122150"/>
        <updated>2023-05-10T00:58:40.464Z</updated>
        <summary type="html"><![CDATA[As powerful as fine-grained visual classification (FGVC) is, responding your query with a bird name of “Whip-poor-will” or “Mallard” probably does not make much sense. This however commonly accepted in the literature, underlines a fundamental question interfacing AI and human – what constitutes transferable knowledge for human to learn from AI? This paper sets out to answer this very question usin...]]></summary>
        <author>
            <name>Dongliang Chang</name>
        </author>
        <author>
            <name>Kaiyue Pang</name>
        </author>
        <author>
            <name>Ruoyi Du</name>
        </author>
        <author>
            <name>Yujun Tong</name>
        </author>
        <author>
            <name>Yi-Zhe Song</name>
        </author>
        <author>
            <name>Zhanyu Ma</name>
        </author>
        <author>
            <name>Jun Guo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Inherit With Distillation and Evolve With Contrast: Exploring Class Incremental Semantic Segmentation Without Exemplar Memory]]></title>
        <id>https://ieeexplore.ieee.org/document/10120962</id>
        <link href="https://ieeexplore.ieee.org/document/10120962"/>
        <updated>2023-05-09T01:00:45.929Z</updated>
        <summary type="html"><![CDATA[As a front-burner problem in incremental learning, class incremental semantic segmentation (CISS) is plagued by catastrophic forgetting and semantic drift. Although recent methods have utilized knowledge distillation to transfer knowledge from the old model, they are still unable to avoid pixel confusion, which results in severe misclassification after incremental steps due to the lack of annotati...]]></summary>
        <author>
            <name>Danpei Zhao</name>
        </author>
        <author>
            <name>Bo Yuan</name>
        </author>
        <author>
            <name>Zhenwei Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Deviation-Robust Agent Navigation Via Perturbation-Aware Contrastive Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10120966</id>
        <link href="https://ieeexplore.ieee.org/document/10120966"/>
        <updated>2023-05-09T01:00:45.929Z</updated>
        <summary type="html"><![CDATA[Vision-and-language navigation (VLN) asks an agent to follow a given language instruction to navigate through a real 3D environment. Despite significant advances, conventional VLN agents are trained typically under disturbance-free environments and may easily fail in real-world navigation scenarios, since they are unaware of how to deal with various possible disturbances, such as sudden obstacles ...]]></summary>
        <author>
            <name>Bingqian Lin</name>
        </author>
        <author>
            <name>Yanxin Long</name>
        </author>
        <author>
            <name>Yi Zhu</name>
        </author>
        <author>
            <name>Fengda Zhu</name>
        </author>
        <author>
            <name>Xiaodan Liang</name>
        </author>
        <author>
            <name>Qixiang Ye</name>
        </author>
        <author>
            <name>Liang Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Saliency as Pseudo-Pixel Supervision for Weakly and Semi-Supervised Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10120949</id>
        <link href="https://ieeexplore.ieee.org/document/10120949"/>
        <updated>2023-05-09T01:00:45.929Z</updated>
        <summary type="html"><![CDATA[Existing studies on semantic segmentation using image-level weak supervision have several limitations, including sparse object coverage, inaccurate object boundaries, and co-occurring pixels from non-target objects. To overcome these challenges, we propose a novel framework, an improved version of Explicit Pseudo-pixel Supervision (EPS++), which learns from pixel-level feedback by combining two ty...]]></summary>
        <author>
            <name>Minhyun Lee</name>
        </author>
        <author>
            <name>Seungho Lee</name>
        </author>
        <author>
            <name>Jongwuk Lee</name>
        </author>
        <author>
            <name>Hyunjung Shim</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Cross-Graph Reasoning and Adaptive Structured Semantics Learning for Compositional Temporal Grounding]]></title>
        <id>https://ieeexplore.ieee.org/document/10121664</id>
        <link href="https://ieeexplore.ieee.org/document/10121664"/>
        <updated>2023-05-09T01:00:45.929Z</updated>
        <summary type="html"><![CDATA[Temporal grounding is the task of locating a specific segment from an untrimmed video according to a query sentence. This task has achieved significant momentum in the computer vision community as it enables activity grounding beyond pre-defined activity classes by utilizing the semantic diversity of natural language descriptions. The semantic diversity is rooted in the principle of compositionali...]]></summary>
        <author>
            <name>Juncheng Li</name>
        </author>
        <author>
            <name>Siliang Tang</name>
        </author>
        <author>
            <name>Linchao Zhu</name>
        </author>
        <author>
            <name>Wenqiao Zhang</name>
        </author>
        <author>
            <name>Yi Yang</name>
        </author>
        <author>
            <name>Tat-Seng Chua</name>
        </author>
        <author>
            <name>Fei Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Infer Unseen Single-/Multi-Attribute-Object Compositions With Graph Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10120982</id>
        <link href="https://ieeexplore.ieee.org/document/10120982"/>
        <updated>2023-05-09T01:00:45.929Z</updated>
        <summary type="html"><![CDATA[Inferring the unseen attribute-object composition is critical to make machines learn to decompose and compose complex concepts like people. Most existing methods are limited to the composition recognition of single-attribute-object, and can hardly learn relations between the attributes and objects. In this paper, we propose an attribute-object semantic association graph model to learn the complex ...]]></summary>
        <author>
            <name>Hui Chen</name>
        </author>
        <author>
            <name>Jingjing Jiang</name>
        </author>
        <author>
            <name>Nanning Zheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformal Prediction for Time Series]]></title>
        <id>https://ieeexplore.ieee.org/document/10121511</id>
        <link href="https://ieeexplore.ieee.org/document/10121511"/>
        <updated>2023-05-09T01:00:45.929Z</updated>
        <summary type="html"><![CDATA[We present a general framework for constructing distribution-free prediction intervals for time series. We establish explicit bounds on the conditional and marginal coverage gaps of estimated prediction intervals, which asymptotically converge to zero under additional assumptions. We also provide similar bounds on the size of set differences between oracle and estimated prediction intervals. To im...]]></summary>
        <author>
            <name>Chen Xu</name>
        </author>
        <author>
            <name>Yao Xie</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Earning Extra Performance from Restrictive Feedbacks]]></title>
        <id>https://ieeexplore.ieee.org/document/10119201</id>
        <link href="https://ieeexplore.ieee.org/document/10119201"/>
        <updated>2023-05-06T00:55:24.600Z</updated>
        <summary type="html"><![CDATA[Many machine learning applications encounter situations where model providers are required to further refine the previously trained model so as to gratify the specific need of local users. This problem is reduced to the standard model tuning paradigm if the target data is permissibly fed to the model. However, it is rather difficult in a wide range of practical cases where target data is not share...]]></summary>
        <author>
            <name>Jing Li</name>
        </author>
        <author>
            <name>Yuangang Pan</name>
        </author>
        <author>
            <name>Yueming Lyu</name>
        </author>
        <author>
            <name>Yinghua Yao</name>
        </author>
        <author>
            <name>Yulei Sui</name>
        </author>
        <author>
            <name>Ivor W. Tsang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learnable Distribution Calibration for Few-Shot Class-Incremental Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10119176</id>
        <link href="https://ieeexplore.ieee.org/document/10119176"/>
        <updated>2023-05-06T00:55:24.600Z</updated>
        <summary type="html"><![CDATA[Few-shot class-incremental learning (FSCIL) faces the challenges of memorizing old class distributions and estimating new class distributions given few training samples. In this study, we propose a learnable distribution calibration (LDC) approach, to systematically solve these two challenges using a unified framework. LDC is built upon a parameterized calibration unit (PCU), which initializes bia...]]></summary>
        <author>
            <name>Binghao Liu</name>
        </author>
        <author>
            <name>Boyu Yang</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Ren Wang</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
        <author>
            <name>Qixiang Ye</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10119209</id>
        <link href="https://ieeexplore.ieee.org/document/10119209"/>
        <updated>2023-05-06T00:55:24.600Z</updated>
        <summary type="html"><![CDATA[Confluence is a novel non-Intersection over Union (IoU) alternative to Non-Maxima Suppression (NMS) in bounding box post-processing in object detection. It overcomes the inherent limitations of IoU-based NMS variants to provide a more stable, consistent predictor of bounding box clustering by using a normalized Manhattan Distance inspired proximity metric to represent bounding box clustering. Unli...]]></summary>
        <author>
            <name>Andrew J. Shepley</name>
        </author>
        <author>
            <name>Greg Falzon</name>
        </author>
        <author>
            <name>Paul Kwan</name>
        </author>
        <author>
            <name>Ljiljana Brankovic</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-Supervised Learning from Untrimmed Videos via Hierarchical Consistency]]></title>
        <id>https://ieeexplore.ieee.org/document/10119224</id>
        <link href="https://ieeexplore.ieee.org/document/10119224"/>
        <updated>2023-05-06T00:55:24.600Z</updated>
        <summary type="html"><![CDATA[Natural untrimmed videos provide rich visual content for self-supervised learning. Yet most previous efforts to learn spatiotemporal representations rely on manually trimmed videos, such as Kinetics dataset [1], resulting in limited diversity in visual patterns and limited performance gains. In this work, we aim to improve video representations by leveraging the rich information in natural untrimm...]]></summary>
        <author>
            <name>Zhiwu Qing</name>
        </author>
        <author>
            <name>Shiwei Zhang</name>
        </author>
        <author>
            <name>Ziyuan Huang</name>
        </author>
        <author>
            <name>Yi Xu</name>
        </author>
        <author>
            <name>Xiang Wang</name>
        </author>
        <author>
            <name>Changxin Gao</name>
        </author>
        <author>
            <name>Rong Jin</name>
        </author>
        <author>
            <name>Nong Sang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Editorial: Special Section on Egocentric Perception]]></title>
        <id>https://ieeexplore.ieee.org/document/10120668</id>
        <link href="https://ieeexplore.ieee.org/document/10120668"/>
        <updated>2023-05-06T00:55:24.600Z</updated>
        <author>
            <name>Antonino Furnari</name>
        </author>
        <author>
            <name>David Crandall</name>
        </author>
        <author>
            <name>Dima Damen</name>
        </author>
        <author>
            <name>Kristen Grauman</name>
        </author>
        <author>
            <name>Giovanni Maria Farinella</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Guest Editorial: Introduction to the Special Section on Graphs in Vision and Pattern Analysis]]></title>
        <id>https://ieeexplore.ieee.org/document/10120667</id>
        <link href="https://ieeexplore.ieee.org/document/10120667"/>
        <updated>2023-05-06T00:55:24.600Z</updated>
        <author>
            <name>Song Bai</name>
        </author>
        <author>
            <name>Philip H.S. Torr</name>
        </author>
        <author>
            <name>Ranjay Krishna</name>
        </author>
        <author>
            <name>Fei-Fei Li</name>
        </author>
        <author>
            <name>Abhinav Gupta</name>
        </author>
        <author>
            <name>Song-Chun Zhu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diverse Sample Generation: Pushing the Limit of Generative Data-Free Quantization]]></title>
        <id>https://ieeexplore.ieee.org/document/10115486</id>
        <link href="https://ieeexplore.ieee.org/document/10115486"/>
        <updated>2023-05-05T00:55:13.972Z</updated>
        <summary type="html"><![CDATA[Generative data-free quantization emerges as a practical compression approach that quantizes deep neural networks to low bit-width without accessing the real data. This approach generates data utilizing batch normalization (BN) statistics of the full-precision networks to quantize the networks. However, it always faces the serious challenges of accuracy degradation in practice. We first give a the...]]></summary>
        <author>
            <name>Haotong Qin</name>
        </author>
        <author>
            <name>Yifu Ding</name>
        </author>
        <author>
            <name>Xiangguo Zhang</name>
        </author>
        <author>
            <name>Jiakai Wang</name>
        </author>
        <author>
            <name>Xianglong Liu</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SPDET: Edge-Aware Self-Supervised Panoramic Depth Estimation Transformer With Spherical Geometry]]></title>
        <id>https://ieeexplore.ieee.org/document/10115484</id>
        <link href="https://ieeexplore.ieee.org/document/10115484"/>
        <updated>2023-05-05T00:55:13.972Z</updated>
        <summary type="html"><![CDATA[Panoramic depth estimation has become a hot topic in 3D reconstruction techniques with its omnidirectional spatial field of view. However, panoramic RGB-D datasets are difficult to obtain due to the lack of panoramic RGB-D cameras, thus limiting the practicality of supervised panoramic depth estimation. Self-supervised learning based on RGB stereo image pairs has the potential to overcome this lim...]]></summary>
        <author>
            <name>Chuanqing Zhuang</name>
        </author>
        <author>
            <name>Zhengda Lu</name>
        </author>
        <author>
            <name>Yiqun Wang</name>
        </author>
        <author>
            <name>Jun Xiao</name>
        </author>
        <author>
            <name>Ying Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SC$^{2}$-PCR++: Rethinking the Generation and Selection for Efficient and Robust Point Cloud Registration]]></title>
        <id>https://ieeexplore.ieee.org/document/10115040</id>
        <link href="https://ieeexplore.ieee.org/document/10115040"/>
        <updated>2023-05-03T20:08:48.087Z</updated>
        <summary type="html"><![CDATA[Outlier removal is a critical part of feature-based point cloud registration. In this paper, we revisit the model generation and selection of the classic RANSAC approach for fast and robust point cloud registration. For the model generation, we propose a second-order spatial compatibility (SC$^{2}$) measure to compute the similarity between correspondences. It takes into account global compatibili...]]></summary>
        <author>
            <name>Zhi Chen</name>
        </author>
        <author>
            <name>Kun Sun</name>
        </author>
        <author>
            <name>Fan Yang</name>
        </author>
        <author>
            <name>Lin Guo</name>
        </author>
        <author>
            <name>Wenbing Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual Adaptive Representation Alignment for Cross-Domain Few-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10115025</id>
        <link href="https://ieeexplore.ieee.org/document/10115025"/>
        <updated>2023-05-03T20:08:48.087Z</updated>
        <summary type="html"><![CDATA[Few-shot learning aims to recognize novel queries with limited support samples by learning from base knowledge. Recent progress in this setting assumes that the base knowledge and novel query samples are distributed in the same domains, which are usually infeasible for realistic applications. Toward this issue, we propose to address the cross-domain few-shot learning problem where only extremely f...]]></summary>
        <author>
            <name>Yifan Zhao</name>
        </author>
        <author>
            <name>Tong Zhang</name>
        </author>
        <author>
            <name>Jia Li</name>
        </author>
        <author>
            <name>Yonghong Tian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging Commonsense for Object Localisation in Partial Scenes]]></title>
        <id>https://ieeexplore.ieee.org/document/10115261</id>
        <link href="https://ieeexplore.ieee.org/document/10115261"/>
        <updated>2023-05-03T20:08:48.087Z</updated>
        <summary type="html"><![CDATA[We propose an end-to-end solution to address the problem of object localisation in partial scenes, where we aim to estimate the position of an object in an unknown area given only a partial 3D scan of the scene. We propose a novel scene representation to facilitate the geometric reasoning, Directed Spatial Commonsense Graph (D-SCG), a spatial scene graph that is enriched with additional concept no...]]></summary>
        <author>
            <name>Francesco Giuliari</name>
        </author>
        <author>
            <name>Geri Skenderi</name>
        </author>
        <author>
            <name>Marco Cristani</name>
        </author>
        <author>
            <name>Alessio Del Bue</name>
        </author>
        <author>
            <name>Yiming Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Toward Human-Like Grasp: Functional Grasp by Dexterous Robotic Hand Via Object-Hand Semantic Representation]]></title>
        <id>https://ieeexplore.ieee.org/document/10115005</id>
        <link href="https://ieeexplore.ieee.org/document/10115005"/>
        <updated>2023-05-03T20:08:48.087Z</updated>
        <summary type="html"><![CDATA[Intelligent robotic manipulation is a challenging study of machine intelligence. Although many dexterous robotic hands have been designed to assist or replace human hands in executing various tasks, how to teach them to perform dexterous operations like human hands is still a challenge. This motivates us to conduct an in-depth analysis of human behavior in manipulating objects and propose an objec...]]></summary>
        <author>
            <name>Tianqiang Zhu</name>
        </author>
        <author>
            <name>Rina Wu</name>
        </author>
        <author>
            <name>Jinglue Hang</name>
        </author>
        <author>
            <name>Xiangbo Lin</name>
        </author>
        <author>
            <name>Yi Sun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diffusion Mechanism in Residual Neural Network: Theory and Applications]]></title>
        <id>https://ieeexplore.ieee.org/document/10114599</id>
        <link href="https://ieeexplore.ieee.org/document/10114599"/>
        <updated>2023-05-02T20:09:10.040Z</updated>
        <summary type="html"><![CDATA[Diffusion, a fundamental internal mechanism emerging in many physical processes, describes the interaction among different objects. In many learning tasks with limited training samples, the diffusion connects the labeled and unlabeled data points and is a critical component for achieving high classification accuracy. Many existing deep learning approaches directly impose the fusion loss when train...]]></summary>
        <author>
            <name>Tangjun Wang</name>
        </author>
        <author>
            <name>Zehao Dou</name>
        </author>
        <author>
            <name>Chenglong Bao</name>
        </author>
        <author>
            <name>Zuoqiang Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recent Advances for Quantum Neural Networks in Generative Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10113742</id>
        <link href="https://ieeexplore.ieee.org/document/10113742"/>
        <updated>2023-05-01T20:09:18.610Z</updated>
        <summary type="html"><![CDATA[Quantum computers are next-generation devices that hold promise to perform calculations beyond the reach of classical computers. A leading method towards achieving this goal is through quantum machine learning, especially quantum generative learning. Due to the intrinsic probabilistic nature of quantum mechanics, it is reasonable to postulate that quantum generative learning models (QGLMs) may sur...]]></summary>
        <author>
            <name>Jinkai Tian</name>
        </author>
        <author>
            <name>Xiaoyu Sun</name>
        </author>
        <author>
            <name>Yuxuan Du</name>
        </author>
        <author>
            <name>Shanshan Zhao</name>
        </author>
        <author>
            <name>Qing Liu</name>
        </author>
        <author>
            <name>Kaining Zhang</name>
        </author>
        <author>
            <name>Wei Yi</name>
        </author>
        <author>
            <name>Wanrong Huang</name>
        </author>
        <author>
            <name>Chaoyue Wang</name>
        </author>
        <author>
            <name>Xingyao Wu</name>
        </author>
        <author>
            <name>Min-Hsiu Hsieh</name>
        </author>
        <author>
            <name>Tongliang Liu</name>
        </author>
        <author>
            <name>Wenjing Yang</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CMW-Net: Learning a Class-Aware Sample Weighting Mapping for Robust Deep Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10113668</id>
        <link href="https://ieeexplore.ieee.org/document/10113668"/>
        <updated>2023-05-01T20:09:18.610Z</updated>
        <summary type="html"><![CDATA[Modern deep neural networks (DNNs) can easily overfit to biased training data containing corrupted labels or class imbalance. Sample re-weighting methods are popularly used to alleviate this data bias issue. Most current methods, however, require manually pre-specifying the weighting schemes as well as their additional hyper-parameters relying on the characteristics of the investigated problem and...]]></summary>
        <author>
            <name>Jun Shu</name>
        </author>
        <author>
            <name>Xiang Yuan</name>
        </author>
        <author>
            <name>Deyu Meng</name>
        </author>
        <author>
            <name>Zongben Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PyMAF-X: Towards Well-Aligned Full-Body Model Regression From Monocular Images]]></title>
        <id>https://ieeexplore.ieee.org/document/10113183</id>
        <link href="https://ieeexplore.ieee.org/document/10113183"/>
        <updated>2023-05-01T20:09:18.610Z</updated>
        <summary type="html"><![CDATA[We present PyMAF-X, a regression-based approach to recovering a parametric full-body model from a single image. This task is very challenging since minor parametric deviation may lead to noticeable misalignment between the estimated mesh and the input image. Moreover, when integrating part-specific estimations into the full-body model, existing solutions tend to either degrade the alignment or pro...]]></summary>
        <author>
            <name>Hongwen Zhang</name>
        </author>
        <author>
            <name>Yating Tian</name>
        </author>
        <author>
            <name>Yuxiang Zhang</name>
        </author>
        <author>
            <name>Mengcheng Li</name>
        </author>
        <author>
            <name>Liang An</name>
        </author>
        <author>
            <name>Zhenan Sun</name>
        </author>
        <author>
            <name>Yebin Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Data-Free Knowledge Distillation for Continual Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10113287</id>
        <link href="https://ieeexplore.ieee.org/document/10113287"/>
        <updated>2023-05-01T20:09:18.610Z</updated>
        <summary type="html"><![CDATA[Deep neural networks suffer from catastrophic forgetting when trained on sequential tasks in continual learning. Various methods rely on storing data of previous tasks to mitigate catastrophic forgetting, which is prohibited in real-world applications considering privacy and security issues. In this paper, we consider a realistic setting of continual learning, where training data of previous tasks...]]></summary>
        <author>
            <name>Xiaorong Li</name>
        </author>
        <author>
            <name>Shipeng Wang</name>
        </author>
        <author>
            <name>Jian Sun</name>
        </author>
        <author>
            <name>Zongben Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast-SNARF: A Fast Deformer for Articulated Neural Fields]]></title>
        <id>https://ieeexplore.ieee.org/document/10112633</id>
        <link href="https://ieeexplore.ieee.org/document/10112633"/>
        <updated>2023-04-28T20:08:47.075Z</updated>
        <summary type="html"><![CDATA[Neural fields have revolutionized the area of 3D reconstruction and novel view synthesis of rigid scenes. A key challenge in making such methods applicable to articulated objects, such as the human body, is to model the deformation of 3D locations between the rest pose (a canonical space) and the deformed space. We propose a new articulation module for neural fields, Fast-SNARF, which finds accura...]]></summary>
        <author>
            <name>Xu Chen</name>
        </author>
        <author>
            <name>Tianjian Jiang</name>
        </author>
        <author>
            <name>Jie Song</name>
        </author>
        <author>
            <name>Max Rietmann</name>
        </author>
        <author>
            <name>Andreas Geiger</name>
        </author>
        <author>
            <name>Michael J. Black</name>
        </author>
        <author>
            <name>Otmar Hilliges</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Measuring Human Perception to Improve Open Set Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10109834</id>
        <link href="https://ieeexplore.ieee.org/document/10109834"/>
        <updated>2023-04-28T01:21:22.240Z</updated>
        <summary type="html"><![CDATA[The human ability to recognize when an object belongs or does not belong to a particular vision task outperforms all open set recognition algorithms. Human perception as measured by the methods and procedures of visual psychophysics from psychology provides an additional data stream for algorithms that need to manage novelty. For instance, measured reaction time from human subjects can offer insig...]]></summary>
        <author>
            <name>Jin Huang</name>
        </author>
        <author>
            <name>Derek Prijatelj</name>
        </author>
        <author>
            <name>Justin Dulay</name>
        </author>
        <author>
            <name>Walter Scheirer</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SignBERT+: Hand-model-aware Self-supervised Pre-training for Sign Language Understanding]]></title>
        <id>https://ieeexplore.ieee.org/document/10109128</id>
        <link href="https://ieeexplore.ieee.org/document/10109128"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Hand gesture serves as a crucial role during the expression of sign language. Current deep learning based methods for sign language understanding (SLU) are prone to over-fitting due to insufficient sign data resource and suffer limited interpretability. In this paper, we propose the first self-supervised pre-trainable SignBERT+ framework with model-aware hand prior incorporated. In our framework, ...]]></summary>
        <author>
            <name>Hezhen Hu</name>
        </author>
        <author>
            <name>Weichao Zhao</name>
        </author>
        <author>
            <name>Wengang Zhou</name>
        </author>
        <author>
            <name>Houqiang Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Source-Free Progressive Graph Learning for Open-Set Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/10107906</id>
        <link href="https://ieeexplore.ieee.org/document/10107906"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Open-set domain adaptation (OSDA) has gained considerable attention in many visual recognition tasks. The aim of OSDA is to transfer knowledge from a label-rich source domain to a label-scarce target domain while addressing the disturbances from the irrelevant target classes that are not present in the source data. However, most existing OSDA approaches are limited due to three main reasons, inclu...]]></summary>
        <author>
            <name>Yadan Luo</name>
        </author>
        <author>
            <name>Zijian Wang</name>
        </author>
        <author>
            <name>Zhuoxiao Chen</name>
        </author>
        <author>
            <name>Zi Huang</name>
        </author>
        <author>
            <name>Mahsa Baktashmotlagh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-Order Correlation-Guided Slide-Level Histology Retrieval With Self-Supervised Hashing]]></title>
        <id>https://ieeexplore.ieee.org/document/10107814</id>
        <link href="https://ieeexplore.ieee.org/document/10107814"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Histopathological Whole Slide Images (WSIs) play a crucial role in cancer diagnosis. It is of significant importance for pathologists to search for images sharing similar content with the query WSI, especially in the case-based diagnosis. While slide-level retrieval could be more intuitive and practical in clinical applications, most methods are designed for patch-level retrieval. A few recently u...]]></summary>
        <author>
            <name>Shengrui Li</name>
        </author>
        <author>
            <name>Yining Zhao</name>
        </author>
        <author>
            <name>Jun Zhang</name>
        </author>
        <author>
            <name>Ting Yu</name>
        </author>
        <author>
            <name>Ji Zhang</name>
        </author>
        <author>
            <name>Yue Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NExT-OOD: Overcoming Dual Multiple-choice VQA Biases]]></title>
        <id>https://ieeexplore.ieee.org/document/10107423</id>
        <link href="https://ieeexplore.ieee.org/document/10107423"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In recent years, multiple-choice Visual Question Answering (VQA) has become topical and achieved remarkable progress. However, most pioneer multiple-choice VQA models are heavily driven by statistical correlations in datasets, which cannot perform well on multimodal understanding and suffer from poor generalization. In this paper, we identify two kinds of spurious correlations, i.e., a Vision-Answ...]]></summary>
        <author>
            <name>Xi Zhang</name>
        </author>
        <author>
            <name>Feifei Zhang</name>
        </author>
        <author>
            <name>Changsheng Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An integrated fast Hough transform for multidimensional data]]></title>
        <id>https://ieeexplore.ieee.org/document/10106423</id>
        <link href="https://ieeexplore.ieee.org/document/10106423"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Line, plane and hyperplane detection in multidimensional data has many applications in computer vision and artificial intelligence. We propose Integrated Fast Hough Transform (IFHT), a highly-efficient multidimensional Hough transform algorithm based on a new mathematical model. The parameter space of IFHT can be represented with a single k-tree to support hierarchical storage and “coarse-to-fine”...]]></summary>
        <author>
            <name>Yanhui Li</name>
        </author>
        <author>
            <name>Xiangchao Gan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Relational Point Completion Network for Robust 3D Classification]]></title>
        <id>https://ieeexplore.ieee.org/document/10106495</id>
        <link href="https://ieeexplore.ieee.org/document/10106495"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Real-scanned point clouds are often incomplete due to viewpoint, occlusion, and noise, which hampers 3D geometric modeling and perception. Existing point cloud completion methods tend to generate global shape skeletons and hence lack fine local details. Furthermore, they mostly learn a deterministic partial-to-complete mapping, but overlook structural relations in man-made objects. To tackle these...]]></summary>
        <author>
            <name>Liang Pan</name>
        </author>
        <author>
            <name>Xinyi Chen</name>
        </author>
        <author>
            <name>Zhongang Cai</name>
        </author>
        <author>
            <name>Junzhe Zhang</name>
        </author>
        <author>
            <name>Haiyu Zhao</name>
        </author>
        <author>
            <name>Shuai Yi</name>
        </author>
        <author>
            <name>Ziwei Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Information-Theoretic Method to Automatic Shortcut Avoidance and Domain Generalization for Dense Prediction Tasks]]></title>
        <id>https://ieeexplore.ieee.org/document/10106000</id>
        <link href="https://ieeexplore.ieee.org/document/10106000"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Deep convolutional neural networks for dense prediction tasks are commonly optimized using synthetic data, as generating pixel-wise annotations for real-world data is laborious. However, the synthetically trained models do not generalize well to real-world environments. This poor “synthetic to real” (S2R) generalization we address through the lens of shortcut learning. We demonstrate that the lear...]]></summary>
        <author>
            <name>WeiQin Chuah</name>
        </author>
        <author>
            <name>Ruwan Tennakoon</name>
        </author>
        <author>
            <name>Reza Hoseinnezhad</name>
        </author>
        <author>
            <name>David Suter</name>
        </author>
        <author>
            <name>Alireza Bab- Hadiashar</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global Aligned Structured Sparsity Learning for Efficient Image Super-Resolution]]></title>
        <id>https://ieeexplore.ieee.org/document/10106130</id>
        <link href="https://ieeexplore.ieee.org/document/10106130"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Efficient image super-resolution (SR) has witnessed rapid progress thanks to novel lightweight architectures or model compression techniques (e.g., neural architecture search and knowledge distillation). Nevertheless, these methods consume considerable resources or/and neglect to squeeze out the network redundancy at a more fine-grained convolution filter level. Network pruning is a promising alte...]]></summary>
        <author>
            <name>Huan Wang</name>
        </author>
        <author>
            <name>Yulun Zhang</name>
        </author>
        <author>
            <name>Can Qin</name>
        </author>
        <author>
            <name>Luc Van Gool</name>
        </author>
        <author>
            <name>Yun Fu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deformable Part Region Learning and Feature Aggregation Tree Representation for Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10106088</id>
        <link href="https://ieeexplore.ieee.org/document/10106088"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Region-based object detection infers object regions for one or more categories in an image. Due to the recent advances in deep learning and region proposal methods, object detectors based on convolutional neural networks (CNNs) have been flourishing and provided promising detection results. However, the accuracy of the convolutional object detectors can be degraded often due to the low feature dis...]]></summary>
        <author>
            <name>Seung-Hwan Bae</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RelTR: Relation Transformer for Scene Graph Generation]]></title>
        <id>https://ieeexplore.ieee.org/document/10105507</id>
        <link href="https://ieeexplore.ieee.org/document/10105507"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Different objects in the same scene are more or less related to each other, but only a limited number of these relationships are noteworthy. Inspired by Detection Transformer, which excels in object detection, we view scene graph generation as a set prediction problem. In this paper, we propose an end-to-end scene graph generation model Relation Transformer (RelTR), which has an encoder-decoder ar...]]></summary>
        <author>
            <name>Yuren Cong</name>
        </author>
        <author>
            <name>Michael Ying Yang</name>
        </author>
        <author>
            <name>Bodo Rosenhahn</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Representing Multimodal Behaviors With Mean Location for Pedestrian Trajectory Prediction]]></title>
        <id>https://ieeexplore.ieee.org/document/10105525</id>
        <link href="https://ieeexplore.ieee.org/document/10105525"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Representing multimodal behaviors is a critical challenge for pedestrian trajectory prediction. Previous methods commonly represent this multimodality with multiple latent variables repeatedly sampled from a latent space, encountering difficulties in interpretable trajectory prediction. Moreover, the latent space is usually built by encoding global interaction into future trajectory, which inevita...]]></summary>
        <author>
            <name>Liushuai Shi</name>
        </author>
        <author>
            <name>Le Wang</name>
        </author>
        <author>
            <name>Chengjiang Long</name>
        </author>
        <author>
            <name>Sanping Zhou</name>
        </author>
        <author>
            <name>Wei Tang</name>
        </author>
        <author>
            <name>Nanning Zheng</name>
        </author>
        <author>
            <name>Gang Hua</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual Vision Transformer]]></title>
        <id>https://ieeexplore.ieee.org/document/10105499</id>
        <link href="https://ieeexplore.ieee.org/document/10105499"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recent advances have presented several strategies to mitigate the computations of self-attention mechanism with high-resolution inputs. Many of these works consider decomposing the global self-attention procedure over image patches into regional and local feature extraction procedures that each incurs a smaller computational complexity. Despite good efficiency, these approaches seldom explore the ...]]></summary>
        <author>
            <name>Ting Yao</name>
        </author>
        <author>
            <name>Yehao Li</name>
        </author>
        <author>
            <name>Yingwei Pan</name>
        </author>
        <author>
            <name>Yu Wang</name>
        </author>
        <author>
            <name>Xiao-Ping Zhang</name>
        </author>
        <author>
            <name>Tao Mei</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[REDRESS: Generating Compressed Models for Edge Inference Using Tsetlin Machines]]></title>
        <id>https://ieeexplore.ieee.org/document/10105493</id>
        <link href="https://ieeexplore.ieee.org/document/10105493"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Inference at-the-edge using embedded machine learning models is associated with challenging trade-offs between resource metrics, such as energy and memory footprint, and the performance metrics, such as computation time and accuracy. In this work, we go beyond the conventional Neural Network based approaches to explore Tsetlin Machine (TM), an emerging machine learning algorithm, that uses learnin...]]></summary>
        <author>
            <name>Sidharth Maheshwari</name>
        </author>
        <author>
            <name>Tousif Rahman</name>
        </author>
        <author>
            <name>Rishad ShafikSenior member</name>
        </author>
        <author>
            <name>Alex Yakovlev</name>
        </author>
        <author>
            <name>Ashur Rafiev</name>
        </author>
        <author>
            <name>Lei Jiao</name>
        </author>
        <author>
            <name>Ole-Christoffer Granmo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mutual Voting for Ranking 3D Correspondences]]></title>
        <id>https://ieeexplore.ieee.org/document/10105460</id>
        <link href="https://ieeexplore.ieee.org/document/10105460"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Consistent correspondences between point clouds are vital to 3D vision tasks such as registration and recognition. In this paper, we present a mutual voting method for ranking 3D correspondences. The key insight is to achieve reliable scoring results for correspondences by refining both voters and candidates in a mutual voting scheme. First, a graph is constructed for the initial correspondence se...]]></summary>
        <author>
            <name>Jiaqi Yang</name>
        </author>
        <author>
            <name>Xiyu Zhang</name>
        </author>
        <author>
            <name>Shichao Fan</name>
        </author>
        <author>
            <name>Chunlin Ren</name>
        </author>
        <author>
            <name>Yanning Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LRRNet: A Novel Representation Learning Guided Fusion Network for Infrared and Visible Images]]></title>
        <id>https://ieeexplore.ieee.org/document/10105495</id>
        <link href="https://ieeexplore.ieee.org/document/10105495"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Deep learning based fusion methods have been achieving promising performance in image fusion tasks. This is attributed to the network architecture that plays a very important role in the fusion process. However, in general, it is hard to specify a good fusion architecture, and consequently, the design of fusion networks is still a black art, rather than science. To address this problem, we formula...]]></summary>
        <author>
            <name>Hui Li</name>
        </author>
        <author>
            <name>Tianyang Xu</name>
        </author>
        <author>
            <name>Xiao-Jun Wu</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
        <author>
            <name>Josef Kittler</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Long-Tailed Learning: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10105457</id>
        <link href="https://ieeexplore.ieee.org/document/10105457"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Deep long-tailed learning, one of the most challenging problems in visual recognition, aims to train well-performing deep models from a large number of images that follow a long-tailed class distribution. In the last decade, deep learning has emerged as a powerful recognition model for learning high-quality image representations and has led to remarkable breakthroughs in generic visual recognition...]]></summary>
        <author>
            <name>Yifan Zhang</name>
        </author>
        <author>
            <name>Bingyi Kang</name>
        </author>
        <author>
            <name>Bryan Hooi</name>
        </author>
        <author>
            <name>Shuicheng Yan</name>
        </author>
        <author>
            <name>Jiashi Feng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Attention Weighted Local Descriptors]]></title>
        <id>https://ieeexplore.ieee.org/document/10105519</id>
        <link href="https://ieeexplore.ieee.org/document/10105519"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Local features detection and description are widely used in many vision applications with high industrial and commercial demands. With large-scale applications, these tasks raise high expectations for both the accuracy and speed of local features. Most existing studies on local features learning focus on the local descriptions of individual keypoints, which neglect their relationships established ...]]></summary>
        <author>
            <name>Changwei Wang</name>
        </author>
        <author>
            <name>Rongtao Xu</name>
        </author>
        <author>
            <name>Ke Lv</name>
        </author>
        <author>
            <name>Shibiao Xu</name>
        </author>
        <author>
            <name>Weiliang Meng</name>
        </author>
        <author>
            <name>Yuyang Zhang</name>
        </author>
        <author>
            <name>Bin Fan</name>
        </author>
        <author>
            <name>Xiaopeng Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Reasoning: From State to Transformation]]></title>
        <id>https://ieeexplore.ieee.org/document/10105523</id>
        <link href="https://ieeexplore.ieee.org/document/10105523"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Most existing visual reasoning tasks, such as CLEVR in VQA, ignore an important factor, i.e. transformation. They are solely defined to test how well machines understand concepts and relations within static settings, like one image. Such state driven visual reasoning has limitations in reflecting the ability to infer the dynamics between different states, which has shown to be equally important fo...]]></summary>
        <author>
            <name>Xin Hong</name>
        </author>
        <author>
            <name>Yanyan Lan</name>
        </author>
        <author>
            <name>Liang Pang</name>
        </author>
        <author>
            <name>Jiafeng Guo</name>
        </author>
        <author>
            <name>Xueqi Cheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gate-Shift-Fuse for Video Action Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10105518</id>
        <link href="https://ieeexplore.ieee.org/document/10105518"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Convolutional Neural Networks are the de facto models for image recognition. However 3D CNNs, the straight forward extension of 2D CNNs for video recognition, have not achieved the same success on standard action recognition benchmarks. One of the main reasons for this reduced performance of 3D CNNs is the increased computational complexity requiring large scale annotated datasets to train them in...]]></summary>
        <author>
            <name>Swathikiran Sudhakaran</name>
        </author>
        <author>
            <name>Sergio Escalera</name>
        </author>
        <author>
            <name>Oswald Lanz</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prior Image Guided Snapshot Compressive Spectral Imaging]]></title>
        <id>https://ieeexplore.ieee.org/document/10098166</id>
        <link href="https://ieeexplore.ieee.org/document/10098166"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Spectral images with rich spatial and spectral information have wide usage, however, traditional spectral imaging techniques undeniably take a long time to capture scenes. We consider the computational imaging problem of the snapshot spectral spectrometer, i.e., the Coded Aperture Snapshot Spectral Imaging (CASSI) system. For the sake of a fast and generalized reconstruction algorithm, we propose ...]]></summary>
        <author>
            <name>Yurong Chen</name>
        </author>
        <author>
            <name>Yaonan Wang</name>
        </author>
        <author>
            <name>Hui Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Temporal Pixel-Level Semantic Understanding Through the VSPW Dataset]]></title>
        <id>https://ieeexplore.ieee.org/document/10098665</id>
        <link href="https://ieeexplore.ieee.org/document/10098665"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Scene understanding through pixel-level semantic parsing is one of the main problems in computer vision. Till now, image-based methods and datasets for scene parsing have been well explored. However, the real world is naturally dynamic instead of a static state. Thus, learning to perform video scene parsing is more practical for real-world applications. Considering that few datasets cover an exten...]]></summary>
        <author>
            <name>Jiaxu Miao</name>
        </author>
        <author>
            <name>Yunchao Wei</name>
        </author>
        <author>
            <name>Xiaohan Wang</name>
        </author>
        <author>
            <name>Yi Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Base and Meta: A New Perspective on Few-Shot Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10098188</id>
        <link href="https://ieeexplore.ieee.org/document/10098188"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Despite the progress made by few-shot segmentation (FSS) in low-data regimes, the generalization capability of most previous works could be fragile when countering hard query samples with seen-class objects. This paper proposes a fresh and powerful scheme to tackle such an intractable bias problem, dubbed base and meta (BAM). Concretely, we apply an auxiliary branch (base learner) to the conventio...]]></summary>
        <author>
            <name>Chunbo Lang</name>
        </author>
        <author>
            <name>Gong Cheng</name>
        </author>
        <author>
            <name>Binfei Tu</name>
        </author>
        <author>
            <name>Chao Li</name>
        </author>
        <author>
            <name>Junwei Han</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse-to-Dense Matching Network for Large-scale LiDAR Point Cloud Registration]]></title>
        <id>https://ieeexplore.ieee.org/document/10097640</id>
        <link href="https://ieeexplore.ieee.org/document/10097640"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Point cloud registration is a fundamental problem in 3D computer vision. Previous learning-based methods for LiDAR point cloud registration can be categorized into two schemes: dense-to-dense matching methods and sparse-to-sparse matching methods. However, for large-scale outdoor LiDAR point clouds, solving dense point correspondences is time-consuming, whereas sparse keypoint matching easily suff...]]></summary>
        <author>
            <name>Fan Lu</name>
        </author>
        <author>
            <name>Guang Chen</name>
        </author>
        <author>
            <name>Yinlong Liu</name>
        </author>
        <author>
            <name>Yibing Zhan</name>
        </author>
        <author>
            <name>Zhijun Li</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
        <author>
            <name>Changjun Jiang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PSLT: A Light-weight Vision Transformer with Ladder Self-Attention and Progressive Shift]]></title>
        <id>https://ieeexplore.ieee.org/document/10097573</id>
        <link href="https://ieeexplore.ieee.org/document/10097573"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Vision Transformer (ViT) has shown great potential for various visual tasks due to its ability to model long-range dependency. However, ViT requires a large amount of computing resource to compute the global self-attention. In this work, we propose a ladder self-attention block with multiple branches and a progressive shift mechanism to develop a light-weight transformer backbone that requires les...]]></summary>
        <author>
            <name>Gaojie Wu</name>
        </author>
        <author>
            <name>Wei-Shi Zheng</name>
        </author>
        <author>
            <name>Yutong Lu</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CP3: Unifying Point Cloud Completion by Pretrain-Prompt-Predict Paradigm]]></title>
        <id>https://ieeexplore.ieee.org/document/10097548</id>
        <link href="https://ieeexplore.ieee.org/document/10097548"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Point cloud completion aims to predict complete shape from its partial observation. Current approaches mainly consist of generation and refinement stages in a coarse-to-fine style. However, the generation stage often lacks robustness to tackle different incomplete variations, while the refinement stage blindly recovers point clouds without the semantic awareness. To tackle these challenges, we uni...]]></summary>
        <author>
            <name>Mingye Xu</name>
        </author>
        <author>
            <name>Yali Wang</name>
        </author>
        <author>
            <name>Yihao Liu</name>
        </author>
        <author>
            <name>Tong He</name>
        </author>
        <author>
            <name>Yu Qiao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prioritized Subnet Sampling for Resource-Adaptive Supernet Training]]></title>
        <id>https://ieeexplore.ieee.org/document/10094012</id>
        <link href="https://ieeexplore.ieee.org/document/10094012"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[A resource-adaptive supernet adjusts its subnets for inference to fit the dynamically available resources. In this paper, we propose prioritized subnet sampling to train a resource-adaptive supernet, termed PSS-Net. We maintain multiple subnet pools, each of which stores the information of substantial subnets with similar resource consumption. Considering a resource constraint, subnets conditioned...]]></summary>
        <author>
            <name>Bohong Chen</name>
        </author>
        <author>
            <name>Mingbao Lin</name>
        </author>
        <author>
            <name>Rongrong Ji</name>
        </author>
        <author>
            <name>Liujuan Cao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Gaussian Scale Mixture Prior for Image Reconstruction]]></title>
        <id>https://ieeexplore.ieee.org/document/10094019</id>
        <link href="https://ieeexplore.ieee.org/document/10094019"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Image reconstruction from partial observations has attracted increasing attention. Conventional image reconstruction methods with hand-crafted priors often fail to recover fine image details due to the poor representation capability of the hand-crafted priors. Deep learning methods attack this problem by directly learning mapping functions between the observations and the targeted images can achie...]]></summary>
        <author>
            <name>Tao Huang</name>
        </author>
        <author>
            <name>Xin Yuan</name>
        </author>
        <author>
            <name>Weisheng Dong</name>
        </author>
        <author>
            <name>Jinjian Wu</name>
        </author>
        <author>
            <name>Guangming Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The cluster structure function]]></title>
        <id>https://ieeexplore.ieee.org/document/10093042</id>
        <link href="https://ieeexplore.ieee.org/document/10093042"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[For each partition of a data set into a given number of parts there is a partition such that every part is as much as possible a good model (an “algorithmic sufficient statistic”) for the data in that part. Since this can be done for every number between one and the number of data, the result is a function, the cluster structure function. It maps the number of parts of a partition to values relate...]]></summary>
        <author>
            <name>Andrew R. Cohen</name>
        </author>
        <author>
            <name>Paul M.B. Vitányi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector]]></title>
        <id>https://ieeexplore.ieee.org/document/10093066</id>
        <link href="https://ieeexplore.ieee.org/document/10093066"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this paper, we present a novel end-to-end group collaborative learning network, termed GCoNet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. The proposed GCoNet+ achieves the new state-of-the-art performance for co-salient object detection (CoSOD) through mining consensus representations based on the following two essential criteria: 1) intra-gr...]]></summary>
        <author>
            <name>Peng Zheng</name>
        </author>
        <author>
            <name>Huazhu Fu</name>
        </author>
        <author>
            <name>Deng-Ping Fan</name>
        </author>
        <author>
            <name>Qi Fan</name>
        </author>
        <author>
            <name>Jie Qin</name>
        </author>
        <author>
            <name>Yu-Wing Tai</name>
        </author>
        <author>
            <name>Chi-Keung Tang</name>
        </author>
        <author>
            <name>Luc Van Gool</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Surrogate modeling for Bayesian optimization beyond a single Gaussian process]]></title>
        <id>https://ieeexplore.ieee.org/document/10093035</id>
        <link href="https://ieeexplore.ieee.org/document/10093035"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Bayesian optimization (BO) has well-documented merits for optimizing black-box functions with an expensive evaluation cost. Such functions emerge in applications as diverse as hyperparameter tuning, drug discovery, and robotics. BO hinges on a Bayesian surrogate model to sequentially select query points so as to balance exploration with exploitation of the search space. Most existing works rely on...]]></summary>
        <author>
            <name>Qin Lu</name>
        </author>
        <author>
            <name>Konstantinos D. Polyzos</name>
        </author>
        <author>
            <name>Bingcong Li</name>
        </author>
        <author>
            <name>Georgios B. Giannakis</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bias-Compensated Integral Regression for Human Pose Estimation]]></title>
        <id>https://ieeexplore.ieee.org/document/10093110</id>
        <link href="https://ieeexplore.ieee.org/document/10093110"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In human and hand pose estimation, heatmaps are a crucial intermediate representation for a body or hand keypoint. Two popular methods to decode the heatmap into a final joint coordinate are via an argmax, as done in heatmap detection, or via softmax and expectation, as done in integral regression. Integral regression is learnable end-to-end, but has lower accuracy than detection. This paper uncov...]]></summary>
        <author>
            <name>Kerui Gu</name>
        </author>
        <author>
            <name>Linlin Yang</name>
        </author>
        <author>
            <name>Michael Bi Mi</name>
        </author>
        <author>
            <name>Angela Yao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Point Cloud Scene Completion with Joint Color and Semantic Estimation from Single RGB-D Image]]></title>
        <id>https://ieeexplore.ieee.org/document/10093076</id>
        <link href="https://ieeexplore.ieee.org/document/10093076"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We present a deep reinforcement learning method of progressive view inpainting for colored semantic point cloud scene completion under volume guidance, achieving high-quality scene reconstruction from only a single RGB-D image with severe occlusion. Our approach is end-to-end, consisting of three modules: 3D scene volume reconstruction, 2D RGB-D and segmentation image inpainting, and multi-view se...]]></summary>
        <author>
            <name>Zhaoxuan Zhang</name>
        </author>
        <author>
            <name>Xiaoguang Han</name>
        </author>
        <author>
            <name>Bo Dong</name>
        </author>
        <author>
            <name>Tong Li</name>
        </author>
        <author>
            <name>Baocai Yin</name>
        </author>
        <author>
            <name>Xin Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[QGORE: Quadratic-Time Guaranteed Outlier Removal for Point Cloud Registration]]></title>
        <id>https://ieeexplore.ieee.org/document/10091912</id>
        <link href="https://ieeexplore.ieee.org/document/10091912"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[With the development of 3D matching technology, correspondence-based point cloud registration gains more attention. Unfortunately, 3D keypoint techniques inevitably produce a large number of outliers, i.e., outlier rate is often larger than 95%. Guaranteed outlier removal (GORE) [1] has shown very good robustness to extreme outliers. However, the high computational cost (exponential in the worst c...]]></summary>
        <author>
            <name>Jiayuan Li</name>
        </author>
        <author>
            <name>Pengcheng Shi</name>
        </author>
        <author>
            <name>Qingwu Hu</name>
        </author>
        <author>
            <name>Yongjun Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning by Restoring Broken 3D Geometry]]></title>
        <id>https://ieeexplore.ieee.org/document/10091218</id>
        <link href="https://ieeexplore.ieee.org/document/10091218"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The key point for an experienced craftsman to repair broken objects effectively is that he must know about them deeply. Similarly, we believe that a model can capture rich geometry information from a shape/scene and generate discriminative representations if it is able to find distorted parts of shapes/scenes and restore them. Inspired by this observation, we propose a novel self-supervised 3D lea...]]></summary>
        <author>
            <name>Jinxian Liu</name>
        </author>
        <author>
            <name>Bingbing Ni</name>
        </author>
        <author>
            <name>Ye Chen</name>
        </author>
        <author>
            <name>Zhenbo Yu</name>
        </author>
        <author>
            <name>Hang Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse Quadratic Approximation for Graph Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10091452</id>
        <link href="https://ieeexplore.ieee.org/document/10091452"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Learning graphs represented by $M$-matrices via an $\ell _{1}$-regularized Gaussian maximum-likelihood method is a popular approach, but also one that poses computational challenges for large scale datasets. Recently proposed methods cast this problem as a constrained optimization variant of precision matrix estimation. In this paper, we build on a state-of-the-art sparse precision matrix estimati...]]></summary>
        <author>
            <name>Dimosthenis Pasadakis</name>
        </author>
        <author>
            <name>Matthias Bollhöfer</name>
        </author>
        <author>
            <name>Olaf Schenk</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GFNet: Global Filter Networks for Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10091201</id>
        <link href="https://ieeexplore.ieee.org/document/10091201"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recent advances in self-attention and pure multi-layer perceptrons (MLP) models for vision have shown great potential in achieving promising performance with fewer inductive biases. These models are generally based on learning interaction among spatial locations from raw data. The complexity of self-attention and MLP grows quadratically as the image size increases, which makes these models hard to...]]></summary>
        <author>
            <name>Yongming Rao</name>
        </author>
        <author>
            <name>Wenliang Zhao</name>
        </author>
        <author>
            <name>Zheng Zhu</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Spatial Sparsification for Efficient Vision Transformers and Convolutional Neural Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10091227</id>
        <link href="https://ieeexplore.ieee.org/document/10091227"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this paper, we present a new approach for model acceleration by exploiting spatial sparsity in visual data. We observe that the final prediction in vision Transformers is only based on a subset of the most informative regions, which is sufficient for accurate image recognition. Based on this observation, we propose a dynamic token sparsification framework to prune redundant tokens progressively...]]></summary>
        <author>
            <name>Yongming Rao</name>
        </author>
        <author>
            <name>Zuyan Liu</name>
        </author>
        <author>
            <name>Wenliang Zhao</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap]]></title>
        <id>https://ieeexplore.ieee.org/document/10089511</id>
        <link href="https://ieeexplore.ieee.org/document/10089511"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recent advances in transformer-based architectures have shown promise in several machine learning tasks. In the audio domain, such architectures have been successfully utilised in the field of speech emotion recognition (SER). However, existing works have not evaluated the influence of model size and pre-training data on downstream performance, and have shown limited attention to generalisation, r...]]></summary>
        <author>
            <name>Johannes Wagner</name>
        </author>
        <author>
            <name>Andreas Triantafyllopoulos</name>
        </author>
        <author>
            <name>Hagen Wierstorf</name>
        </author>
        <author>
            <name>Maximilian Schmitt</name>
        </author>
        <author>
            <name>Felix Burkhardt</name>
        </author>
        <author>
            <name>Florian Eyben</name>
        </author>
        <author>
            <name>Björn W. Schuller</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Depth-Guided Optimization of Neural Radiance Fields for Indoor Multi-View Stereo]]></title>
        <id>https://ieeexplore.ieee.org/document/10089515</id>
        <link href="https://ieeexplore.ieee.org/document/10089515"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this work, we present a new multi-view depth estimation method NerfingMVS that utilizes both conventional reconstruction and learning-based priors over the recently proposed neural radiance fields (NeRF). Unlike existing neural network based optimization method that relies on estimated correspondences, our method directly optimizes over implicit volumes, eliminating the challenging step of matc...]]></summary>
        <author>
            <name>Yi Wei</name>
        </author>
        <author>
            <name>Shaohui Liu</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GradMDM: Adversarial Attack on Dynamic Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10089510</id>
        <link href="https://ieeexplore.ieee.org/document/10089510"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Dynamic neural networks can greatly reduce computation redundancy without compromising accuracy by adapting their structures based on the input. In this paper, we explore the robustness of dynamic neural networks against energy-oriented attacks targeted at reducing their efficiency. Specifically, we attack dynamic models with our novel algorithm GradMDM. GradMDM is a technique that adjusts the dir...]]></summary>
        <author>
            <name>Jianhong Pan</name>
        </author>
        <author>
            <name>Lin Geng Foo</name>
        </author>
        <author>
            <name>Qichen Zheng</name>
        </author>
        <author>
            <name>Zhipeng Fan</name>
        </author>
        <author>
            <name>Hossein Rahmani</name>
        </author>
        <author>
            <name>Qiuhong Ke</name>
        </author>
        <author>
            <name>Jun Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometry- and Accuracy-Preserving Random Forest Proximities]]></title>
        <id>https://ieeexplore.ieee.org/document/10089875</id>
        <link href="https://ieeexplore.ieee.org/document/10089875"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Random forests are considered one of the best out-of-the-box classification and regression algorithms due to their high level of predictive performance with relatively little tuning. Pairwise proximities can be computed from a trained random forest and measure the similarity between data points relative to the supervised task. Random forest proximities have been used in many applications including...]]></summary>
        <author>
            <name>Jake S. Rhodes</name>
        </author>
        <author>
            <name>Adele Cutler</name>
        </author>
        <author>
            <name>Kevin R. Moon</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features]]></title>
        <id>https://ieeexplore.ieee.org/document/10089190</id>
        <link href="https://ieeexplore.ieee.org/document/10089190"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Decoding human visual neural representations is a challenging task with great scientific significance in revealing vision-processing mechanisms and developing brain-like intelligent machines. Most existing methods are difficult to generalize to novel categories that have no corresponding neural data for training. The two main reasons are 1) the under-exploitation of the multimodal semantic knowled...]]></summary>
        <author>
            <name>Changde Du</name>
        </author>
        <author>
            <name>Kaicheng Fu</name>
        </author>
        <author>
            <name>Jinpeng Li</name>
        </author>
        <author>
            <name>Huiguang He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visible and Infrared Image Fusion Using Deep Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10088423</id>
        <link href="https://ieeexplore.ieee.org/document/10088423"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Visible and infrared image fusion (VIF) has attracted a lot of interest in recent years due to its application in many tasks, such as object detection, object tracking, scene segmentation, and crowd counting. In addition to conventional VIF methods, an increasing number of deep learning-based VIF methods have been proposed in the last five years. Different types of methods, such as CNN-based, auto...]]></summary>
        <author>
            <name>Xingchen Zhang</name>
        </author>
        <author>
            <name>Yiannis Demiris</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Missingness-Pattern-Adaptive Learning With Incomplete Data]]></title>
        <id>https://ieeexplore.ieee.org/document/10086606</id>
        <link href="https://ieeexplore.ieee.org/document/10086606"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Many real-world problems deal with collections of data with missing values, e.g., RNA sequential analytics, image completion, video processing, etc. Usually, such missing data is a serious impediment to a good learning achievement. Existing methods tend to use a universal model for all incomplete data, resulting in a suboptimal model for each missingness pattern. In this paper, we present a genera...]]></summary>
        <author>
            <name>Yongshun Gong</name>
        </author>
        <author>
            <name>Zhibin Li</name>
        </author>
        <author>
            <name>Wei Liu</name>
        </author>
        <author>
            <name>Xiankai Lu</name>
        </author>
        <author>
            <name>Xinwang Liu</name>
        </author>
        <author>
            <name>Ivor W. Tsang</name>
        </author>
        <author>
            <name>Yilong Yin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CRNet: A Fast Continual Learning Framework With Random Theory]]></title>
        <id>https://ieeexplore.ieee.org/document/10086692</id>
        <link href="https://ieeexplore.ieee.org/document/10086692"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Artificial neural networks are prone to suffer from catastrophic forgetting. Networks trained on something new tend to rapidly forget what was learned previously, a common phenomenon within connectionist models. In this work, we propose an effective and efficient continual learning framework using random theory, together with Bayes&#39; rule, to equip a single model with the ability to learn streaming...]]></summary>
        <author>
            <name>Depeng Li</name>
        </author>
        <author>
            <name>Zhigang Zeng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Automatic Transformation Search Against Deep Leakage from Gradients]]></title>
        <id>https://ieeexplore.ieee.org/document/10086616</id>
        <link href="https://ieeexplore.ieee.org/document/10086616"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Collaborative learning has gained great popularity due to its benefit of data privacy protection: participants can jointly train a Deep Learning model without sharing their training sets. However, recent works discovered that an adversary can fully recover the sensitive training samples from the shared gradients. Such reconstruction attacks pose severe threats to collaborative learning. Hence, eff...]]></summary>
        <author>
            <name>Wei Gao</name>
        </author>
        <author>
            <name>Xu Zhang</name>
        </author>
        <author>
            <name>Shangwei Guo</name>
        </author>
        <author>
            <name>Tianwei Zhang</name>
        </author>
        <author>
            <name>Tao Xiang</name>
        </author>
        <author>
            <name>Han Qiu</name>
        </author>
        <author>
            <name>Yonggang Wen</name>
        </author>
        <author>
            <name>Yang Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SDV-LOAM: Semi-Direct Visual-LiDAR Odometry and Mapping]]></title>
        <id>https://ieeexplore.ieee.org/document/10086694</id>
        <link href="https://ieeexplore.ieee.org/document/10086694"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Visual-LiDAR odometry and mapping (V-LOAM), which fuses complementary information of a camera and a LiDAR, is an attractive solution for accurate and robust pose estimation and mapping. However, existing systems could suffer nontrivial tracking errors arising from 1) association between 3D LiDAR points and sparse 2D features (i.e. 3D-2D depth association) and 2) obvious drifts in the vertical dire...]]></summary>
        <author>
            <name>Zikang Yuan</name>
        </author>
        <author>
            <name>Qingjie Wang</name>
        </author>
        <author>
            <name>Ken Cheng</name>
        </author>
        <author>
            <name>Tianyu Hao</name>
        </author>
        <author>
            <name>Xin Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[muxGNN: Multiplex Graph Neural Network for Heterogeneous Graphs]]></title>
        <id>https://ieeexplore.ieee.org/document/10086644</id>
        <link href="https://ieeexplore.ieee.org/document/10086644"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Graph neural networks (GNNs) have become effective learning techniques for many downstream network mining tasks including node and graph classification, link prediction, and network reconstruction. However, most GNN methods have been developed for homogeneous networks with only a single type of node and edge. In this work we present muxGNN, a multiplex graph neural network for heterogeneous graphs...]]></summary>
        <author>
            <name>Joshua Melton</name>
        </author>
        <author>
            <name>Siddharth Krishnan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Point Cloud Representation Learning with Deep Neural Networks: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10086697</id>
        <link href="https://ieeexplore.ieee.org/document/10086697"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Point cloud data have been widely explored due to its superior accuracy and robustness under various adverse situations. Meanwhile, deep neural networks (DNNs) have achieved very impressive success in various applications such as surveillance and autonomous driving. The convergence of point cloud and DNNs has led to many deep point cloud models, largely trained under the supervision of large-scale...]]></summary>
        <author>
            <name>Aoran Xiao</name>
        </author>
        <author>
            <name>Jiaxing Huang</name>
        </author>
        <author>
            <name>Dayan Guan</name>
        </author>
        <author>
            <name>Xiaoqin Zhang</name>
        </author>
        <author>
            <name>Shijian Lu</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient Robustness Assessment Via Adversarial Spatial-Temporal Focus on Videos]]></title>
        <id>https://ieeexplore.ieee.org/document/10086664</id>
        <link href="https://ieeexplore.ieee.org/document/10086664"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Adversarial robustness assessment for video recognition models has raised concerns owing to their wide applications on safety-critical tasks. Compared with images, videos have much high dimension, which brings huge computational costs when generating adversarial videos. This is especially serious for the query-based black-box attacks where gradient estimation for the threat models is usually utili...]]></summary>
        <author>
            <name>Xingxing Wei</name>
        </author>
        <author>
            <name>Songping Wang</name>
        </author>
        <author>
            <name>Huanqian Yan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Measuring Perceptual Color Differences of Smartphone Photographs]]></title>
        <id>https://ieeexplore.ieee.org/document/10083226</id>
        <link href="https://ieeexplore.ieee.org/document/10083226"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Measuring perceptual color differences (CDs) is of great importance in modern smartphone photography. Despite the long history, most CD measures have been constrained by psychophysical data of homogeneous color patches or a limited number of simplistic natural photographic images. It is thus questionable whether existing CD measures generalize in the age of smartphone photography characterized by ...]]></summary>
        <author>
            <name>Zhihua Wang</name>
        </author>
        <author>
            <name>Keshuo Xu</name>
        </author>
        <author>
            <name>Yang Yang</name>
        </author>
        <author>
            <name>Jianlei Dong</name>
        </author>
        <author>
            <name>Shuhang Gu</name>
        </author>
        <author>
            <name>Lihao Xu</name>
        </author>
        <author>
            <name>Yuming Fang</name>
        </author>
        <author>
            <name>Kede Ma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Local-Global Context Aware Transformer for Language-Guided Video Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10083244</id>
        <link href="https://ieeexplore.ieee.org/document/10083244"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We explore the task of language-guided video segmentation (LVS). Previous algorithms mostly adopt 3D CNNs to learn video representation, struggling to capture long-term context and easily suffering from visual-linguistic misalignment. In light of this, we present Locater (local-global context aware Transformer), which augments the Transformer architecture with a finite memory so as to query the en...]]></summary>
        <author>
            <name>Chen Liang</name>
        </author>
        <author>
            <name>Wenguan Wang</name>
        </author>
        <author>
            <name>Tianfei Zhou</name>
        </author>
        <author>
            <name>Jiaxu Miao</name>
        </author>
        <author>
            <name>Yawei Luo</name>
        </author>
        <author>
            <name>Yi Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Performance-aware Approximation of Global Channel Pruning for Multitask CNNs]]></title>
        <id>https://ieeexplore.ieee.org/document/10083285</id>
        <link href="https://ieeexplore.ieee.org/document/10083285"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Global channel pruning (GCP) aims to remove a subset of channels (filters) across different layers from a deep model without hurting the performance. Previous works focus on either single task model pruning or simply adapting it to multitask scenario, and still face the following problems when handling multitask pruning: 1) Due to the task mismatch, a well-pruned backbone for classification task f...]]></summary>
        <author>
            <name>Hancheng Ye</name>
        </author>
        <author>
            <name>Bo Zhang</name>
        </author>
        <author>
            <name>Tao Chen</name>
        </author>
        <author>
            <name>Jiayuan Fan</name>
        </author>
        <author>
            <name>Bin Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CaCo: Both Positive and Negative Samples are Directly Learnable via Cooperative-adversarial Contrastive Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10083274</id>
        <link href="https://ieeexplore.ieee.org/document/10083274"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[As a representative self-supervised method, contrastive learning has achieved great successes in unsupervised training of representations. It trains an encoder by distinguishing positive samples from negative ones given query anchors. These positive and negative samples play critical roles in defining the objective to learn the discriminative encoder, avoiding it from learning trivial features. Wh...]]></summary>
        <author>
            <name>Xiao Wang</name>
        </author>
        <author>
            <name>Yuhang Huang</name>
        </author>
        <author>
            <name>Dan Zeng</name>
        </author>
        <author>
            <name>Guo-Jun Qi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Progressive Instance-Aware Feature Learning for Compositional Action Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10082892</id>
        <link href="https://ieeexplore.ieee.org/document/10082892"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In order to enable the model to generalize to unseen “action-objects” (compositional action), previous methods encode multiple pieces of information (i.e., the appearance, position, and identity of visual instances) independently and concatenate them for classification. However, these methods ignore the potential supervisory role of instance information (i.e., position and identity) in the process...]]></summary>
        <author>
            <name>Rui Yan</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Xiangbo Shu</name>
        </author>
        <author>
            <name>Liyan Zhang</name>
        </author>
        <author>
            <name>Jinhui Tang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Diffusion Models in Vision: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10081412</id>
        <link href="https://ieeexplore.ieee.org/document/10081412"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling. A diffusion model is a deep generative model that is based on two stages, a forward diffusion stage and a reverse diffusion stage. In the forward diffusion stage, the input data is gradually perturbed over several steps by adding Gaussian noise. In t...]]></summary>
        <author>
            <name>Florinel-Alin Croitoru</name>
        </author>
        <author>
            <name>Vlad Hondru</name>
        </author>
        <author>
            <name>Radu Tudor Ionescu</name>
        </author>
        <author>
            <name>Mubarak Shah</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Extracting Semantic Knowledge from GANs with Unsupervised Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10081465</id>
        <link href="https://ieeexplore.ieee.org/document/10081465"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recently, unsupervised learning has made impressive progress on various tasks. Despite the dominance of discriminative models, increasing attention is drawn to representations learned by generative models and in particular, Generative Adversarial Networks (GANs). Previous works on the interpretation of GANs reveal that GANs encode semantics in feature maps in a linearly separable form. In this wor...]]></summary>
        <author>
            <name>Jianjin Xu</name>
        </author>
        <author>
            <name>Zhaoxiang Zhang</name>
        </author>
        <author>
            <name>Xiaolin Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Learn Task-Adaptive Hyperparameters for Few-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10080995</id>
        <link href="https://ieeexplore.ieee.org/document/10080995"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The objective of few-shot learning is to design a system that can adapt to a given task with only few examples while achieving generalization. Model-agnostic meta-learning (MAML), which has recently gained the popularity for its simplicity and flexibility, learns a good initialization for fast adaptation to a task under few-data regime. However, its performance has been relatively limited especial...]]></summary>
        <author>
            <name>Sungyong Baik</name>
        </author>
        <author>
            <name>Myungsub Choi</name>
        </author>
        <author>
            <name>Janghoon Choi</name>
        </author>
        <author>
            <name>Heewon Kim</name>
        </author>
        <author>
            <name>Kyoung Mu Lee</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Matrix Completion with Cross-Concentrated Sampling: Bridging Uniform Sampling and CUR Sampling]]></title>
        <id>https://ieeexplore.ieee.org/document/10079176</id>
        <link href="https://ieeexplore.ieee.org/document/10079176"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[While uniform sampling has been widely studied in the matrix completion literature, CUR sampling approximates a low-rank matrix via row and column samples. Unfortunately, both sampling models lack flexibility for various circumstances in real-world applications. In this work, we propose a novel and easy-to-implement sampling strategy, coined Cross-Concentrated Sampling (CCS). By bridging uniform s...]]></summary>
        <author>
            <name>HanQin Cai</name>
        </author>
        <author>
            <name>Longxiu Huang</name>
        </author>
        <author>
            <name>Pengyu Li</name>
        </author>
        <author>
            <name>Deanna Needell</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Face Alignment via Inherent Relation Learning and Uncertainty Estimation]]></title>
        <id>https://ieeexplore.ieee.org/document/10079153</id>
        <link href="https://ieeexplore.ieee.org/document/10079153"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Human tends to locate the facial landmarks with heavy occlusion by their relative position to the easily identified landmarks. The clue is defined as the landmark inherent relation while it is ignored by most existing methods. In this paper, we present Dynamic Sparse Local Patch Transformer (DSLPT), a novel face alignment framework for the inherent relation learning and uncertainty estimation. Unl...]]></summary>
        <author>
            <name>Jiahao Xia</name>
        </author>
        <author>
            <name>Min Xu</name>
        </author>
        <author>
            <name>Haimin Zhang</name>
        </author>
        <author>
            <name>Jianguo Zhang</name>
        </author>
        <author>
            <name>Wenjian Huang</name>
        </author>
        <author>
            <name>Hu Cao</name>
        </author>
        <author>
            <name>Shiping Wen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Training Compact CNNs for Image Classification using Dynamic-coded Filter Fusion]]></title>
        <id>https://ieeexplore.ieee.org/document/10078845</id>
        <link href="https://ieeexplore.ieee.org/document/10078845"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The mainstream approach for filter pruning is usually either to force a hard-coded importance estimation upon a computation-heavy pretrained model to select “important” filters, or to impose a hyperparameter-sensitive sparse constraint on the loss objective to regularize the network training. In this paper, we present a novel filter pruning method, dubbed dynamic-coded filter fusion (DCFF), to der...]]></summary>
        <author>
            <name>Mingbao Lin</name>
        </author>
        <author>
            <name>Bohong Chen</name>
        </author>
        <author>
            <name>Fei Chao</name>
        </author>
        <author>
            <name>Rongrong Ji</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Insights from Generative Modeling for Neural Video Compression]]></title>
        <id>https://ieeexplore.ieee.org/document/10078276</id>
        <link href="https://ieeexplore.ieee.org/document/10078276"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[While recent machine learning research has revealed connections between deep generative models such as VAEs and rate-distortion losses used in learned compression, most of this work has focused on images. In a similar spirit, we view recently proposed neural video coding algorithms through the lens of deep autoregressive and latent variable modeling. We present these codecs as instances of a gener...]]></summary>
        <author>
            <name>Ruihan Yang</name>
        </author>
        <author>
            <name>Yibo Yang</name>
        </author>
        <author>
            <name>Joseph Marino</name>
        </author>
        <author>
            <name>Stephan Mandt</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Guaranteed Tensor Recovery Fused Low-rankness and Smoothness]]></title>
        <id>https://ieeexplore.ieee.org/document/10078018</id>
        <link href="https://ieeexplore.ieee.org/document/10078018"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Vast visual data like multi-spectral images and multi-frame videos are essentially with the tensor format. However, due to the defects of signal acquisition equipments, the practically collected tensor data are always with evident degradations like corruptions or missing values. The tensor data recovery task has thus attracted much research attention in recent years. Solving such an ill-posed prob...]]></summary>
        <author>
            <name>Hailin Wang</name>
        </author>
        <author>
            <name>Jiangjun Peng</name>
        </author>
        <author>
            <name>Wenjin Qin</name>
        </author>
        <author>
            <name>Jianjun Wang</name>
        </author>
        <author>
            <name>Deyu Meng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GeoTransformer: Fast and Robust Point Cloud Registration With Geometric Transformer]]></title>
        <id>https://ieeexplore.ieee.org/document/10076895</id>
        <link href="https://ieeexplore.ieee.org/document/10076895"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We study the problem of extracting accurate correspondences for point cloud registration. Recent keypoint-free methods have shown great potential through bypassing the detection of repeatable keypoints which is difficult to do especially in low-overlap scenarios. They seek correspondences over downsampled superpoints, which are then propagated to dense points. Superpoints are matched based on whet...]]></summary>
        <author>
            <name>Zheng Qin</name>
        </author>
        <author>
            <name>Hao Yu</name>
        </author>
        <author>
            <name>Changjian Wang</name>
        </author>
        <author>
            <name>Yulan Guo</name>
        </author>
        <author>
            <name>Yuxing Peng</name>
        </author>
        <author>
            <name>Slobodan Ilic</name>
        </author>
        <author>
            <name>Dewen Hu</name>
        </author>
        <author>
            <name>Kai Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linear Complexity Self-Attention with $3^{\text{rd}}$ Order Polynomials]]></title>
        <id>https://ieeexplore.ieee.org/document/10076897</id>
        <link href="https://ieeexplore.ieee.org/document/10076897"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Self-attention mechanisms and non-local blocks have become crucial building blocks for state-of-the-art neural architectures thanks to their unparalleled ability in capturing long-range dependencies in the input. However their cost is quadratic with the number of spatial positions hence making their use impractical in many real case applications. In this work, we analyze these methods through a po...]]></summary>
        <author>
            <name>Francesca Babiloni</name>
        </author>
        <author>
            <name>Ioannis Marras</name>
        </author>
        <author>
            <name>Jiankang Deng</name>
        </author>
        <author>
            <name>Filippos Kokkinos</name>
        </author>
        <author>
            <name>Matteo Maggioni</name>
        </author>
        <author>
            <name>Grigorios Chrysos</name>
        </author>
        <author>
            <name>Philip Torr</name>
        </author>
        <author>
            <name>Stefanos Zafeiriou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised 3D Pose Transfer With Cross Consistency and Dual Reconstruction]]></title>
        <id>https://ieeexplore.ieee.org/document/10076900</id>
        <link href="https://ieeexplore.ieee.org/document/10076900"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The goal of 3D pose transfer is to transfer the pose from the source mesh to the target mesh while preserving the identity information (e.g., face, body shape) of the target mesh. Deep learning-based methods improved the efficiency and performance of 3D pose transfer. However, most of them are trained under the supervision of the ground truth, whose availability is limited in real-world scenarios....]]></summary>
        <author>
            <name>Chaoyue Song</name>
        </author>
        <author>
            <name>Jiacheng Wei</name>
        </author>
        <author>
            <name>Ruibo Li</name>
        </author>
        <author>
            <name>Fayao Liu</name>
        </author>
        <author>
            <name>Guosheng Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Rates for Nonconvex Pairwise Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10076835</id>
        <link href="https://ieeexplore.ieee.org/document/10076835"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Pairwise learning is receiving increasing attention since it covers many important machine learning tasks, e.g., metric learning, AUC maximization, and ranking. Investigating the generalization behavior of pairwise learning is thus of great significance. However, existing generalization analysis mainly focuses on the convex objective functions, leaving the nonconvex pairwise learning far less expl...]]></summary>
        <author>
            <name>Shaojie Li</name>
        </author>
        <author>
            <name>Yong Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CoReS: Compatible Representations via Stationarity]]></title>
        <id>https://ieeexplore.ieee.org/document/10077426</id>
        <link href="https://ieeexplore.ieee.org/document/10077426"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Compatible features enable the direct comparison of old and new learned features allowing to use them interchangeably over time. In visual search systems, this eliminates the need to extract new features from the gallery-set when the representation model is upgraded with novel data. This has a big value in real applications as re-indexing the gallery-set can be computationally expensive when the g...]]></summary>
        <author>
            <name>Niccolò Biondi</name>
        </author>
        <author>
            <name>Federico Pernici</name>
        </author>
        <author>
            <name>Matteo Bruni</name>
        </author>
        <author>
            <name>Alberto Del Bimbo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Domain Adaptation of Object Detectors: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10075484</id>
        <link href="https://ieeexplore.ieee.org/document/10075484"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recent advances in deep learning have led to the development of accurate and efficient models for various computer vision applications such as classification, segmentation, and detection. However, learning highly accurate models relies on the availability of large-scale annotated datasets. Due to this, model performance drops drastically when evaluated on label-scarce datasets having visually dist...]]></summary>
        <author>
            <name>Poojan Oza</name>
        </author>
        <author>
            <name>Vishwanath A. Sindagi</name>
        </author>
        <author>
            <name>Vibashan Vishnukumar Sharmini</name>
        </author>
        <author>
            <name>Vishal M. Patel</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Temporal Sentence Grounding in Videos: A Survey and Future Directions]]></title>
        <id>https://ieeexplore.ieee.org/document/10075491</id>
        <link href="https://ieeexplore.ieee.org/document/10075491"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Temporal sentence grounding in videos (TSGV), a.k.a. natural language video localization (NLVL) or video moment retrieval (VMR), aims to retrieve a temporal moment that semantically corresponds to a language query from an untrimmed video. Connecting computer vision and natural language, TSGV has drawn significant attention from researchers in both communities. This survey attempts to provide a sum...]]></summary>
        <author>
            <name>Hao Zhang</name>
        </author>
        <author>
            <name>Aixin Sun</name>
        </author>
        <author>
            <name>Wei Jing</name>
        </author>
        <author>
            <name>Joey Tianyi Zhou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Random Cycle Loss and Its Application to Voice Conversion]]></title>
        <id>https://ieeexplore.ieee.org/document/10073591</id>
        <link href="https://ieeexplore.ieee.org/document/10073591"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Speech disentanglement aims to decompose independent causal factors of speech signals into separate codes. Perfect disentanglement benefits to a broad range of speech processing tasks. This paper presents a simple but effective disentanglement approach based on cycle consistency loss and random factor substitution. This leads to a novel random cycle (RC) loss that enforces analysis-and-resynthesis...]]></summary>
        <author>
            <name>Haoran Sun</name>
        </author>
        <author>
            <name>Dong Wang</name>
        </author>
        <author>
            <name>Lantian Li</name>
        </author>
        <author>
            <name>Chen Chen</name>
        </author>
        <author>
            <name>Thomas Fang Zheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Learning of Graph Matching With Mixture of Modes Via Discrepancy Minimization]]></title>
        <id>https://ieeexplore.ieee.org/document/10073537</id>
        <link href="https://ieeexplore.ieee.org/document/10073537"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Graph matching (GM) has been a long-standing combinatorial problem due to its NP-hard nature. Recently (deep) learning-based approaches have shown their superiority over the traditional solvers while the methods are almost based on supervised learning which can be expensive or even impractical. We develop a unified unsupervised framework from matching two graphs to multiple graphs, without corresp...]]></summary>
        <author>
            <name>Runzhong Wang</name>
        </author>
        <author>
            <name>Junchi Yan</name>
        </author>
        <author>
            <name>Xiaokang Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DAQE: Enhancing the Quality of Compressed Images by Exploiting the Inherent Characteristic of Defocus]]></title>
        <id>https://ieeexplore.ieee.org/document/10073543</id>
        <link href="https://ieeexplore.ieee.org/document/10073543"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Image defocus is inherent in the physics of image formation caused by the optical aberration of lenses, providing plentiful information on image quality. Unfortunately, existing quality enhancement approaches for compressed images neglect the inherent characteristic of defocus, resulting in inferior performance. This paper finds that in compressed images, significantly defocused regions have bette...]]></summary>
        <author>
            <name>Qunliang Xing</name>
        </author>
        <author>
            <name>Mai Xu</name>
        </author>
        <author>
            <name>Xin Deng</name>
        </author>
        <author>
            <name>Yichen Guo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Online Knowledge Distillation Via Mutual Contrastive Learning for Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10073628</id>
        <link href="https://ieeexplore.ieee.org/document/10073628"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The teacher-free online Knowledge Distillation (KD) aims to train an ensemble of multiple student models collaboratively and distill knowledge from each other. Although existing online KD methods achieve desirable performance, they often focus on class probabilities as the core knowledge type, ignoring the valuable feature representational information. We present a Mutual Contrastive Learning (MCL...]]></summary>
        <author>
            <name>Chuanguang Yang</name>
        </author>
        <author>
            <name>Zhulin An</name>
        </author>
        <author>
            <name>Helong Zhou</name>
        </author>
        <author>
            <name>Fuzhen Zhuang</name>
        </author>
        <author>
            <name>Yongjun Xu</name>
        </author>
        <author>
            <name>Qian Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Brain-Machine Coupled Learning Method for Facial Emotion Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10073607</id>
        <link href="https://ieeexplore.ieee.org/document/10073607"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Neural network models of machine learning have shown promising prospects for visual tasks, such as facial emotion recognition (FER). However, the generalization of the model trained from a dataset with a few samples is limited. Unlike the machine, the human brain can effectively realize the required information from a few samples to complete the visual tasks. To learn the generalization ability of...]]></summary>
        <author>
            <name>Dongjun Liu</name>
        </author>
        <author>
            <name>Weichen Dai</name>
        </author>
        <author>
            <name>Hangkui Zhang</name>
        </author>
        <author>
            <name>Xuanyu Jin</name>
        </author>
        <author>
            <name>Jianting Cao</name>
        </author>
        <author>
            <name>Wanzeng Kong</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Affine Subspace Robust Low-Rank Self-Representation: from Matrix to Tensor]]></title>
        <id>https://ieeexplore.ieee.org/document/10070813</id>
        <link href="https://ieeexplore.ieee.org/document/10070813"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Low-rank self-representation based subspace learning has confirmed its great effectiveness in a broad range of applications. Nevertheless, existing studies mainly focus on exploring the global linear subspace structure, and cannot commendably handle the case where the samples approximately (i.e., the samples contain data errors) lie in several more general affine subspaces. To overcome this drawba...]]></summary>
        <author>
            <name>Yongqiang Tang</name>
        </author>
        <author>
            <name>Yuan Xie</name>
        </author>
        <author>
            <name>Wensheng Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When Object Detection Meets Knowledge Distillation: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10070820</id>
        <link href="https://ieeexplore.ieee.org/document/10070820"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Object detection (OD) is a basic computer vision task. To date, there have been many OD algorithms or models for solving different problems. The performance of the current models has gradually improved and their applications have expanded. However, the models have also become more complex, with larger numbers of parameters, making them unsuitable for industrial applications. The knowledge distilla...]]></summary>
        <author>
            <name>Zhihui Li</name>
        </author>
        <author>
            <name>Pengfei Xu</name>
        </author>
        <author>
            <name>Xiaojun Chang</name>
        </author>
        <author>
            <name>Luyao Yang</name>
        </author>
        <author>
            <name>Yuanyuan Zhang</name>
        </author>
        <author>
            <name>Lina Yao</name>
        </author>
        <author>
            <name>Xiaojiang Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics-Informed Guided Disentanglement In generative networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10070869</id>
        <link href="https://ieeexplore.ieee.org/document/10070869"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Image-to-image translation (i2i) networks suffer from entanglement effects in presence of physics-related phenomena in target domain (such as occlusions, fog, etc), lowering altogether the translation quality, controllability and variability. In this paper, we propose a general framework to disentangle visual traits in target images. Primarily, we build upon collection of simple physics models, gu...]]></summary>
        <author>
            <name>Fabio Pizzati</name>
        </author>
        <author>
            <name>Pietro Cerri</name>
        </author>
        <author>
            <name>Raoul de Charette</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning with Asymmetric Kernels: Least Squares and Feature Interpretation]]></title>
        <id>https://ieeexplore.ieee.org/document/10070836</id>
        <link href="https://ieeexplore.ieee.org/document/10070836"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Asymmetric kernels naturally exist in real life, e.g., for conditional probability and directed graphs. However, most of the existing kernel-based learning methods require kernels to be symmetric, which prevents the use of asymmetric kernels. This paper addresses the asymmetric kernel-based learning in the framework of the least squares support vector machine named AsK-LS, resulting in the first c...]]></summary>
        <author>
            <name>Mingzhen He</name>
        </author>
        <author>
            <name>Fan He</name>
        </author>
        <author>
            <name>Lei Shi</name>
        </author>
        <author>
            <name>Xiaolin Huang</name>
        </author>
        <author>
            <name>Johan A.K. Suykens</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Theory Based Large-Scale Machine Learning with Multi-Dimensional Constrained Optimization Approaches for Exact Epidemiological Modelling of Pandemic Diseases]]></title>
        <id>https://ieeexplore.ieee.org/document/10068311</id>
        <link href="https://ieeexplore.ieee.org/document/10068311"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Multi-dimensional prediction models of the pandemic diseases should be constructed in a way to reflect their peculiar epidemiological characters. In this paper, a graph theory-based constrained multi-dimensional (CM) mathematical and meta-heuristic algorithms (MA) are formed to learn the unknown parameters of a large-scale epidemiological model. The specified parameter signs and the coupling param...]]></summary>
        <author>
            <name>Onder Tutsoy</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast and Informative Model Selection using Learning Curve Cross-Validation]]></title>
        <id>https://ieeexplore.ieee.org/document/10064171</id>
        <link href="https://ieeexplore.ieee.org/document/10064171"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Common cross-validation (CV) methods like k-fold cross-validation or Monte Carlo cross-validation estimate the predictive performance of a learner by repeatedly training it on a large portion of the given data and testing it on the remaining data. These techniques have two major drawbacks. First, they can be unnecessarily slow on large datasets. Second, beyond an estimation of the final performanc...]]></summary>
        <author>
            <name>Felix Mohr</name>
        </author>
        <author>
            <name>Jan N. van Rijn</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Free-HeadGAN: Neural Talking Head Synthesis with Explicit Gaze Control]]></title>
        <id>https://ieeexplore.ieee.org/document/10061572</id>
        <link href="https://ieeexplore.ieee.org/document/10061572"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We present Free-HeadGAN, a person-generic neural talking head synthesis system. We show that modeling faces with sparse 3D facial landmarks is sufficient for achieving state-of-the-art generative performance, without relying on strong statistical priors of the face, such as 3D Morphable Models. Apart from 3D pose and facial expressions, our method is capable of fully transferring the eye gaze, fro...]]></summary>
        <author>
            <name>Michail Christos Doukas</name>
        </author>
        <author>
            <name>Evangelos Ververas</name>
        </author>
        <author>
            <name>Viktoriia Sharmanska</name>
        </author>
        <author>
            <name>Stefanos Zafeiriou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Jointly Defending DeepFake Manipulation and Adversarial Attack using Decoy Mechanism]]></title>
        <id>https://ieeexplore.ieee.org/document/10061274</id>
        <link href="https://ieeexplore.ieee.org/document/10061274"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Highly realistic imaging and video synthesis have become possible and relatively simple tasks with the rapid growth of generative adversarial networks (GANs). GAN-related applications, such as DeepFake image and video manipulation and adversarial attacks, have been used to disrupt and confound the truth in images and videos over social media. DeepFake technology aims to synthesize high visual qual...]]></summary>
        <author>
            <name>Guan-Lin Chen</name>
        </author>
        <author>
            <name>Chih-Chung Hsu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Multi-View Kernel Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10061269</id>
        <link href="https://ieeexplore.ieee.org/document/10061269"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Kernel method is a proven technique in multi-view learning. It implicitly defines a Hilbert space where samples can be linearly separated. Most kernel-based multi-view learning algorithms compute a kernel function aggregating and compressing the views into a single kernel. However, existing approaches compute the kernels independently for each view. This ignores complementary information across vi...]]></summary>
        <author>
            <name>Jiyuan Liu</name>
        </author>
        <author>
            <name>Xinwang Liu</name>
        </author>
        <author>
            <name>Yuexiang Yang</name>
        </author>
        <author>
            <name>Qing Liao</name>
        </author>
        <author>
            <name>Yuanqing Xia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Clustered Task-Aware Meta-Learning by Learning From Learning Paths]]></title>
        <id>https://ieeexplore.ieee.org/document/10061493</id>
        <link href="https://ieeexplore.ieee.org/document/10061493"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[To enable effective learning of new tasks with only a few examples, meta-learning acquires common knowledge from the existing tasks with a globally shared meta-learner. To further address the problem of task heterogeneity, recent developments balance between customization and generalization by incorporating task clustering to generate task-aware modulation to be applied to the global meta-learner....]]></summary>
        <author>
            <name>Danni Peng</name>
        </author>
        <author>
            <name>Sinno Jialin Pan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Persistent Homology with Improved Locality Information for more Effective Delineation]]></title>
        <id>https://ieeexplore.ieee.org/document/10057132</id>
        <link href="https://ieeexplore.ieee.org/document/10057132"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Persistent Homology (PH) has been successfully used to train networks to detect curvilinear structures and to improve the topological quality of their results. However, existing methods are very global and ignore the location of topological features. In this paper, we remedy this by introducing a new filtration function that fuses two earlier approaches: thresholding-based filtration, previously u...]]></summary>
        <author>
            <name>Doruk Oner</name>
        </author>
        <author>
            <name>Adélie Garin</name>
        </author>
        <author>
            <name>Mateusz Koziński</name>
        </author>
        <author>
            <name>Kathryn Hess</name>
        </author>
        <author>
            <name>Pascal Fua</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Low-Rank Matrix Completion Theory via Plücker Coordinates]]></title>
        <id>https://ieeexplore.ieee.org/document/10056236</id>
        <link href="https://ieeexplore.ieee.org/document/10056236"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Despite the popularity of low-rank matrix completion, the majority of its theory has been developed under the assumption of random observation patterns, whereas very little is known about the practically relevant case of non-random patterns. Specifically, a fundamental yet largely open question is to describe patterns that allow for unique or finitely many completions. This paper provides three su...]]></summary>
        <author>
            <name>Manolis C. Tsakiris</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Normalization Techniques in Training DNNs: Methodology, Analysis and Application]]></title>
        <id>https://ieeexplore.ieee.org/document/10056354</id>
        <link href="https://ieeexplore.ieee.org/document/10056354"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Normalization techniques are essential for accelerating the training and improving the generalization of deep neural networks (DNNs), and have successfully been used in various applications. This paper reviews and comments on the past, present and future of normalization methods in the context of DNN training. We provide a unified picture of the main motivation behind different approaches from the...]]></summary>
        <author>
            <name>Lei Huang</name>
        </author>
        <author>
            <name>Jie Qin</name>
        </author>
        <author>
            <name>Yi Zhou</name>
        </author>
        <author>
            <name>Fan Zhu</name>
        </author>
        <author>
            <name>Li Liu</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Augmentation Pathways Network for Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10056356</id>
        <link href="https://ieeexplore.ieee.org/document/10056356"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Data augmentation is practically helpful for visual recognition, especially at the time of data scarcity. However, such success is only limited to quite a few light augmentations (e.g., random crop, flip). Heavy augmentations are either unstable or show adverse effects during training, owing to the big gap between the original and augmented images. This paper introduces a novel network design, not...]]></summary>
        <author>
            <name>Yalong Bai</name>
        </author>
        <author>
            <name>Mohan Zhou</name>
        </author>
        <author>
            <name>Wei Zhang</name>
        </author>
        <author>
            <name>Bowen Zhou</name>
        </author>
        <author>
            <name>Tao Mei</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PDC-Net+: Enhanced Probabilistic Dense Correspondence Network]]></title>
        <id>https://ieeexplore.ieee.org/document/10054148</id>
        <link href="https://ieeexplore.ieee.org/document/10054148"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Establishing robust and accurate correspondences between a pair of images is a long-standing computer vision problem with numerous applications. While classically dominated by sparse methods, emerging dense approaches offer a compelling alternative paradigm that avoids the keypoint detection step. However, dense flow estimation is often inaccurate in the case of large displacements, occlusions, or...]]></summary>
        <author>
            <name>Prune Truong</name>
        </author>
        <author>
            <name>Martin Danelljan</name>
        </author>
        <author>
            <name>Radu Timofte</name>
        </author>
        <author>
            <name>Luc Van Gool</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Personalized Latent Structure Learning for Recommendation]]></title>
        <id>https://ieeexplore.ieee.org/document/10053625</id>
        <link href="https://ieeexplore.ieee.org/document/10053625"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In recommender systems, users&#39; behavior data are driven by the interactions of user-item latent factors. To improve recommendation effectiveness and robustness, recent advances focus on latent factor disentanglement via variational inference. Despite significant progress, uncovering the underlying interactions, i.e., dependencies of latent factors, remains largely neglected by the literature. To b...]]></summary>
        <author>
            <name>Shengyu Zhang</name>
        </author>
        <author>
            <name>Fuli Feng</name>
        </author>
        <author>
            <name>Kun Kuang</name>
        </author>
        <author>
            <name>Wenqiao Zhang</name>
        </author>
        <author>
            <name>Zhou Zhao</name>
        </author>
        <author>
            <name>Hongxia Yang</name>
        </author>
        <author>
            <name>Tat-Seng Chua</name>
        </author>
        <author>
            <name>Fei Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Localization Distillation for Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10052761</id>
        <link href="https://ieeexplore.ieee.org/document/10052761"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Previous knowledge distillation (KD) methods for object detection mostly focus on feature imitation instead of mimicking the prediction logits due to its inefficiency in distilling the localization information. In this paper, we investigate whether logit mimicking always lags behind feature imitation. Towards this goal, we first present a novel localization distillation (LD) method which can effic...]]></summary>
        <author>
            <name>Zhaohui Zheng</name>
        </author>
        <author>
            <name>Rongguang Ye</name>
        </author>
        <author>
            <name>Qibin Hou</name>
        </author>
        <author>
            <name>Dongwei Ren</name>
        </author>
        <author>
            <name>Ping Wang</name>
        </author>
        <author>
            <name>Wangmeng Zuo</name>
        </author>
        <author>
            <name>Ming-Ming Cheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Search-and-Training for Robust and Efficient Network Pruning]]></title>
        <id>https://ieeexplore.ieee.org/document/10052756</id>
        <link href="https://ieeexplore.ieee.org/document/10052756"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Both network pruning and neural architecture search (NAS) can be interpreted as techniques to automate the design and optimization of artificial neural networks. In this paper, we challenge the conventional wisdom of training before pruning by proposing a joint search-and-training approach to learn a compact network directly from scratch. Using pruning as a search strategy, we advocate three new i...]]></summary>
        <author>
            <name>Xiaotong Lu</name>
        </author>
        <author>
            <name>Weisheng Dong</name>
        </author>
        <author>
            <name>Xin Li</name>
        </author>
        <author>
            <name>Jinjian Wu</name>
        </author>
        <author>
            <name>Leida Li</name>
        </author>
        <author>
            <name>Guangming Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ADPL: Adaptive Dual Path Learning for Domain Adaptation of Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10050808</id>
        <link href="https://ieeexplore.ieee.org/document/10050808"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[To alleviate the need for large-scale pixel-wise annotations, domain adaptation for semantic segmentation trains segmentation models on synthetic data (source) with computer-generated annotations, which can be then generalized to segment realistic images (target). Recently, self-supervised learning (SSL) with a combination of image-to-image translation shows great effectiveness in adaptive segment...]]></summary>
        <author>
            <name>Yiting Cheng</name>
        </author>
        <author>
            <name>Fangyun Wei</name>
        </author>
        <author>
            <name>Jianmin Bao</name>
        </author>
        <author>
            <name>Dong Chen</name>
        </author>
        <author>
            <name>Wenqiang Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Drug Synergy Prediction With a Prior-Guided Hypernetwork Architecture]]></title>
        <id>https://ieeexplore.ieee.org/document/10050784</id>
        <link href="https://ieeexplore.ieee.org/document/10050784"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Predicting drug synergy is critical to tailoring feasible drug combination treatment regimens for cancer patients. However, most of the existing computational methods only focus on data-rich cell lines, and hardly work on data-poor cell lines. To this end, here we proposed a novel few-shot drug synergy prediction method (called HyperSynergy) for data-poor cell lines by designing a prior-guided Hyp...]]></summary>
        <author>
            <name>Qingqing Zhang</name>
        </author>
        <author>
            <name>Shaowu Zhang</name>
        </author>
        <author>
            <name>Yuehua Feng</name>
        </author>
        <author>
            <name>Jianyu Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast and Robust Non-Rigid Registration Using Accelerated Majorization-Minimization]]></title>
        <id>https://ieeexplore.ieee.org/document/10049724</id>
        <link href="https://ieeexplore.ieee.org/document/10049724"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Non-rigid 3D registration, which deforms a source 3D shape in a non-rigid way to align with a target 3D shape, is a classical problem in computer vision. Such problems can be challenging because of imperfect data (noise, outliers and partial overlap) and high degrees of freedom. Existing methods typically adopt the $\ell _{p}$ type robust norm to measure the alignment error and regularize the smoo...]]></summary>
        <author>
            <name>Yuxin Yao</name>
        </author>
        <author>
            <name>Bailin Deng</name>
        </author>
        <author>
            <name>Weiwei Xu</name>
        </author>
        <author>
            <name>Juyong Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Consistent 3D Hand Reconstruction in Video via Self-Supervised Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10050006</id>
        <link href="https://ieeexplore.ieee.org/document/10050006"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We present a method for reconstructing accurate and consistent 3D hands from a monocular video. We observe that the detected 2D hand keypoints and the image texture provide important cues about the geometry and texture of the 3D hand, which can reduce or even eliminate the requirement on 3D hand annotation. Accordingly, in this work, we propose $\mathrm{{S}^{2}HAND}$, a self-supervised 3D hand rec...]]></summary>
        <author>
            <name>Zhigang Tu</name>
        </author>
        <author>
            <name>Zhisheng Huang</name>
        </author>
        <author>
            <name>Yujin Chen</name>
        </author>
        <author>
            <name>Di Kang</name>
        </author>
        <author>
            <name>Linchao Bao</name>
        </author>
        <author>
            <name>Bisheng Yang</name>
        </author>
        <author>
            <name>Junsong Yuan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Augment Poses for 3D Human Pose Estimation in Images and Videos]]></title>
        <id>https://ieeexplore.ieee.org/document/10050391</id>
        <link href="https://ieeexplore.ieee.org/document/10050391"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Existing 3D human pose estimation methods often suffer inferior generalization performance to new datasets, largely due to the limited diversity of 2D-3D pose pairs in the training data. To address this problem, we present PoseAug, a novel auto-augmentation framework that learns to augment the available training poses towards greater diversity and thus enhances the generalization power of the trai...]]></summary>
        <author>
            <name>Jianfeng Zhang</name>
        </author>
        <author>
            <name>Kehong Gong</name>
        </author>
        <author>
            <name>Xinchao Wang</name>
        </author>
        <author>
            <name>Jiashi Feng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Latent Class-Conditional Noise Model]]></title>
        <id>https://ieeexplore.ieee.org/document/10049697</id>
        <link href="https://ieeexplore.ieee.org/document/10049697"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Learning with noisy labels has become imperative in the Big Data era, which saves expensive human labors on accurate annotations. Previous noise-transition-based methods have achieved theoretically-grounded performance under the Class-Conditional Noise model (CCN). However, these approaches builds upon an ideal but impractical anchor set available to pre-estimate the noise transition. Even though ...]]></summary>
        <author>
            <name>Jiangchao Yao</name>
        </author>
        <author>
            <name>Bo Han</name>
        </author>
        <author>
            <name>Zhihan Zhou</name>
        </author>
        <author>
            <name>Ya Zhang</name>
        </author>
        <author>
            <name>Ivor W. Tsang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cross-Modal Retrieval with Partially Mismatched Pairs]]></title>
        <id>https://ieeexplore.ieee.org/document/10050111</id>
        <link href="https://ieeexplore.ieee.org/document/10050111"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this paper, we study a challenging but less-touched problem in cross-modal retrieval, i.e., partially mismatched pairs (PMPs). Specifically, in real-world scenarios, a huge number of multimedia data (e.g., the Conceptual Captions dataset) are collected from the Internet, and thus it is inevitable to wrongly treat some irrelevant cross-modal pairs as matched. Undoubtedly, such a PMP problem will...]]></summary>
        <author>
            <name>Peng Hu</name>
        </author>
        <author>
            <name>Zhenyu Huang</name>
        </author>
        <author>
            <name>Dezhong Peng</name>
        </author>
        <author>
            <name>Xu Wang</name>
        </author>
        <author>
            <name>Xi Peng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Nested Dropout]]></title>
        <id>https://ieeexplore.ieee.org/document/10049079</id>
        <link href="https://ieeexplore.ieee.org/document/10049079"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Nested dropout  is a variant of dropout operation that is able to order network parameters or features based on the pre-defined importance during training. It has been explored for: I. Constructing nested nets [11], [10]: the nested nets are neural networks whose architectures can be adjusted instantly during testing time, e.g., based on computational constraints. The nested dropout implicitly ran...]]></summary>
        <author>
            <name>Yufei Cui</name>
        </author>
        <author>
            <name>Yu Mao</name>
        </author>
        <author>
            <name>Ziquan Liu</name>
        </author>
        <author>
            <name>Qiao Li</name>
        </author>
        <author>
            <name>Antoni B. Chan</name>
        </author>
        <author>
            <name>Xue Liu</name>
        </author>
        <author>
            <name>Tei-Wei Kuo</name>
        </author>
        <author>
            <name>Chun Jason Xue</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey on Label-Efficient Deep Image Segmentation: Bridging the Gap Between Weak Supervision and Dense Prediction]]></title>
        <id>https://ieeexplore.ieee.org/document/10048555</id>
        <link href="https://ieeexplore.ieee.org/document/10048555"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The rapid development of deep learning has made a great progress in image segmentation, one of the fundamental tasks of computer vision. However, the current segmentation algorithms mostly rely on the availability of pixel-level annotations, which are often expensive, tedious, and laborious. To alleviate this burden, the past years have witnessed an increasing attention in building label-efficient...]]></summary>
        <author>
            <name>Wei Shen</name>
        </author>
        <author>
            <name>Zelin Peng</name>
        </author>
        <author>
            <name>Xuehui Wang</name>
        </author>
        <author>
            <name>Huayu Wang</name>
        </author>
        <author>
            <name>Jiazhong Cen</name>
        </author>
        <author>
            <name>Dongsheng Jiang</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Xiaokang Yang</name>
        </author>
        <author>
            <name>Q. Tian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Occlusion-Aware Instance Segmentation Via BiLayer Network Architectures]]></title>
        <id>https://ieeexplore.ieee.org/document/10048550</id>
        <link href="https://ieeexplore.ieee.org/document/10048550"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Segmenting highly-overlapping image objects is challenging, because there is typically no distinction between real object contours and occlusion boundaries on images. Unlike previous instance segmentation methods, we model image formation as a composition of two overlapping layers, and propose Bilayer Convolutional Network (BCNet), where the top layer detects occluding objects (occluders) and the ...]]></summary>
        <author>
            <name>Lei Ke</name>
        </author>
        <author>
            <name>Yu-Wing Tai</name>
        </author>
        <author>
            <name>Chi-Keung Tang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Handling Open-set Noise and Novel Target Recognition in Domain Adaptive Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10048580</id>
        <link href="https://ieeexplore.ieee.org/document/10048580"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[This paper studies a practical domain adaptive (DA) semantic segmentation problem where only pseudo-labeled target data is accessible through a black-box model. Due to the domain gap and label shift between two domains, pseudo-labeled target data contains mixed closed-set and open-set label noises. In this paper, we propose a simplex noise transition matrix (SimT) to model the mixed noise distribu...]]></summary>
        <author>
            <name>Xiaoqing Guo</name>
        </author>
        <author>
            <name>Jie Liu</name>
        </author>
        <author>
            <name>Tongliang Liu</name>
        </author>
        <author>
            <name>Yixuan Yuan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Neural Representations with Structured Latent Codes for Human Body Modeling]]></title>
        <id>https://ieeexplore.ieee.org/document/10045794</id>
        <link href="https://ieeexplore.ieee.org/document/10045794"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[This paper addresses the challenge of novel view synthesis for a human performer from a very sparse set of camera views. Some recent works have shown that learning implicit neural representations of 3D scenes achieves remarkable view synthesis quality given dense input views. However, the representation learning will be ill-posed if the views are highly sparse. To solve this ill-posed problem, our...]]></summary>
        <author>
            <name>Sida Peng</name>
        </author>
        <author>
            <name>Chen Geng</name>
        </author>
        <author>
            <name>Yuanqing Zhang</name>
        </author>
        <author>
            <name>Yinghao Xu</name>
        </author>
        <author>
            <name>Qianqian Wang</name>
        </author>
        <author>
            <name>Qing Shuai</name>
        </author>
        <author>
            <name>Xiaowei Zhou</name>
        </author>
        <author>
            <name>Hujun Bao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multifractal Characterization of Texts for Pattern Recognition: on the Complexity of Morphological Structures in Modern and Ancient Languages]]></title>
        <id>https://ieeexplore.ieee.org/document/10045797</id>
        <link href="https://ieeexplore.ieee.org/document/10045797"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The study of languages&#39; structure and their organization in a set of well-defined relation schemes is a delicate matter. In the last decades, the convergence of traditional conflicting views by linguists is supported by an interdisciplinary approach that involves not only genetics or bio-archelogy but nowadays even the science of complexity. In light of this new and useful approach, this study pro...]]></summary>
        <author>
            <name>Enrico De Santis</name>
        </author>
        <author>
            <name>Giovanni De Santis</name>
        </author>
        <author>
            <name>Antonello Rizzi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud Analysis]]></title>
        <id>https://ieeexplore.ieee.org/document/10044160</id>
        <link href="https://ieeexplore.ieee.org/document/10044160"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Point clouds are characterized by irregularity and unstructuredness, which pose challenges in efficient data exploitation and discriminative feature extraction. In this paper, we present an unsupervised deep neural architecture called Flattening-Net to represent irregular 3D point clouds of arbitrary geometry and topology as a completely regular 2D point geometry image (PGI) structure, in which co...]]></summary>
        <author>
            <name>Qijian Zhang</name>
        </author>
        <author>
            <name>Junhui Hou</name>
        </author>
        <author>
            <name>Yue Qian</name>
        </author>
        <author>
            <name>Yiming Zeng</name>
        </author>
        <author>
            <name>Juyong Zhang</name>
        </author>
        <author>
            <name>Ying He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RoReg: Pairwise Point Cloud Registration with Oriented Descriptors and Local Rotations]]></title>
        <id>https://ieeexplore.ieee.org/document/10044259</id>
        <link href="https://ieeexplore.ieee.org/document/10044259"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We present RoReg, a novel point cloud registration framework that fully exploits oriented descriptors and estimated local rotations in the whole registration pipeline. Previous methods mainly focus on extracting rotation-invariant descriptors for registration but unanimously neglect the orientations of descriptors. In this paper, we show that the oriented descriptors and the estimated local rotati...]]></summary>
        <author>
            <name>Haiping Wang</name>
        </author>
        <author>
            <name>Yuan Liu</name>
        </author>
        <author>
            <name>Qingyong Hu</name>
        </author>
        <author>
            <name>Bing Wang</name>
        </author>
        <author>
            <name>Jianguo Chen</name>
        </author>
        <author>
            <name>Zhen Dong</name>
        </author>
        <author>
            <name>Yulan Guo</name>
        </author>
        <author>
            <name>Wenping Wang</name>
        </author>
        <author>
            <name>Bisheng Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MILO: Multi-bounce Inverse Rendering for Indoor Scene with Light-emitting Objects]]></title>
        <id>https://ieeexplore.ieee.org/document/10043749</id>
        <link href="https://ieeexplore.ieee.org/document/10043749"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recently, many advances in inverse rendering are achieved by high-dimensional lighting representations and differentiable rendering. However, multi-bounce lighting effects can hardly be handled correctly in scene editing using high-dimensional lighting representations, and light source model deviation and ambiguities exist in differentiable rendering methods. These problems limit the applications ...]]></summary>
        <author>
            <name>Bohan Yu</name>
        </author>
        <author>
            <name>Siqi Yang</name>
        </author>
        <author>
            <name>Xuanning Cui</name>
        </author>
        <author>
            <name>Siyan Dong</name>
        </author>
        <author>
            <name>Baoquan Chen</name>
        </author>
        <author>
            <name>Boxin Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-supervised Video-centralised Transformer for Video Face Clustering]]></title>
        <id>https://ieeexplore.ieee.org/document/10042051</id>
        <link href="https://ieeexplore.ieee.org/document/10042051"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[This paper presents a novel method for face clustering in videos using a video-centralised transformer. Previous works often employed contrastive learning to learn frame-level representation and used average pooling to aggregate the features along the temporal dimension. This approach may not fully capture the complicated video dynamics. In addition, despite the recent progress in video-based cont...]]></summary>
        <author>
            <name>Yujiang Wang</name>
        </author>
        <author>
            <name>Mingzhi Dong</name>
        </author>
        <author>
            <name>Jie Shen</name>
        </author>
        <author>
            <name>Yiming Luo</name>
        </author>
        <author>
            <name>Yiming Lin</name>
        </author>
        <author>
            <name>Pingchuan Ma</name>
        </author>
        <author>
            <name>Stavros Petridis</name>
        </author>
        <author>
            <name>Maja Pantic</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances]]></title>
        <id>https://ieeexplore.ieee.org/document/10041995</id>
        <link href="https://ieeexplore.ieee.org/document/10041995"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[With the advent of Deep Learning (DL), Super-Resolution (SR) has also become a thriving research area. However, despite promising results, the field still faces challenges that require further research, e.g., allowing flexible upsampling, more effective loss functions, and better evaluation metrics. We review the domain of SR in light of recent advances and examine state-of-the-art models such as ...]]></summary>
        <author>
            <name>Brian B. Moser</name>
        </author>
        <author>
            <name>Federico Raue</name>
        </author>
        <author>
            <name>Stanislav Frolov</name>
        </author>
        <author>
            <name>Sebastian Palacio</name>
        </author>
        <author>
            <name>Jörn Hees</name>
        </author>
        <author>
            <name>Andreas Dengel</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Instance to Metric Calibration: A Unified Framework for Open-World Few-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10041935</id>
        <link href="https://ieeexplore.ieee.org/document/10041935"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Robust few-shot learning (RFSL), which aims to address noisy labels in few-shot learning, has recently gained considerable attention. Existing RFSL methods are based on the assumption that the noise comes from known classes (in-domain), which is inconsistent with many real-world scenarios where the noise does not belong to any known classes (out-of-domain). We refer to this more complex scenario a...]]></summary>
        <author>
            <name>Yuexuan An</name>
        </author>
        <author>
            <name>Hui Xue</name>
        </author>
        <author>
            <name>Xingyu Zhao</name>
        </author>
        <author>
            <name>Jing Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Tractable Maximum Likelihood Estimation for Latent Structure Influence Models with Applications to EEG & ECoG processing]]></title>
        <id>https://ieeexplore.ieee.org/document/10042041</id>
        <link href="https://ieeexplore.ieee.org/document/10042041"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Brain signals are nonlinear and nonstationary time series, which provide information about spatiotemporal patterns of electrical activity in the brain. CHMMs are suitable tools for modeling multi-channel time-series dependent on both time and space, but state-space parameters grow exponentially with the number of channels. To cope with this limitation, we consider the influence model as the intera...]]></summary>
        <author>
            <name>Sajjad Karimi</name>
        </author>
        <author>
            <name>Mohammad Bagher Shamsollahi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Video Transformers: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/10041724</id>
        <link href="https://ieeexplore.ieee.org/document/10041724"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Transformer models have shown great success handling long-range interactions, making them a promising tool for modeling video. However, they lack inductive biases and scale quadratically with input length. These limitations are further exacerbated when dealing with the high dimensionality introduced by the temporal dimension. While there are surveys analyzing the advances of Transformers for visio...]]></summary>
        <author>
            <name>Javier Selva</name>
        </author>
        <author>
            <name>Anders S. Johansen</name>
        </author>
        <author>
            <name>Sergio Escalera</name>
        </author>
        <author>
            <name>Kamal Nasrollahi</name>
        </author>
        <author>
            <name>Thomas B. Moeslund</name>
        </author>
        <author>
            <name>Albert Clapés</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Image-to-Character-to-Word Transformers for Accurate Scene Text Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10041804</id>
        <link href="https://ieeexplore.ieee.org/document/10041804"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Leveraging the advances of natural language processing, most recent scene text recognizers adopt an encoder-decoder architecture where text images are first converted to representative features and then a sequence of characters via ‘sequential decoding’. However, scene text images suffer from rich noises of different sources such as complex background and geometric distortions which often confuse ...]]></summary>
        <author>
            <name>Chuhui Xue</name>
        </author>
        <author>
            <name>Jiaxing Huang</name>
        </author>
        <author>
            <name>Wenqing Zhang</name>
        </author>
        <author>
            <name>Shijian Lu</name>
        </author>
        <author>
            <name>Changhu Wang</name>
        </author>
        <author>
            <name>Song Bai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contextual Instance Decoupling for Instance-Level Human Analysis]]></title>
        <id>https://ieeexplore.ieee.org/document/10040902</id>
        <link href="https://ieeexplore.ieee.org/document/10040902"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[One fundamental challenge of instance-level human analysis is to decouple instances in crowded scenes, where multiple persons are overlapped with each other. This paper proposes the Contextual Instance Decoupling (CID), which presents a new pipeline of decoupling persons for multi-person instance-level analysis. Instead of relying on person bounding boxes to spatially differentiate persons, CID de...]]></summary>
        <author>
            <name>Dongkai Wang</name>
        </author>
        <author>
            <name>Shiliang Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Belief Propagation for Scene Graph Generation]]></title>
        <id>https://ieeexplore.ieee.org/document/10040751</id>
        <link href="https://ieeexplore.ieee.org/document/10040751"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Scene graph generation aims to interpret an input image by explicitly modelling the objects contained therein and their relationships. In existing methods the problem is predominantly solved by message passing neural network models. Unfortunately, in such models, the variational distributions generally ignore the structural dependencies among the output variables, and most of the scoring functions...]]></summary>
        <author>
            <name>Daqi Liu</name>
        </author>
        <author>
            <name>Miroslaw Bober</name>
        </author>
        <author>
            <name>Josef Kittler</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Coarse-to-fine Disentangling Demoiréing Framework for Recaptured Screen Images]]></title>
        <id>https://ieeexplore.ieee.org/document/10040914</id>
        <link href="https://ieeexplore.ieee.org/document/10040914"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Removing the undesired moiré patterns from images capturing the contents displayed on screens is of increasing research interest, as the need for recording and sharing the instant information conveyed by the screens is growing. Previous demoiréing methods provide limited investigations into the formation process of moiré patterns to exploit moiré-specific priors for guiding the learning of demoiré...]]></summary>
        <author>
            <name>Ce Wang</name>
        </author>
        <author>
            <name>Bin He</name>
        </author>
        <author>
            <name>Shengsen Wu</name>
        </author>
        <author>
            <name>Renjie Wan</name>
        </author>
        <author>
            <name>Boxin Shi</name>
        </author>
        <author>
            <name>Ling-Yu Duan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Asymmetric Loss Functions for Noise-Tolerant Learning: Theory and Applications]]></title>
        <id>https://ieeexplore.ieee.org/document/10039708</id>
        <link href="https://ieeexplore.ieee.org/document/10039708"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Supervised deep learning has achieved tremendous success in many computer vision tasks, which however is prone to overfit noisy labels. To mitigate the undesirable influence of noisy labels, robust loss functions offer a feasible approach to achieve noise-tolerant learning. In this work, we systematically study the problem of noise-tolerant learning with respect to both classification and regressi...]]></summary>
        <author>
            <name>Xiong Zhou</name>
        </author>
        <author>
            <name>Xianming Liu</name>
        </author>
        <author>
            <name>Deming Zhai</name>
        </author>
        <author>
            <name>Junjun Jiang</name>
        </author>
        <author>
            <name>Xiangyang Ji</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SequenceMorph: A Unified Unsupervised Learning Framework for Motion Tracking on Cardiac Image Sequences]]></title>
        <id>https://ieeexplore.ieee.org/document/10039678</id>
        <link href="https://ieeexplore.ieee.org/document/10039678"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Modern medical imaging techniques, such as ultrasound (US) and cardiac magnetic resonance (MR) imaging, have enabled the evaluation of myocardial deformation directly from an image sequence. While many traditional cardiac motion tracking methods have been developed for the automated estimation of the myocardial wall deformation, they are not widely used in clinical diagnosis, due to their lack of ...]]></summary>
        <author>
            <name>Meng Ye</name>
        </author>
        <author>
            <name>Dong Yang</name>
        </author>
        <author>
            <name>Qiaoying Huang</name>
        </author>
        <author>
            <name>Mikael Kanski</name>
        </author>
        <author>
            <name>Leon Axel</name>
        </author>
        <author>
            <name>Dimitris N Metaxas</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conformer: Local Features Coupling Global Representations for Recognition and Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10040235</id>
        <link href="https://ieeexplore.ieee.org/document/10040235"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[With convolution operations, Convolutional Neural Networks (CNNs) are good at extracting local features but experience difficulty to capture global representations. With cascaded self-attention modules, vision transformers can capture long-distance feature dependencies but unfortunately deteriorate local feature details. In this paper, we propose a hybrid network structure, termed Conformer, to ta...]]></summary>
        <author>
            <name>Zhiliang Peng</name>
        </author>
        <author>
            <name>Zonghao Guo</name>
        </author>
        <author>
            <name>Wei Huang</name>
        </author>
        <author>
            <name>Yaowei Wang</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Jianbin Jiao</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
        <author>
            <name>Qixiang Ye</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cascaded Deep Video Deblurring Using Temporal Sharpness Prior and Non-local Spatial-Temporal Similarity]]></title>
        <id>https://ieeexplore.ieee.org/document/10039490</id>
        <link href="https://ieeexplore.ieee.org/document/10039490"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We present compact and effective deep convolutional neural networks (CNNs) by exploring properties of videos for video deblurring. Motivated by the non-uniform blur property that not all the pixels of the frames are blurry, we develop a CNN to integrate a temporal sharpness prior (TSP) for removing blur in videos. The TSP exploits sharp pixels from adjacent frames to facilitate the CNN for better ...]]></summary>
        <author>
            <name>Jinshan Pan</name>
        </author>
        <author>
            <name>Boming Xu</name>
        </author>
        <author>
            <name>Haoran Bai</name>
        </author>
        <author>
            <name>Jinhui Tang</name>
        </author>
        <author>
            <name>Ming-Hsuan Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Salvage of Supervision in Weakly Supervised Object Detection and Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10039501</id>
        <link href="https://ieeexplore.ieee.org/document/10039501"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Weakly supervised vision tasks, including detection and segmentation, have attracted much attention in the vision community recently. However, the lack of detailed and precise annotations in the weakly supervised case leads to a large accuracy gap between weakly- and fully-supervised methods. In this paper, we propose a new framework, Salvage of Supervision (SoS), with the key idea being to effect...]]></summary>
        <author>
            <name>Lin Sui</name>
        </author>
        <author>
            <name>Chen-Lin Zhang</name>
        </author>
        <author>
            <name>Jianxin Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Federated Learning via Inexact ADMM]]></title>
        <id>https://ieeexplore.ieee.org/document/10040221</id>
        <link href="https://ieeexplore.ieee.org/document/10040221"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[One of the crucial issues in federated learning is how to develop efficient optimization algorithms. Most of the current ones require full device participation and/or impose strong assumptions for convergence. Different from the widely-used gradient descent-based algorithms, in this paper, we develop an inexact alternating direction method of multipliers (ADMM), which is both computation- and comm...]]></summary>
        <author>
            <name>Shenglong Zhou</name>
        </author>
        <author>
            <name>Geoffrey Ye Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Properties of Standard and Sketched Kernel Fisher Discriminant]]></title>
        <id>https://ieeexplore.ieee.org/document/10038534</id>
        <link href="https://ieeexplore.ieee.org/document/10038534"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Kernel Fisher discriminant (KFD) is a popular tool as a nonlinear extension of Fisher&#39;s linear discriminant, based on the use of the kernel trick. However, its asymptotic properties are still rarely studied. We first present an operator-theoretical formulation of KFD which elucidates the population target of the estimation problem. Convergence of the KFD solution to its population target is then e...]]></summary>
        <author>
            <name>Jiamin Liu</name>
        </author>
        <author>
            <name>Wangli Xu</name>
        </author>
        <author>
            <name>Fode Zhang</name>
        </author>
        <author>
            <name>Heng Lian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Content-aware Warping for View Synthesis]]></title>
        <id>https://ieeexplore.ieee.org/document/10038566</id>
        <link href="https://ieeexplore.ieee.org/document/10038566"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Existing image-based rendering methods usually adopt depth-based image warping operation to synthesize novel views. In this paper, we reason the essential limitations of the traditional warping operation to be the limited neighborhood and only distance-based interpolation weights. To this end, we propose content-aware warping, which adaptively learns the interpolation weights for pixels of a relat...]]></summary>
        <author>
            <name>Mantang Guo</name>
        </author>
        <author>
            <name>Junhui Hou</name>
        </author>
        <author>
            <name>Jing Jin</name>
        </author>
        <author>
            <name>Hui Liu</name>
        </author>
        <author>
            <name>Huanqiang Zeng</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hybrid High Dynamic Range Imaging fusing Neuromorphic and Conventional Images]]></title>
        <id>https://ieeexplore.ieee.org/document/10036136</id>
        <link href="https://ieeexplore.ieee.org/document/10036136"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Reconstruction of high dynamic range image from a single low dynamic range image captured by a conventional RGB camera, which suffers from over- or under-exposure, is an ill-posed problem. In contrast, recent neuromorphic cameras like event camera and spike camera can record high dynamic range scenes in the form of intensity maps, but with much lower spatial resolution and no color information. In...]]></summary>
        <author>
            <name>Jin Han</name>
        </author>
        <author>
            <name>Yixin Yang</name>
        </author>
        <author>
            <name>Peiqi Duan</name>
        </author>
        <author>
            <name>Chu Zhou</name>
        </author>
        <author>
            <name>Lei Ma</name>
        </author>
        <author>
            <name>Chao Xu</name>
        </author>
        <author>
            <name>Tiejun Huang</name>
        </author>
        <author>
            <name>Imari Sato</name>
        </author>
        <author>
            <name>Boxin Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continual Image Deraining with Hypergraph Convolutional Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10035447</id>
        <link href="https://ieeexplore.ieee.org/document/10035447"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Image deraining is a challenging task since rain streaks have the characteristics of spatially long structure and complex diversity. Existing deep learning-based methods mainly construct the deraining networks by stacking vanilla convolutional layers with local relations, and can only handle a single dataset due to the catastrophic forgetting, resulting in a limited performance and insufficient ad...]]></summary>
        <author>
            <name>Xueyang Fu</name>
        </author>
        <author>
            <name>Jie Xiao</name>
        </author>
        <author>
            <name>Yurui Zhu</name>
        </author>
        <author>
            <name>Aiping Liu</name>
        </author>
        <author>
            <name>Feng Wu</name>
        </author>
        <author>
            <name>Zheng-Jun Zha</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Generalized Explanation Framework for Visualization of Deep Learning Model Predictions]]></title>
        <id>https://ieeexplore.ieee.org/document/10034989</id>
        <link href="https://ieeexplore.ieee.org/document/10034989"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Attribution-based explanations are popular in computer vision but of limited use for fine-grained classification problems typical of expert domains, where classes differ by subtle details. In these domains, users also seek understanding of “why” a class was chosen and “why not” an alternative class. A new GenerAlized expLanatiOn fRamEwork (GALORE) is proposed to satisfy all these requirements, by ...]]></summary>
        <author>
            <name>Pei Wang</name>
        </author>
        <author>
            <name>Nuno Vasconcelos</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepEIT: Deep Image Prior Enabled Electrical Impedance Tomography]]></title>
        <id>https://ieeexplore.ieee.org/document/10034853</id>
        <link href="https://ieeexplore.ieee.org/document/10034853"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Neural networks (NNs) have been widely applied in tomographic imaging through data-driven training and image processing. One of the main challenges in using NNs in real medical imaging is the requirement of massive amounts of training data which are not always available in clinical practice. In this paper, we demonstrate that, on the contrary, one can directly execute image reconstruction using NN...]]></summary>
        <author>
            <name>Dong Liu</name>
        </author>
        <author>
            <name>Junwu Wang</name>
        </author>
        <author>
            <name>Qianxue Shan</name>
        </author>
        <author>
            <name>Danny Smyl</name>
        </author>
        <author>
            <name>Jiansong Deng</name>
        </author>
        <author>
            <name>Jiangfeng Du</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Attention Spiking Neural Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10032591</id>
        <link href="https://ieeexplore.ieee.org/document/10032591"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Brain-inspired spiking neural networks (SNNs) are becoming a promising energy-efficient alternative to traditional artificial neural networks (ANNs). However, the performance gap between SNNs and ANNs has been a significant hindrance to deploying SNNs ubiquitously. To leverage the full potential of SNNs, in this paper we study the attention mechanisms, which can help human focus on important infor...]]></summary>
        <author>
            <name>Man Yao</name>
        </author>
        <author>
            <name>Guangshe Zhao</name>
        </author>
        <author>
            <name>Hengyu Zhang</name>
        </author>
        <author>
            <name>Yifan Hu</name>
        </author>
        <author>
            <name>Lei Deng</name>
        </author>
        <author>
            <name>Yonghong Tian</name>
        </author>
        <author>
            <name>Bo Xu</name>
        </author>
        <author>
            <name>Guoqi Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SS-TBN: A Semi-Supervised Tri-Branch Network for COVID-19 Screening and Lesion Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10032636</id>
        <link href="https://ieeexplore.ieee.org/document/10032636"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Insufficient annotated data and minor lung lesions pose big challenges for computed tomography (CT)-aided automatic COVID-19 diagnosis at an early outbreak stage. To address this issue, we propose a Semi-Supervised Tri-Branch Network (SS-TBN). First, we develop a joint TBN model for dual-task application scenarios of image segmentation and classification such as CT-based COVID-19 diagnosis, in whi...]]></summary>
        <author>
            <name>Ling-Li Zeng</name>
        </author>
        <author>
            <name>Kai Gao</name>
        </author>
        <author>
            <name>Dewen Hu</name>
        </author>
        <author>
            <name>Zhichao Feng</name>
        </author>
        <author>
            <name>Chenping Hou</name>
        </author>
        <author>
            <name>Pengfei Rong</name>
        </author>
        <author>
            <name>Wei Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Super-Resolve Blurry Images With Events]]></title>
        <id>https://ieeexplore.ieee.org/document/10029887</id>
        <link href="https://ieeexplore.ieee.org/document/10029887"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Super-Resolution from a single motion Blurred image (SRB) is a severely ill-posed problem due to the joint degradation of motion blurs and low spatial resolution. In this paper, we employ events to alleviate the burden of SRB and propose an Event-enhanced SRB (E-SRB) algorithm, which can generate a sequence of sharp and clear images with High Resolution (HR) from a single blurry image with Low Res...]]></summary>
        <author>
            <name>Lei Yu</name>
        </author>
        <author>
            <name>Bishan Wang</name>
        </author>
        <author>
            <name>Xiang Zhang</name>
        </author>
        <author>
            <name>Haijian Zhang</name>
        </author>
        <author>
            <name>Wen Yang</name>
        </author>
        <author>
            <name>Jianzhuang Liu</name>
        </author>
        <author>
            <name>Gui-Song Xia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentiable Multi-Granularity Human Parsing]]></title>
        <id>https://ieeexplore.ieee.org/document/10032235</id>
        <link href="https://ieeexplore.ieee.org/document/10032235"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this work, we study the challenging problem of instance-aware human body part parsing. We introduce a new bottom-up regime which achieves the task through learning category-level human semantic segmentation as well as multi-person pose estimation in a joint and end-to-end manner. The output is a compact, efficient and powerful framework that exploits structural information over different human ...]]></summary>
        <author>
            <name>Tianfei Zhou</name>
        </author>
        <author>
            <name>Yi Yang</name>
        </author>
        <author>
            <name>Wenguan Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Evaluating Classification Model Against Bayes Error Rate]]></title>
        <id>https://ieeexplore.ieee.org/document/10027467</id>
        <link href="https://ieeexplore.ieee.org/document/10027467"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[For a classification task, we usually select an appropriate classifier via model selection. How to evaluate whether the chosen classifier is optimal? One can answer this question via Bayes error rate (BER). Unfortunately, estimating BER is a fundamental conundrum. Most existing BER estimators focus on giving the upper and lower bounds of the BER. However, evaluating whether the selected classifier...]]></summary>
        <author>
            <name>Qingqiang Chen</name>
        </author>
        <author>
            <name>Fuyuan Cao</name>
        </author>
        <author>
            <name>Ying Xing</name>
        </author>
        <author>
            <name>Jiye Liang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TextStyleBrush: Transfer of Text Aesthetics From a Single Example]]></title>
        <id>https://ieeexplore.ieee.org/document/10027471</id>
        <link href="https://ieeexplore.ieee.org/document/10027471"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We present a novel approach for disentangling the content of a text image from all aspects of its appearance. The appearance representation we derive can then be applied to new content, for one-shot transfer of the source style to new content. We learn this disentanglement in a self-supervised manner. Our method processes entire word boxes, without requiring segmentation of text from background, p...]]></summary>
        <author>
            <name>Praveen Krishnan</name>
        </author>
        <author>
            <name>Rama Kovvuri</name>
        </author>
        <author>
            <name>Guan Pang</name>
        </author>
        <author>
            <name>Boris Vassilev</name>
        </author>
        <author>
            <name>Tal Hassner</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[General Greedy De-bias Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10027464</id>
        <link href="https://ieeexplore.ieee.org/document/10027464"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Neural networks often make predictions relying on the spurious correlations from the datasets rather than the intrinsic properties of the task of interest, facing with sharp degradation on out-of-distribution (OOD) test data. Existing de-bias learning frameworks try to capture specific dataset bias by annotations but they fail to handle complicated OOD scenarios. Others implicitly identify the dat...]]></summary>
        <author>
            <name>Xinzhe Han</name>
        </author>
        <author>
            <name>Shuhui Wang</name>
        </author>
        <author>
            <name>Chi Su</name>
        </author>
        <author>
            <name>Qingming Huang</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Good Features to Transfer Across Tasks and Domains]]></title>
        <id>https://ieeexplore.ieee.org/document/10027474</id>
        <link href="https://ieeexplore.ieee.org/document/10027474"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Availability of labelled data is the major obstacle to the deployment of deep learning algorithms for computer vision tasks in new domains. The fact that many frameworks adopted to solve different tasks share the same architecture suggests that there should be a way of reusing the knowledge learned in a specific setting to solve novel tasks with limited or no additional supervision. In this work, ...]]></summary>
        <author>
            <name>Pierluigi Zama Ramirez</name>
        </author>
        <author>
            <name>Adriano Cardace</name>
        </author>
        <author>
            <name>Luca De Luigi</name>
        </author>
        <author>
            <name>Alessio Tonioni</name>
        </author>
        <author>
            <name>Samuele Salti</name>
        </author>
        <author>
            <name>Luigi Di Stefano</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Image Intensity Variation Information for Interest Point Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10026417</id>
        <link href="https://ieeexplore.ieee.org/document/10026417"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Interest point detection methods are gaining more attention and are widely applied in computer vision tasks such as image retrieval and 3D reconstruction. However, there still exist two main problems to be solved: (1) from the perspective of mathematical representations, the differences among edges, corners, and blobs have not been convincingly explained and the relationships among the amplitude r...]]></summary>
        <author>
            <name>Weichuan Zhang</name>
        </author>
        <author>
            <name>Changming Sun</name>
        </author>
        <author>
            <name>Yongsheng Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge-aware Global Reasoning for Situation Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10024320</id>
        <link href="https://ieeexplore.ieee.org/document/10024320"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The task of situation recognition aims to solve the visual reasoning problem with the ability to predict the activity happening (salient action) in an image and the nouns of all associated semantic roles playing in the activity. This poses severe challenges due to long-tailed data distributions and local class ambiguities. Prior works only propagate the local noun-level features on one single imag...]]></summary>
        <author>
            <name>Weijiang Yu</name>
        </author>
        <author>
            <name>Haofan Wang</name>
        </author>
        <author>
            <name>Guohao Li</name>
        </author>
        <author>
            <name>Nong Xiao</name>
        </author>
        <author>
            <name>Bernard Ghanem</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-Adversarial Disentangling for Specific Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/10024368</id>
        <link href="https://ieeexplore.ieee.org/document/10024368"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Domain adaptation aims to bridge the domain shifts between the source and the target domain. These shifts may span different dimensions such as fog, rainfall, etc. However, recent methods typically do not consider explicit prior knowledge about the domain shifts on a specific dimension, thus leading to less desired adaptation performance. In this paper, we study a practical setting called Specific...]]></summary>
        <author>
            <name>Qianyu Zhou</name>
        </author>
        <author>
            <name>Qiqi Gu</name>
        </author>
        <author>
            <name>Jiangmiao Pang</name>
        </author>
        <author>
            <name>Xuequan Lu</name>
        </author>
        <author>
            <name>Lizhuang Ma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Diffusion Convolutional Network for Skeleton Based Semantic Recognition of Two-Person Actions]]></title>
        <id>https://ieeexplore.ieee.org/document/10023982</id>
        <link href="https://ieeexplore.ieee.org/document/10023982"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Graph Convolutional Networks (GCNs) have successfully boosted skeleton-based human action recognition. However, existing GCN-based methods mostly cast the problem as separated person&#39;s action recognition while ignoring the interaction between the action initiator and the action responder, especially for the fundamental two-person interactive action recognition. It is still challenging to effective...]]></summary>
        <author>
            <name>Shuai Li</name>
        </author>
        <author>
            <name>Xinxue He</name>
        </author>
        <author>
            <name>Wenfeng Song</name>
        </author>
        <author>
            <name>Aimin Hao</name>
        </author>
        <author>
            <name>Hong Qin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AGConv: Adaptive Graph Convolution on 3D Point Clouds]]></title>
        <id>https://ieeexplore.ieee.org/document/10024001</id>
        <link href="https://ieeexplore.ieee.org/document/10024001"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Convolution on 3D point clouds is widely researched yet far from perfect in geometric deep learning. The traditional wisdom of convolution characterises feature correspondences indistinguishably among 3D points, arising an intrinsic limitation of poor distinctive feature learning. In this paper, we propose Adaptive Graph Convolution (AGConv) for wide applications of point cloud analysis. AGConv ge...]]></summary>
        <author>
            <name>Mingqiang Wei</name>
        </author>
        <author>
            <name>Zeyong Wei</name>
        </author>
        <author>
            <name>Haoran Zhou</name>
        </author>
        <author>
            <name>Fei Hu</name>
        </author>
        <author>
            <name>Huajian Si</name>
        </author>
        <author>
            <name>Zhilei Chen</name>
        </author>
        <author>
            <name>Zhe Zhu</name>
        </author>
        <author>
            <name>Jingbo Qiu</name>
        </author>
        <author>
            <name>Xuefeng Yan</name>
        </author>
        <author>
            <name>Yanwen Guo</name>
        </author>
        <author>
            <name>Jun Wang</name>
        </author>
        <author>
            <name>Jing Qin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Restoring Vision in Adverse Weather Conditions With Patch-Based Denoising Diffusion Models]]></title>
        <id>https://ieeexplore.ieee.org/document/10021824</id>
        <link href="https://ieeexplore.ieee.org/document/10021824"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Image restoration under adverse weather conditions has been of significant interest for various computer vision applications. Recent successful methods rely on the current progress in deep neural network architectural designs (e.g., with vision transformers). Motivated by the recent progress achieved with state-of-the-art conditional generative models, we present a novel patch-based image restorat...]]></summary>
        <author>
            <name>Ozan Özdenizci</name>
        </author>
        <author>
            <name>Robert Legenstein</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Feature Selection With Augmented Attributes]]></title>
        <id>https://ieeexplore.ieee.org/document/10021870</id>
        <link href="https://ieeexplore.ieee.org/document/10021870"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In many dynamic environment applications, with the evolution of data collection ways, the data attributes are incremental and the samples are stored with accumulated feature spaces gradually. For instance, in the neuroimaging-based diagnosis of neuropsychiatric disorders, with emerging of diverse testing ways, we get more brain image features over time. The accumulation of different types of featu...]]></summary>
        <author>
            <name>Chenping Hou</name>
        </author>
        <author>
            <name>Ruidong Fan</name>
        </author>
        <author>
            <name>Ling-Li Zeng</name>
        </author>
        <author>
            <name>Dewen Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recognizing Object by Components with Human Prior Knowledge Enhances Adversarial Robustness of Deep Neural Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10019576</id>
        <link href="https://ieeexplore.ieee.org/document/10019576"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Adversarial attacks can easily fool object recognition systems based on deep neural networks (DNNs). Although many defense methods have been proposed in recent years, most of them can still be adaptively evaded. One reason for the weak adversarial robustness may be that DNNs are only supervised by category labels and do not have part-based inductive bias like the recognition process of humans. Ins...]]></summary>
        <author>
            <name>Xiao Li</name>
        </author>
        <author>
            <name>Ziqi Wang</name>
        </author>
        <author>
            <name>Bo Zhang</name>
        </author>
        <author>
            <name>Fuchun Sun</name>
        </author>
        <author>
            <name>Xiaolin Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large Scale Visual Food Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10019590</id>
        <link href="https://ieeexplore.ieee.org/document/10019590"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Food recognition plays an important role in food choice and intake, which is essential to the health and well-being of humans. It is thus of importance to the computer vision community, and can further support many food-oriented vision and multimodal tasks, e.g., food detection and segmentation, cross-modal recipe retrieval and generation. Unfortunately, we have witnessed remarkable advancements i...]]></summary>
        <author>
            <name>Weiqing Min</name>
        </author>
        <author>
            <name>Zhiling Wang</name>
        </author>
        <author>
            <name>Yuxin Liu</name>
        </author>
        <author>
            <name>Mengjiang Luo</name>
        </author>
        <author>
            <name>Liping Kang</name>
        </author>
        <author>
            <name>Xiaoming Wei</name>
        </author>
        <author>
            <name>Xiaolin Wei</name>
        </author>
        <author>
            <name>Shuqiang Jiang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Capture the Moment: High-speed Imaging with Spiking Cameras through Short-term Plasticity]]></title>
        <id>https://ieeexplore.ieee.org/document/10019594</id>
        <link href="https://ieeexplore.ieee.org/document/10019594"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[High-speed imaging can help us understand some phenomena that our eyes cannot capture fast enough. Although ultra-fast frame-based cameras (e.g., Phantom) can record millions of fps at reduced resolution, are too expensive to be widely used. Recently, a retina-inspired vision sensor, spiking camera, has been developed to record external information at 40, 000 Hz. The spiking camera uses the asynch...]]></summary>
        <author>
            <name>Yajing Zheng</name>
        </author>
        <author>
            <name>Lingxiao Zheng</name>
        </author>
        <author>
            <name>Zhaofei Yu</name>
        </author>
        <author>
            <name>Tiejun Huang</name>
        </author>
        <author>
            <name>Song Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fully Convolutional Change Detection Framework with Generative Adversarial Network for Unsupervised, Weakly Supervised and Regional Supervised Change Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10019593</id>
        <link href="https://ieeexplore.ieee.org/document/10019593"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Deep learning for change detection is one of the current hot topics in the field of remote sensing. However, most end-to-end networks are proposed for supervised change detection, and unsupervised change detection models depend on traditional pre-detection methods. Therefore, we proposed a fully convolutional change detection framework with generative adversarial network, to unify unsupervised, we...]]></summary>
        <author>
            <name>Chen Wu</name>
        </author>
        <author>
            <name>Bo Du</name>
        </author>
        <author>
            <name>Liangpei Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transforming Complex Problems into K-means Solutions]]></title>
        <id>https://ieeexplore.ieee.org/document/10018468</id>
        <link href="https://ieeexplore.ieee.org/document/10018468"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[K-means is a fundamental clustering algorithm widely used in both academic and industrial applications. Its popularity can be attributed to its simplicity and efficiency. Studies show the equivalence of K-means to principal component analysis, non-negative matrix factorization, and spectral clustering. However, these studies focus on standard K-means with squared Euclidean distance. In this review...]]></summary>
        <author>
            <name>Hongfu Liu</name>
        </author>
        <author>
            <name>Junxiang Chen</name>
        </author>
        <author>
            <name>Jennifer Dy</name>
        </author>
        <author>
            <name>Yun Fu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ContextLoc++: A Unified Context Model for Temporal Action Localization]]></title>
        <id>https://ieeexplore.ieee.org/document/10018461</id>
        <link href="https://ieeexplore.ieee.org/document/10018461"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Effectively tackling the problem of temporal action localization (TAL) necessitates a visual representation that jointly pursues two confounding goals, i.e., fine-grained discrimination for temporal localization and sufficient visual invariance for action classification. We address this challenge by enriching the local, global and multi-scale contexts in the popular two-stage temporal localization...]]></summary>
        <author>
            <name>Zixin Zhu</name>
        </author>
        <author>
            <name>Le Wang</name>
        </author>
        <author>
            <name>Wei Tang</name>
        </author>
        <author>
            <name>Nanning Zheng</name>
        </author>
        <author>
            <name>Gang Hua</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SePiCo: Semantic-Guided Pixel Contrast for Domain Adaptive Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10018569</id>
        <link href="https://ieeexplore.ieee.org/document/10018569"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Domain adaptive semantic segmentation attempts to make satisfactory dense predictions on an unlabeled target domain by utilizing the supervised model trained on a labeled source domain. One popular solution is self-training, which retrains the model with pseudo labels on target instances. Plenty of approaches tend to alleviate noisy pseudo labels, however, they ignore the intrinsic connection of t...]]></summary>
        <author>
            <name>Binhui Xie</name>
        </author>
        <author>
            <name>Shuang Li</name>
        </author>
        <author>
            <name>Mingjia Li</name>
        </author>
        <author>
            <name>Chi Harold Liu</name>
        </author>
        <author>
            <name>Gao Huang</name>
        </author>
        <author>
            <name>Guoren Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SceneHGN: Hierarchical Graph Networks for 3D Indoor Scene Generation with Fine-Grained Geometry]]></title>
        <id>https://ieeexplore.ieee.org/document/10018465</id>
        <link href="https://ieeexplore.ieee.org/document/10018465"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[3D indoor scenes are widely used in computer graphics, with applications ranging from interior design to gaming to virtual and augmented reality. They also contain rich information, including room layout, as well as furniture type, geometry, and placement. High-quality 3D indoor scenes are highly demanded while it requires expertise and is time-consuming to design high-quality 3D indoor scenes man...]]></summary>
        <author>
            <name>Lin Gao</name>
        </author>
        <author>
            <name>Jia-Mu Sun</name>
        </author>
        <author>
            <name>Kaichun Mo</name>
        </author>
        <author>
            <name>Yu-Kun Lai</name>
        </author>
        <author>
            <name>Leonidas J. Guibas</name>
        </author>
        <author>
            <name>Jie Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Pixel-Perfect Structure-From-Motion With Featuremetric Refinement]]></title>
        <id>https://ieeexplore.ieee.org/document/10018409</id>
        <link href="https://ieeexplore.ieee.org/document/10018409"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Finding local features that are repeatable across multiple views is a cornerstone of sparse 3D reconstruction. The classical image matching paradigm detects keypoints per-image once and for all, which can yield poorly-localized features and propagate large errors to the final geometry. In this paper, we refine two key steps of structure-from-motion by a direct alignment of low-level image informat...]]></summary>
        <author>
            <name>Paul-Edouard Sarlin</name>
        </author>
        <author>
            <name>Philipp Lindenberger</name>
        </author>
        <author>
            <name>Viktor Larsson</name>
        </author>
        <author>
            <name>Marc Pollefeys</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generalizable Black-Box Adversarial Attack With Meta Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/10017370</id>
        <link href="https://ieeexplore.ieee.org/document/10017370"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In the scenario of black-box adversarial attack, the target model&#39;s parameters are unknown, and the attacker aims to find a successful adversarial perturbation based on query feedback under a query budget. Due to the limited feedback information, existing query-based black-box attack methods often require many queries for attacking each benign example. To reduce query cost, we propose to utilize t...]]></summary>
        <author>
            <name>Fei Yin</name>
        </author>
        <author>
            <name>Yong Zhang</name>
        </author>
        <author>
            <name>Baoyuan Wu</name>
        </author>
        <author>
            <name>Yan Feng</name>
        </author>
        <author>
            <name>Jingyi Zhang</name>
        </author>
        <author>
            <name>Yanbo Fan</name>
        </author>
        <author>
            <name>Yujiu Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FingerGAN: A Constrained Fingerprint Generation Scheme for Latent Fingerprint Enhancement]]></title>
        <id>https://ieeexplore.ieee.org/document/10016755</id>
        <link href="https://ieeexplore.ieee.org/document/10016755"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Latent fingerprint enhancement is an essential preprocessing step for latent fingerprint identification. Most latent fingerprint enhancement methods try to restore corrupted gray ridges/valleys. In this paper, we propose a new method that formulates latent fingerprint enhancement as a constrained fingerprint generation problem within a generative adversarial network (GAN) framework. We name the pr...]]></summary>
        <author>
            <name>Yanming Zhu</name>
        </author>
        <author>
            <name>Xuefei Yin</name>
        </author>
        <author>
            <name>Jiankun Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convolution-enhanced Evolving Attention Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/10016752</id>
        <link href="https://ieeexplore.ieee.org/document/10016752"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Attention-based neural networks, such as Transformers, have become ubiquitous in numerous applications, including computer vision, natural language processing, and time-series analysis. In all kinds of attention networks, the attention maps are crucial as they encode semantic dependencies between input tokens. However, most existing attention networks perform modeling or reasoning based on represe...]]></summary>
        <author>
            <name>Yujing Wang</name>
        </author>
        <author>
            <name>Yaming Yang</name>
        </author>
        <author>
            <name>Zhuo Li</name>
        </author>
        <author>
            <name>Jiangang Bai</name>
        </author>
        <author>
            <name>Mingliang Zhang</name>
        </author>
        <author>
            <name>Xiangtai Li</name>
        </author>
        <author>
            <name>Jing Yu</name>
        </author>
        <author>
            <name>Ce Zhang</name>
        </author>
        <author>
            <name>Gao Huang</name>
        </author>
        <author>
            <name>Yunhai Tong</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adversarially-Regularized Mixed Effects Deep Learning (ARMED) Models Improve Interpretability, Performance, and Generalization on Clustered (non-iid) Data]]></title>
        <id>https://ieeexplore.ieee.org/document/10016237</id>
        <link href="https://ieeexplore.ieee.org/document/10016237"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Natural science datasets frequently violate assumptions of independence. Samples may be clustered (e.g. by study site, subject, or experimental batch), leading to spurious associations, poor model fitting, and confounded analyses. While largely unaddressed in deep learning, this problem has been handled in the statistics community through mixed effects models, which separate cluster-invariant fixe...]]></summary>
        <author>
            <name>Kevin P. Nguyen</name>
        </author>
        <author>
            <name>Alex H. Treacher</name>
        </author>
        <author>
            <name>Albert A. Montillo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Full-Volume 3D Fluid Flow Reconstruction With Light Field PIV]]></title>
        <id>https://ieeexplore.ieee.org/document/10015628</id>
        <link href="https://ieeexplore.ieee.org/document/10015628"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Particle Imaging Velocimetry (PIV) is a classical method that estimates fluid flow by analyzing the motion of injected particles. To reconstruct and track the swirling particles is a difficult computer vision problem, as the particles are dense in the fluid volume and have similar appearances. Further, tracking a large number of particles is particularly challenging due to heavy occlusion. Here we...]]></summary>
        <author>
            <name>Yuqi Ding</name>
        </author>
        <author>
            <name>Zhong Li</name>
        </author>
        <author>
            <name>Zhang Chen</name>
        </author>
        <author>
            <name>Yu Ji</name>
        </author>
        <author>
            <name>Jingyi Yu</name>
        </author>
        <author>
            <name>Jinwei Ye</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Subgraph Neural Network with Reinforced Critical Structure Mining]]></title>
        <id>https://ieeexplore.ieee.org/document/10013693</id>
        <link href="https://ieeexplore.ieee.org/document/10013693"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[While graph representation learning methods have shown success in various graph mining tasks, what knowledge is exploited for predictions is less discussed. This paper proposes a novel Adaptive Subgraph Neural Network named AdaSNN to find critical structures in graph data, i.e., subgraphs that are dominant to the prediction results. To detect critical subgraphs of arbitrary size and shape in the a...]]></summary>
        <author>
            <name>Jianxin Li</name>
        </author>
        <author>
            <name>Qingyun Sun</name>
        </author>
        <author>
            <name>Hao Peng</name>
        </author>
        <author>
            <name>Beining Yang</name>
        </author>
        <author>
            <name>Jia Wu</name>
        </author>
        <author>
            <name>Phillp S. Yu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Language-Aware Spatial-Temporal Collaboration for Referring Video Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10013778</id>
        <link href="https://ieeexplore.ieee.org/document/10013778"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Given a natural language referring expression, the goal of referring video segmentation task is to predict the segmentation mask of the referred object in the video. Previous methods only adopt 3D CNNs upon the video clip as a single encoder to extract a mixed spatio-temporal feature for the target frame. Though 3D convolutions are able to recognize which object is performing the described actions...]]></summary>
        <author>
            <name>Tianrui Hui</name>
        </author>
        <author>
            <name>Si Liu</name>
        </author>
        <author>
            <name>Zihan Ding</name>
        </author>
        <author>
            <name>Shaofei Huang</name>
        </author>
        <author>
            <name>Guanbin Li</name>
        </author>
        <author>
            <name>Wenguan Wang</name>
        </author>
        <author>
            <name>Luoqi Liu</name>
        </author>
        <author>
            <name>Jizhong Han</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DAN: a Segmentation-free Document Attention Network for Handwritten Document Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/10013687</id>
        <link href="https://ieeexplore.ieee.org/document/10013687"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Unconstrained handwritten text recognition is a challenging computer vision task. It is traditionally handled by a two-step approach, combining line segmentation followed by text line recognition. For the first time, we propose an end-to-end segmentation-free architecture for the task of handwritten document recognition: the Document Attention Network. In addition to text recognition, the model is...]]></summary>
        <author>
            <name>Denis Coquenet</name>
        </author>
        <author>
            <name>Clément Chatelain</name>
        </author>
        <author>
            <name>Thierry Paquet</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SIGMA++: Improved Semantic-complete Graph Matching for Domain Adaptive Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10012542</id>
        <link href="https://ieeexplore.ieee.org/document/10012542"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Domain Adaptive Object Detection (DAOD) generalizes the object detector from an annotated domain to a label-free novel one. Recent works estimate prototypes (class centers) and minimize the corresponding distances to adapt the cross-domain class conditional distribution. However, this prototype-based paradigm 1) fails to capture the class variance with agnostic structural dependencies, and 2) igno...]]></summary>
        <author>
            <name>Wuyang Li</name>
        </author>
        <author>
            <name>Xinyu Liu</name>
        </author>
        <author>
            <name>Yixuan Yuan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BNET: Batch Normalization With Enhanced Linear Transformation]]></title>
        <id>https://ieeexplore.ieee.org/document/10012548</id>
        <link href="https://ieeexplore.ieee.org/document/10012548"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Batch normalization (BN) is a fundamental unit in modern deep neural networks. However, BN and its variants focus on normalization statistics but neglect the recovery step that uses linear transformation to improve the capacity of fitting complex data distributions. In this paper, we demonstrate that the recovery step can be improved by aggregating the neighborhood of each neuron rather than just ...]]></summary>
        <author>
            <name>Yuhui Xu</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Cihang Xie</name>
        </author>
        <author>
            <name>Wenrui Dai</name>
        </author>
        <author>
            <name>Jieru Mei</name>
        </author>
        <author>
            <name>Siyuan Qiao</name>
        </author>
        <author>
            <name>Wei Shen</name>
        </author>
        <author>
            <name>Hongkai Xiong</name>
        </author>
        <author>
            <name>Alan Yuille</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Thorough Benchmark and a New Model for Light Field Saliency Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/10012539</id>
        <link href="https://ieeexplore.ieee.org/document/10012539"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Compared with current RGB or RGB-D saliency detection datasets, those for light field saliency detection often suffer from many defects, e.g., insufficient data amount and diversity, incomplete data formats, and rough annotations, thus impeding the prosperity of this field. To settle these issues, we elaborately build a large-scale light field dataset, dubbed PKU-LF, comprising 5,000 light fields ...]]></summary>
        <author>
            <name>Wei Gao</name>
        </author>
        <author>
            <name>Songlin Fan</name>
        </author>
        <author>
            <name>Ge Li</name>
        </author>
        <author>
            <name>Weisi Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Detection-Friendly Dehazing: Object Detection in Real-World Hazy Scenes]]></title>
        <id>https://ieeexplore.ieee.org/document/10012056</id>
        <link href="https://ieeexplore.ieee.org/document/10012056"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Adverse weather conditions in real-world scenarios lead to performance degradation of deep learning-based detection models. A well-known method is to use image restoration methods to enhance degraded images before object detection. However, how to build a positive correlation between these two tasks is still technically challenging. The restoration labels are also unavailable in practice. To this ...]]></summary>
        <author>
            <name>Chengyang Li</name>
        </author>
        <author>
            <name>Heng Zhou</name>
        </author>
        <author>
            <name>Yang Liu</name>
        </author>
        <author>
            <name>Caidong Yang</name>
        </author>
        <author>
            <name>Yongqiang Xie</name>
        </author>
        <author>
            <name>Zhongbo Li</name>
        </author>
        <author>
            <name>Liping Zhu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Convolutional Hough Matching Networks for Robust and Efficient Visual Correspondence]]></title>
        <id>https://ieeexplore.ieee.org/document/10008958</id>
        <link href="https://ieeexplore.ieee.org/document/10008958"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Despite advances in feature representation, leveraging geometric relations is crucial for establishing reliable visual correspondences under large variations of images. In this work we introduce a Hough transform perspective on convolutional matching and propose an effective geometric matching algorithm, dubbed Convolutional Hough Matching (CHM). The method distributes similarities of candidate ma...]]></summary>
        <author>
            <name>Juhong Min</name>
        </author>
        <author>
            <name>Seungwook Kim</name>
        </author>
        <author>
            <name>Minsu Cho</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Co-Salient Object Detection with Co-Representation Purification]]></title>
        <id>https://ieeexplore.ieee.org/document/10008072</id>
        <link href="https://ieeexplore.ieee.org/document/10008072"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Co-salient object detection (Co-SOD) aims at discovering the common objects in a group of relevant images. Mining a co-representation is essential for locating co-salient objects. Unfortunately, the current Co-SOD method does not pay enough attention that the information not related to the co-salient object is included in the co-representation. Such irrelevant information in the co-representation ...]]></summary>
        <author>
            <name>Ziyue Zhu</name>
        </author>
        <author>
            <name>Zhao Zhang</name>
        </author>
        <author>
            <name>Zheng Lin</name>
        </author>
        <author>
            <name>Xing Sun</name>
        </author>
        <author>
            <name>Ming-Ming Cheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GCNet: Graph Completion Network for Incomplete Multimodal Learning in Conversation]]></title>
        <id>https://ieeexplore.ieee.org/document/10008078</id>
        <link href="https://ieeexplore.ieee.org/document/10008078"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Conversations have become a critical data format on social media platforms. Understanding conversation from emotion, content and other aspects also attracts increasing attention from researchers due to its widespread application in human-computer interaction. In real-world environments, we often encounter the problem of incomplete modalities, which has become a core issue of conversation understan...]]></summary>
        <author>
            <name>Zheng Lian</name>
        </author>
        <author>
            <name>Lan Chen</name>
        </author>
        <author>
            <name>Licai Sun</name>
        </author>
        <author>
            <name>Bin Liu</name>
        </author>
        <author>
            <name>Jianhua Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Metric Learning with Adaptively Composite Dynamic Constraints]]></title>
        <id>https://ieeexplore.ieee.org/document/10008092</id>
        <link href="https://ieeexplore.ieee.org/document/10008092"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this paper, we propose a deep metric learning with adaptively composite dynamic constraints (DML-DC) method for image retrieval and clustering. Most existing deep metric learning methods impose pre-defined constraints on the training samples, which might not be optimal at all stages of training. To address this, we propose a learnable constraint generator to adaptively produce dynamic constrain...]]></summary>
        <author>
            <name>Wenzhao Zheng</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gradient Descent Ascent for Minimax Problems on Riemannian Manifolds]]></title>
        <id>https://ieeexplore.ieee.org/document/10005847</id>
        <link href="https://ieeexplore.ieee.org/document/10005847"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In the paper, we study a class of useful minimax problems on Riemanian manifolds and propose a class of effective Riemanian gradient-based methods to solve these minimax problems. Specifically, we propose an effective Riemannian gradient descent ascent (RGDA) algorithm for the deterministic minimax optimization. Moreover, we prove that our RGDA has a sample complexity of $O(\kappa ^{2}\epsilon ^{-...]]></summary>
        <author>
            <name>Feihu Huang</name>
        </author>
        <author>
            <name>Shangqian Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Universal Multimodal Representation for Language Understanding]]></title>
        <id>https://ieeexplore.ieee.org/document/10005816</id>
        <link href="https://ieeexplore.ieee.org/document/10005816"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Representation learning is the foundation of natural language processing (NLP). This work presents new methods to employ visual information as assistant signals to general NLP tasks. For each sentence, we first retrieve a flexible number of images either from a light topic-image lookup table extracted over the existing sentence-image pairs or a shared cross-modal embedding space that is pre-traine...]]></summary>
        <author>
            <name>Zhuosheng Zhang</name>
        </author>
        <author>
            <name>Kehai Chen</name>
        </author>
        <author>
            <name>Rui Wang</name>
        </author>
        <author>
            <name>Masao Utiyama</name>
        </author>
        <author>
            <name>Eiichiro Sumita</name>
        </author>
        <author>
            <name>Zuchao Li</name>
        </author>
        <author>
            <name>Hai Zhao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From Keypoints to Object Landmarks via Self-Training Correspondence: A novel approach to Unsupervised Landmark Discovery]]></title>
        <id>https://ieeexplore.ieee.org/document/10005822</id>
        <link href="https://ieeexplore.ieee.org/document/10005822"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[This paper proposes a novel paradigm for the unsupervised learning of object landmark detectors. Contrary to existing methods that build on auxiliary tasks such as image generation or equivariance, we propose a self-training approach where, departing from generic keypoints, a landmark detector and descriptor is trained to improve itself, tuning the keypoints into distinctive landmarks. To this end...]]></summary>
        <author>
            <name>Dimitrios Mallis</name>
        </author>
        <author>
            <name>Enrique Sanchez</name>
        </author>
        <author>
            <name>Matt Bell</name>
        </author>
        <author>
            <name>Georgios Tzimiropoulos</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Blindly Enhancing Extremely Noisy Videos With Recurrent Spatio-Temporal Large-Span Network]]></title>
        <id>https://ieeexplore.ieee.org/document/10005850</id>
        <link href="https://ieeexplore.ieee.org/document/10005850"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Capturing videos under the extremely dark environment is quite challenging for the extremely large and complex noise. To accurately represent the complex noise distribution, the physics-based noise modeling and learning-based blind noise modeling methods are proposed. However, these methods suffer from either the requirement of complex calibration procedure or performance degradation in practice. ...]]></summary>
        <author>
            <name>Xin Chen</name>
        </author>
        <author>
            <name>Xuemei Hu</name>
        </author>
        <author>
            <name>Tao Yue</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HOP+: History-Enhanced and Order-Aware Pre-Training for Vision-and-Language Navigation]]></title>
        <id>https://ieeexplore.ieee.org/document/10006384</id>
        <link href="https://ieeexplore.ieee.org/document/10006384"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recent works attempt to employ pre-training in Vision-and-Language Navigation (VLN). However, these methods neglect the importance of historical contexts or ignore predicting future actions during pre-training, limiting the learning of visual-textual correspondence and the capability of decision-making. To address these problems, we present a history-enhanced and order-aware pre-training with the ...]]></summary>
        <author>
            <name>Yanyuan Qiao</name>
        </author>
        <author>
            <name>Yuankai Qi</name>
        </author>
        <author>
            <name>Yicong Hong</name>
        </author>
        <author>
            <name>Zheng Yu</name>
        </author>
        <author>
            <name>Peng Wang</name>
        </author>
        <author>
            <name>Qi Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Monocular 3D Fingerprint Reconstruction and Unwarping]]></title>
        <id>https://ieeexplore.ieee.org/document/10005833</id>
        <link href="https://ieeexplore.ieee.org/document/10005833"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Compared with contact-based fingerprint acquisition techniques, contactless acquisition has the advantages of less skin distortion, more complete fingerprint area, and hygienic acquisition. However, perspective distortion is a challenge in contactless fingerprint recognition, which changes the ridge frequency and relative minutiae location, and thus degrades the recognition accuracy. We propose a ...]]></summary>
        <author>
            <name>Zhe Cui</name>
        </author>
        <author>
            <name>Jianjiang Feng</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unified Visual Information Preservation Framework for Self-supervised Pre-training in Medical Image Analysis]]></title>
        <id>https://ieeexplore.ieee.org/document/10005161</id>
        <link href="https://ieeexplore.ieee.org/document/10005161"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recent advances in self-supervised learning (SSL) in computer vision are primarily comparative, whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views. However, the preserved high-level semantics do not contain enough local information, which is vital in medical image analysis (e.g., image-based diagnosis and tumor segmentation)....]]></summary>
        <author>
            <name>Hong-Yu Zhou</name>
        </author>
        <author>
            <name>Chixiang Lu</name>
        </author>
        <author>
            <name>Chaoqi Chen</name>
        </author>
        <author>
            <name>Sibei Yang</name>
        </author>
        <author>
            <name>Yizhou Yu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Invariant Policy Learning: A Causal Perspective]]></title>
        <id>https://ieeexplore.ieee.org/document/10005169</id>
        <link href="https://ieeexplore.ieee.org/document/10005169"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Contextual bandit and reinforcement learning algorithms have been successfully used in various interactive learning systems such as online advertising, recommender systems, and dynamic pricing. However, they have yet to be widely adopted in high-stakes application domains, such as healthcare. One reason may be that existing approaches assume that the underlying mechanisms are static in the sense t...]]></summary>
        <author>
            <name>Sorawit Saengkyongam</name>
        </author>
        <author>
            <name>Nikolaj Thams</name>
        </author>
        <author>
            <name>Jonas Peters</name>
        </author>
        <author>
            <name>Niklas Pfister</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Unary Convolution in Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/10004645</id>
        <link href="https://ieeexplore.ieee.org/document/10004645"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[It is uncertain whether the power of transformer architectures can complement existing convolutional neural networks. A few recent attempts have combined convolution with transformer design through a range of structures in series, where the main contribution of this paper is to explore a parallel design approach. While previous transformed-based approaches need to segment the image into patch-wise...]]></summary>
        <author>
            <name>Haoran Duan</name>
        </author>
        <author>
            <name>Yang Long</name>
        </author>
        <author>
            <name>Shidong Wang</name>
        </author>
        <author>
            <name>Haofeng Zhang</name>
        </author>
        <author>
            <name>Chris G. Willcocks</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hyperparameter-Free Localized Simple Multiple Kernel K-Means With Global Optimum]]></title>
        <id>https://ieeexplore.ieee.org/document/10005021</id>
        <link href="https://ieeexplore.ieee.org/document/10005021"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The newly proposed localized simple multiple kernel k-means (SimpleMKKM) provides an elegant clustering framework which sufficiently considers the potential variation among samples. Although achieving superior clustering performance in some applications, we observe that it is required to pre-specify an extra hyperparameter, which determines the size of the localization. This greatly limits its ava...]]></summary>
        <author>
            <name>Xinwang Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Querying Labeled for Unlabeled: Cross-Image Semantic Consistency Guided Semi-Supervised Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/10005033</id>
        <link href="https://ieeexplore.ieee.org/document/10005033"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Semi-supervised semantic segmentation aims to learn a semantic segmentation model via limited labeled images and adequate unlabeled images. The key to this task is generating reliable pseudo labels for unlabeled images. Existing methods mainly focus on producing reliable pseudo labels based on the confidence scores of unlabeled images while largely ignoring the use of labeled images with accurate ...]]></summary>
        <author>
            <name>Linshan Wu</name>
        </author>
        <author>
            <name>Leyuan Fang</name>
        </author>
        <author>
            <name>Xingxin He</name>
        </author>
        <author>
            <name>Min He</name>
        </author>
        <author>
            <name>Jiayi Ma</name>
        </author>
        <author>
            <name>Zhun Zhong</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fisher's Linear Discriminant Analysis With Space-Folding Operations]]></title>
        <id>https://ieeexplore.ieee.org/document/10005006</id>
        <link href="https://ieeexplore.ieee.org/document/10005006"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Fisher&#39;s linear discriminant analysis (LDA) is an easy-to-use supervised dimensionality reduction method. However, LDA may be ineffective against complicated class distributions. It is well-known that deep feedforward neural networks with rectified linear units as activation functions can map many input neighborhoods to similar outputs by a succession of space-folding operations. This short paper ...]]></summary>
        <author>
            <name>Chin-Chun Chang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Face Forgery Detection by 3D Decomposition and Composition Search]]></title>
        <id>https://ieeexplore.ieee.org/document/10005010</id>
        <link href="https://ieeexplore.ieee.org/document/10005010"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Detecting digital face manipulation has attracted extensive attention due to fake media&#39;s potential risks to the public. However, recent advances have been able to reduce the forgery signals to a low magnitude. Decomposition, which reversibly decomposes an image into several constituent elements, is a promising way to highlight the hidden forgery details. In this paper, we investigate a novel 3D d...]]></summary>
        <author>
            <name>Xiangyu Zhu</name>
        </author>
        <author>
            <name>Hongyan Fei</name>
        </author>
        <author>
            <name>Bin Zhang</name>
        </author>
        <author>
            <name>Tianshuo Zhang</name>
        </author>
        <author>
            <name>Xiaoyu Zhang</name>
        </author>
        <author>
            <name>Stan Z. Li</name>
        </author>
        <author>
            <name>Zhen Lei</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Implicit Functions for Dense 3D Shape Correspondence of Generic Objects]]></title>
        <id>https://ieeexplore.ieee.org/document/10004641</id>
        <link href="https://ieeexplore.ieee.org/document/10004641"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The objective of this paper is to learn dense 3D shape correspondence for topology-varying generic objects in an unsupervised manner. Conventional implicit functions estimate the occupancy of a 3D point given a shape latent code. Instead, our novel implicit function produces a probabilistic embedding to represent each 3D point in a part embedding space. Assuming the corresponding points are simila...]]></summary>
        <author>
            <name>Feng Liu</name>
        </author>
        <author>
            <name>Xiaoming Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Multi-Task Multi-Stage Transitional Training Framework for Neural Chat Translation]]></title>
        <id>https://ieeexplore.ieee.org/document/10003654</id>
        <link href="https://ieeexplore.ieee.org/document/10003654"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Neural chat translation (NCT) aims to translate a cross-lingual chat between speakers of different languages. Existing context-aware NMT models cannot achieve satisfactory performances due to the following inherent problems: 1) limited resources of annotated bilingual dialogues; 2) the neglect of modelling conversational properties; 3) training discrepancy between different stages. To address thes...]]></summary>
        <author>
            <name>Chulun Zhou</name>
        </author>
        <author>
            <name>Yunlong Liang</name>
        </author>
        <author>
            <name>Fandong Meng</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
        <author>
            <name>Jinan Xu</name>
        </author>
        <author>
            <name>Hongji Wang</name>
        </author>
        <author>
            <name>Min Zhang</name>
        </author>
        <author>
            <name>Jinsong Su</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[WebUAV-3 M: A Benchmark for Unveiling the Power of Million-Scale Deep UAV Tracking]]></title>
        <id>https://ieeexplore.ieee.org/document/10004511</id>
        <link href="https://ieeexplore.ieee.org/document/10004511"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Unmanned aerial vehicle (UAV) tracking is of great significance for a wide range of applications, such as delivery and agriculture. Previous benchmarks in this area mainly focused on small-scale tracking problems while ignoring the amounts of data, types of data modalities, diversities of target categories and scenarios, and evaluation protocols involved, greatly hiding the massive power of deep U...]]></summary>
        <author>
            <name>Chunhui Zhang</name>
        </author>
        <author>
            <name>Guanjie Huang</name>
        </author>
        <author>
            <name>Li Liu</name>
        </author>
        <author>
            <name>Shan Huang</name>
        </author>
        <author>
            <name>Yinan Yang</name>
        </author>
        <author>
            <name>Xiang Wan</name>
        </author>
        <author>
            <name>Shiming Ge</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HAKE: A Knowledge Engine Foundation for Human Activity Understanding]]></title>
        <id>https://ieeexplore.ieee.org/document/10002711</id>
        <link href="https://ieeexplore.ieee.org/document/10002711"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Human activity understanding is of widespread interest in artificial intelligence and spans diverse applications like health care and behavior analysis. Although there have been advances with deep learning, it remains challenging. The object recognition-like solutions usually try to map pixels to semantics directly, but activity patterns are much different from object patterns, thus hindering anot...]]></summary>
        <author>
            <name>Yong-Lu Li</name>
        </author>
        <author>
            <name>Xinpeng Liu</name>
        </author>
        <author>
            <name>Xiaoqian Wu</name>
        </author>
        <author>
            <name>Yizhuo Li</name>
        </author>
        <author>
            <name>Zuoyu Qiu</name>
        </author>
        <author>
            <name>Liang Xu</name>
        </author>
        <author>
            <name>Yue Xu</name>
        </author>
        <author>
            <name>Hao-Shu Fang</name>
        </author>
        <author>
            <name>Cewu Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reducing Spatial Labeling Redundancy for Active Semi-Supervised Crowd Counting]]></title>
        <id>https://ieeexplore.ieee.org/document/10002302</id>
        <link href="https://ieeexplore.ieee.org/document/10002302"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Labeling is onerous for crowd counting as it should annotate each individual in crowd images. Recently, several methods have been proposed for semi-supervised crowd counting to reduce the labeling efforts. Given a limited labeling budget, they typically select a few crowd images and densely label all individuals in each of them. Despite the promising results, we argue the None-or-All labeling stra...]]></summary>
        <author>
            <name>Yongtuo Liu</name>
        </author>
        <author>
            <name>Sucheng Ren</name>
        </author>
        <author>
            <name>Liangyu Chai</name>
        </author>
        <author>
            <name>Hanjie Wu</name>
        </author>
        <author>
            <name>Dan Xu</name>
        </author>
        <author>
            <name>Jing Qin</name>
        </author>
        <author>
            <name>Shengfeng He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[IC9600: A Benchmark Dataset for Automatic Image Complexity Assessment]]></title>
        <id>https://ieeexplore.ieee.org/document/9999482</id>
        <link href="https://ieeexplore.ieee.org/document/9999482"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Image complexity (IC) is an essential visual perception for human beings to understand an image. However, explicitly evaluating the IC is challenging, and has long been overlooked since, on the one hand, the evaluation of IC is relatively subjective due to its dependence on human perception, and on the other hand, the IC is semantic-dependent while real-world images are diverse. To facilitate the ...]]></summary>
        <author>
            <name>Tinglei Feng</name>
        </author>
        <author>
            <name>Yingjie Zhai</name>
        </author>
        <author>
            <name>Jufeng Yang</name>
        </author>
        <author>
            <name>Jie Liang</name>
        </author>
        <author>
            <name>Deng-Ping Fan</name>
        </author>
        <author>
            <name>Jing Zhang</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[High-Performance Transformer Tracking]]></title>
        <id>https://ieeexplore.ieee.org/document/9999490</id>
        <link href="https://ieeexplore.ieee.org/document/9999490"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Correlation has a critical role in the tracking field, especially in recent popular Siamese-based trackers. The correlation operation is a simple fusion method that considers the similarity between the template and the search region. However, the correlation operation is a local linear matching process, losing semantic information and easily falling into a local optimum, which may be the bottlenec...]]></summary>
        <author>
            <name>Xin Chen</name>
        </author>
        <author>
            <name>Bin Yan</name>
        </author>
        <author>
            <name>Jiawen Zhu</name>
        </author>
        <author>
            <name>Huchuan Lu</name>
        </author>
        <author>
            <name>Xiang Ruan</name>
        </author>
        <author>
            <name>Dong Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SignNet II: A Transformer-Based Two-Way Sign Language Translation Model]]></title>
        <id>https://ieeexplore.ieee.org/document/9999492</id>
        <link href="https://ieeexplore.ieee.org/document/9999492"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The role of a sign interpreting agent is to bridge the communication gap between the hearing-only and Deaf or Hard of Hearing communities by translating both from sign language to text and from text to sign language. Until now, much of the AI work in automated sign language processing has focused primarily on sign language to text translation, which puts the advantage mainly on the side of hearing...]]></summary>
        <author>
            <name>Lipisha Chaudhary</name>
        </author>
        <author>
            <name>Tejaswini Ananthanarayana</name>
        </author>
        <author>
            <name>Enjamamul Hoq</name>
        </author>
        <author>
            <name>Ifeoma Nwogu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Radiance Fields from Sparse RGB-D Images for High-Quality View Synthesis]]></title>
        <id>https://ieeexplore.ieee.org/document/9999509</id>
        <link href="https://ieeexplore.ieee.org/document/9999509"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The recently proposed neural radiance fields (NeRF) use a continuous function formulated as a multi-layer perceptron (MLP) to model the appearance and geometry of a 3D scene. This enables realistic synthesis of novel views, even for scenes with view dependent appearance. Many follow-up works have since extended NeRFs in different ways. However, a fundamental restriction of the method remains that ...]]></summary>
        <author>
            <name>Yu-Jie Yuan</name>
        </author>
        <author>
            <name>Yu-Kun Lai</name>
        </author>
        <author>
            <name>Yi-Hua Huang</name>
        </author>
        <author>
            <name>Leif Kobbelt</name>
        </author>
        <author>
            <name>Lin Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Polarimetric Multi-View Inverse Rendering]]></title>
        <id>https://ieeexplore.ieee.org/document/9999345</id>
        <link href="https://ieeexplore.ieee.org/document/9999345"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[A polarization camera has great potential for 3D reconstruction since the angle of polarization (AoP) and the degree of polarization (DoP) of reflected light are related to an object&#39;s surface normal. In this paper, we propose a novel 3D reconstruction method called Polarimetric Multi-View Inverse Rendering (Polarimetric MVIR) that effectively exploits geometric, photometric, and polarimetric cues...]]></summary>
        <author>
            <name>Jinyu Zhao</name>
        </author>
        <author>
            <name>Yusuke Monno</name>
        </author>
        <author>
            <name>Masatoshi Okutomi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simultaneously Optimizing Perturbations and Positions for Black-Box Adversarial Patch Attacks]]></title>
        <id>https://ieeexplore.ieee.org/document/9999043</id>
        <link href="https://ieeexplore.ieee.org/document/9999043"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Adversarial patch is an important form of real-world adversarial attack that brings serious risks to the robustness of deep neural networks. Previous methods generate adversarial patches by either optimizing their perturbation values while fixing the pasting position or manipulating the position while fixing the patch&#39;s content. This reveals that the positions and perturbations are both important ...]]></summary>
        <author>
            <name>Xingxing Wei</name>
        </author>
        <author>
            <name>Ying Guo</name>
        </author>
        <author>
            <name>Jie Yu</name>
        </author>
        <author>
            <name>Bo Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DaisyRec 2.0: Benchmarking Recommendation for Rigorous Evaluation]]></title>
        <id>https://ieeexplore.ieee.org/document/9999032</id>
        <link href="https://ieeexplore.ieee.org/document/9999032"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recently, one critical issue looms large in the field of recommender systems – there are no effective benchmarks for rigorous evaluation – which consequently leads to unreproducible evaluation and unfair comparison. We, therefore, conduct studies from the perspectives of practical theory and experiments, aiming at benchmarking recommendation for rigorous evaluation. Regarding the theoretical study...]]></summary>
        <author>
            <name>Zhu Sun</name>
        </author>
        <author>
            <name>Hui Fang</name>
        </author>
        <author>
            <name>Jie Yang</name>
        </author>
        <author>
            <name>Xinghua Qu</name>
        </author>
        <author>
            <name>Hongyang Liu</name>
        </author>
        <author>
            <name>Di Yu</name>
        </author>
        <author>
            <name>Yew-Soon Ong</name>
        </author>
        <author>
            <name>Jie Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ScoreMix: A Scalable Augmentation Strategy for Training GANs With Limited Data]]></title>
        <id>https://ieeexplore.ieee.org/document/9998118</id>
        <link href="https://ieeexplore.ieee.org/document/9998118"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Generative Adversarial Networks (GANs) typically suffer from overfitting when limited training data is available. To facilitate GAN training, current methods propose to use data-specific augmentation techniques. Despite the effectiveness, it is difficult for these methods to scale to practical applications. In this work, we present ScoreMix, a novel and scalable data augmentation approach for vari...]]></summary>
        <author>
            <name>Jie Cao</name>
        </author>
        <author>
            <name>Mandi Luo</name>
        </author>
        <author>
            <name>Junchi Yu</name>
        </author>
        <author>
            <name>Ming-Hsuan Yang</name>
        </author>
        <author>
            <name>Ran He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Patch-based Separable Transformer for Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9998115</id>
        <link href="https://ieeexplore.ieee.org/document/9998115"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The computational complexity of transformers limits it to be widely deployed onto frameworks for visual recognition. Recent work [9] significantly accelerates the network processing speed by reducing the resolution at the beginning of the network, however, it is still hard to be directly generalized onto other downstream tasks e.g. object detection and segmentation like CNN. In this paper, we pres...]]></summary>
        <author>
            <name>Shuyang Sun</name>
        </author>
        <author>
            <name>Xiaoyu Yue</name>
        </author>
        <author>
            <name>Hengshuang Zhao</name>
        </author>
        <author>
            <name>Philip H.S. Torr</name>
        </author>
        <author>
            <name>Song Bai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-supervised 3D Representation Learning of Dressed Humans from Social Media Videos]]></title>
        <id>https://ieeexplore.ieee.org/document/9996551</id>
        <link href="https://ieeexplore.ieee.org/document/9996551"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[A key challenge of learning a visual representation for the 3D high fidelity geometry of dressed humans lies in the limited availability of the ground truth data (e.g., 3D scanned models), which results in the performance degradation of 3D human reconstruction when applying to real-world imagery. We address this challenge by leveraging a new data resource: a number of social media dance videos tha...]]></summary>
        <author>
            <name>Yasamin Jafarian</name>
        </author>
        <author>
            <name>Hyun Soo Park</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Non-Graph Data Clustering via $\mathcal {O}(n)$ Bipartite Graph Convolution]]></title>
        <id>https://ieeexplore.ieee.org/document/9996549</id>
        <link href="https://ieeexplore.ieee.org/document/9996549"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Since the representative capacity of graph-based clustering methods is usually limited by the graph constructed on the original features, it is attractive to find whether graph neural networks (GNNs), a strong extension of neural networks to graphs, can be applied to augment the capacity of graph-based clustering methods. The core problems mainly come from two aspects. On the one hand, the graph i...]]></summary>
        <author>
            <name>Hongyuan Zhang</name>
        </author>
        <author>
            <name>Jiankun Shi</name>
        </author>
        <author>
            <name>Rui Zhang</name>
        </author>
        <author>
            <name>Xuelong Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Task-Aware Weakly Supervised Object Localization With Transformer]]></title>
        <id>https://ieeexplore.ieee.org/document/9996553</id>
        <link href="https://ieeexplore.ieee.org/document/9996553"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Weakly supervised object localization (WSOL) aims to predict both object locations and categories with only image-level class labels. However, most existing methods rely on class-specific image regions for localization, resulting in incomplete object localization. To alleviate this problem, we propose a novel end-to-end task-aware framework with a transformer encoder-decoder architecture (TAFormer...]]></summary>
        <author>
            <name>Meng Meng</name>
        </author>
        <author>
            <name>Tianzhu Zhang</name>
        </author>
        <author>
            <name>Zhe Zhang</name>
        </author>
        <author>
            <name>Yongdong Zhang</name>
        </author>
        <author>
            <name>Feng Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What Makes for Good Tokenizers in Vision Transformer?]]></title>
        <id>https://ieeexplore.ieee.org/document/9996581</id>
        <link href="https://ieeexplore.ieee.org/document/9996581"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[The architecture of transformers, which recently witness booming applications in vision tasks, has pivoted against the widespread convolutional paradigm. Relying on the tokenization process that splits inputs into multiple tokens, transformers are capable of extracting their pairwise relationships using self-attention. While being the stemming building block of transformers, what makes for a good ...]]></summary>
        <author>
            <name>Shengju Qian</name>
        </author>
        <author>
            <name>Yi Zhu</name>
        </author>
        <author>
            <name>Wenbo Li</name>
        </author>
        <author>
            <name>Mu Li</name>
        </author>
        <author>
            <name>Jiaya Jia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reference-based Image and Video Super-Resolution via $C^{2}$-Matching]]></title>
        <id>https://ieeexplore.ieee.org/document/9996154</id>
        <link href="https://ieeexplore.ieee.org/document/9996154"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising paradigm to enhance a low-resolution (LR) input image or video by introducing an additional high-resolution (HR) reference image. Existing Ref-SR methods mostly rely on implicit correspondence matching to borrow HR textures from reference images to compensate for the information loss in input images. However, performing ...]]></summary>
        <author>
            <name>Yuming Jiang</name>
        </author>
        <author>
            <name>Kelvin C.K. Chan</name>
        </author>
        <author>
            <name>Xintao Wang</name>
        </author>
        <author>
            <name>Chen Change Loy</name>
        </author>
        <author>
            <name>Ziwei Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Knowledge-enriched Attention Network with Group-wise Semantic for Visual Storytelling]]></title>
        <id>https://ieeexplore.ieee.org/document/9996128</id>
        <link href="https://ieeexplore.ieee.org/document/9996128"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[As a technically challenging topic, visual storytelling aims at generating an imaginary and coherent story with narrative multi-sentences from a group of relevant images. Existing methods often generate direct and rigid descriptions of apparent image-based contents, because they are not capable of exploring implicit information beyond images. Hence, these schemes could not capture consistent depen...]]></summary>
        <author>
            <name>Tengpeng Li</name>
        </author>
        <author>
            <name>Hanli Wang</name>
        </author>
        <author>
            <name>Bin He</name>
        </author>
        <author>
            <name>Chang Wen Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Formulating Event-based Image Reconstruction as a Linear Inverse Problem with Deep Regularization using Optical Flow]]></title>
        <id>https://ieeexplore.ieee.org/document/9994038</id>
        <link href="https://ieeexplore.ieee.org/document/9994038"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <author>
            <name>Zelin Zhang</name>
        </author>
        <author>
            <name>Anthony Yezzi</name>
        </author>
        <author>
            <name>Guillermo Gallego</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Deep Framework for Hyperspectral Image Fusion between Different Satellites]]></title>
        <id>https://ieeexplore.ieee.org/document/9992028</id>
        <link href="https://ieeexplore.ieee.org/document/9992028"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recently, fusing a low-resolution hyperspectral image (LR-HSI) with a high-resolution multispectral image (HR-MSI) of different satellites has become an effective way to improve the resolution of an HSI. However, due to different imaging satellites, different illumination, and adjacent imaging time, the LR-HSI and HR-MSI may not satisfy the observation models established by existing works, and the...]]></summary>
        <author>
            <name>Anjing Guo</name>
        </author>
        <author>
            <name>Renwei Dian</name>
        </author>
        <author>
            <name>Shutao Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quantformer: Learning Extremely Low-precision Vision Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/9992209</id>
        <link href="https://ieeexplore.ieee.org/document/9992209"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this paper, we propose extremely low-precision vision transformers called Quantformer for efficient inference. Conventional network quantization methods directly quantize weights and activations of fully-connected layers without considering properties of transformer architectures. Quantization sizably deviates the self-attention compared with full-precision counterparts, and the shared quantiza...]]></summary>
        <author>
            <name>Ziwei Wang</name>
        </author>
        <author>
            <name>Changyuan Wang</name>
        </author>
        <author>
            <name>Xiuwei Xu</name>
        </author>
        <author>
            <name>Jie Zhou</name>
        </author>
        <author>
            <name>Jiwen Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global Learnable Attention for Single Image Super-Resolution]]></title>
        <id>https://ieeexplore.ieee.org/document/9992208</id>
        <link href="https://ieeexplore.ieee.org/document/9992208"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Self-similarity is valuable to the exploration of non-local textures in single image super-resolution (SISR). Researchers usually assume that the importance of non-local textures is positively related to their similarity scores. In this paper, we surprisingly found that when repairing severely damaged query textures, some non-local textures with low-similarity which are closer to the target can pr...]]></summary>
        <author>
            <name>Jian-Nan Su</name>
        </author>
        <author>
            <name>Min Gan</name>
        </author>
        <author>
            <name>Guang-Yong Chen</name>
        </author>
        <author>
            <name>Jia-Li Yin</name>
        </author>
        <author>
            <name>C. L. Philip Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Label Classification via Adaptive Resonance Theory-Based Clustering]]></title>
        <id>https://ieeexplore.ieee.org/document/9992110</id>
        <link href="https://ieeexplore.ieee.org/document/9992110"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[This paper proposes a multi-label classification algorithm capable of continual learning by applying an Adaptive Resonance Theory (ART)-based clustering algorithm and the Bayesian approach for label probability computation. The ART-based clustering algorithm adaptively and continually generates prototype nodes corresponding to given data, and the generated nodes are used as classifiers. The label ...]]></summary>
        <author>
            <name>Naoki Masuyama</name>
        </author>
        <author>
            <name>Yusuke Nojima</name>
        </author>
        <author>
            <name>Chu Kiong Loo</name>
        </author>
        <author>
            <name>Hisao Ishibuchi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Siamese Tracking with a Compact Latent Network]]></title>
        <id>https://ieeexplore.ieee.org/document/9991898</id>
        <link href="https://ieeexplore.ieee.org/document/9991898"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In this paper, we provide an intuitive viewing to simplify the Siamese-based trackers by converting the tracking task to a classification. Under this viewing, we perform an in-depth analysis for them through visual simulations and real tracking examples, and find that the failure cases in some challenging situations can be regarded as the issue of missing decisive samples in offline training. Sinc...]]></summary>
        <author>
            <name>Xingping Dong</name>
        </author>
        <author>
            <name>Jianbing Shen</name>
        </author>
        <author>
            <name>Fatih Porikli</name>
        </author>
        <author>
            <name>Jiebo Luo</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic and Relation Modulation for Audio-Visual Event Localization]]></title>
        <id>https://ieeexplore.ieee.org/document/9990903</id>
        <link href="https://ieeexplore.ieee.org/document/9990903"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[We study the problem of localizing audio-visual events that are both audible and visible in a video. Existing works focus on encoding and aligning audio and visual features at the segment level while neglecting informative correlation between segments of the two modalities and between multi-scale event proposals. We propose a novel Semantic and Relation Modulation Network (SRMN) to learn the above...]]></summary>
        <author>
            <name>Hao Wang</name>
        </author>
        <author>
            <name>Zheng-Jun Zha</name>
        </author>
        <author>
            <name>Liang Li</name>
        </author>
        <author>
            <name>Xuejin Chen</name>
        </author>
        <author>
            <name>Jiebo Luo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TransZero++: Cross Attribute-Guided Transformer for Zero-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9987664</id>
        <link href="https://ieeexplore.ieee.org/document/9987664"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Zero-shot learning (ZSL) tackles the novel class recognition problem by transferring semantic knowledge from seen classes to unseen ones. Semantic knowledge is typically represented by attribute descriptions shared between different classes, which act as strong priors for localizing object attributes that represent discriminative region features, enabling significant and sufficient visual-semantic...]]></summary>
        <author>
            <name>Shiming Chen</name>
        </author>
        <author>
            <name>Ziming Hong</name>
        </author>
        <author>
            <name>Wenjin Hou</name>
        </author>
        <author>
            <name>Guo-Sen Xie</name>
        </author>
        <author>
            <name>Yibing Song</name>
        </author>
        <author>
            <name>Jian Zhao</name>
        </author>
        <author>
            <name>Xinge You</name>
        </author>
        <author>
            <name>Shuicheng Yan</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revealing the Distributional Vulnerability of Discriminators by Implicit Generators]]></title>
        <id>https://ieeexplore.ieee.org/document/9987694</id>
        <link href="https://ieeexplore.ieee.org/document/9987694"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[In deep neural learning, a discriminator trained on in-distribution (ID) samples may make high-confidence predictions on out-of-distribution (OOD) samples. This triggers a significant matter for robust, trustworthy and safe deep learning. The issue is primarily caused by the limited ID samples observable in training the discriminator when OOD samples are unavailable. We propose a general approach ...]]></summary>
        <author>
            <name>Zhilin Zhao</name>
        </author>
        <author>
            <name>Longbing Cao</name>
        </author>
        <author>
            <name>Kun-Yu Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Survey: Leakage and Privacy at Inference Time]]></title>
        <id>https://ieeexplore.ieee.org/document/9987657</id>
        <link href="https://ieeexplore.ieee.org/document/9987657"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Leakage of data from publicly available Machine Learning (ML) models is an area of growing significance since commercial and government applications of ML can draw on multiple sources of data, potentially including users&#39; and clients&#39; sensitive data. We provide a comprehensive survey of contemporary advances on several fronts, covering involuntary data leakage which is natural to ML models, potent...]]></summary>
        <author>
            <name>Marija Jegorova</name>
        </author>
        <author>
            <name>Chaitanya Kaul</name>
        </author>
        <author>
            <name>Charlie Mayor</name>
        </author>
        <author>
            <name>Alison Q. O'Neil</name>
        </author>
        <author>
            <name>Alexander Weir</name>
        </author>
        <author>
            <name>Roderick Murray-Smith</name>
        </author>
        <author>
            <name>Sotirios A. Tsaftaris</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[I2F: A Unified Image-to-Feature Approach for Domain Adaptive Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9984933</id>
        <link href="https://ieeexplore.ieee.org/document/9984933"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Unsupervised domain adaptation (UDA) for semantic segmentation is a promising task freeing people from heavy annotation work. However, domain discrepancies in low-level image statistics and high-level contexts compromise the segmentation performance over the target domain. A key idea to tackle this problem is to perform both image-level and feature-level adaptation jointly. Unfortunately, there is...]]></summary>
        <author>
            <name>Haoyu Ma</name>
        </author>
        <author>
            <name>Xiangru Lin</name>
        </author>
        <author>
            <name>Yizhou Yu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Split-GCN: Effective Interactive Annotation for Segmentation of Disconnected Instance]]></title>
        <id>https://ieeexplore.ieee.org/document/9984937</id>
        <link href="https://ieeexplore.ieee.org/document/9984937"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Annotating object boundaries by humans demands high costs. Recently, polygon-based annotation methods with human interaction have shown successful performance. However, given the connected vertex topology, these methods exhibit difficulty predicting the disconnected components in an object. This paper introduces Split-GCN, a novel architecture based on the polygon approach and self-attention mecha...]]></summary>
        <author>
            <name>Namgil Kim</name>
        </author>
        <author>
            <name>Barom Kang</name>
        </author>
        <author>
            <name>Yeonok Cho</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Depth Completion from Extremely Sparse Data: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9984942</id>
        <link href="https://ieeexplore.ieee.org/document/9984942"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Depth completion aims at predicting dense pixel-wise depth from an extremely sparse map captured from a depth sensor, e.g., LiDARs. It plays an essential role in various applications such as autonomous driving, 3D reconstruction, augmented reality, and robot navigation. Recent successes on the task have been demonstrated and dominated by deep learning based solutions. In this article, for the firs...]]></summary>
        <author>
            <name>Junjie Hu</name>
        </author>
        <author>
            <name>Chenyu Bao</name>
        </author>
        <author>
            <name>Mete Ozay</name>
        </author>
        <author>
            <name>Chenyou Fan</name>
        </author>
        <author>
            <name>Qing Gao</name>
        </author>
        <author>
            <name>Honghai Liu</name>
        </author>
        <author>
            <name>Tin Lun Lam</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orthogonal SVD Covariance Conditioning and Latent Disentanglement]]></title>
        <id>https://ieeexplore.ieee.org/document/9983471</id>
        <link href="https://ieeexplore.ieee.org/document/9983471"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Inserting an SVD meta-layer into neural networks is prone to make the covariance ill-conditioned, which could harm the model in the training stability and generalization abilities. In this paper, we systematically study how to improve the covariance conditioning by enforcing orthogonality to the Pre-SVD layer. Existing orthogonal treatments on the weights are first investigated. However, these tec...]]></summary>
        <author>
            <name>Yue Song</name>
        </author>
        <author>
            <name>Nicu Sebe</name>
        </author>
        <author>
            <name>Wei Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Unifying Probabilistic Framework for Partially Labeled Data Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9983986</id>
        <link href="https://ieeexplore.ieee.org/document/9983986"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Partially labeled data learning (PLDL), including partial label learning (PLL) and partial multi-label learning (PML), has been widely used in nowadays data science. Researchers attempt to construct different specific models to deal with the different classification tasks for PLL and PML scenarios respectively. The main challenge in training classifiers for PLL and PML is how to deal with ambiguit...]]></summary>
        <author>
            <name>Xiuwen Gong</name>
        </author>
        <author>
            <name>Dong Yuan</name>
        </author>
        <author>
            <name>Wei Bao</name>
        </author>
        <author>
            <name>Fulin Luo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[E2E-FS: An End-to-End Feature Selection Method for Neural Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9983480</id>
        <link href="https://ieeexplore.ieee.org/document/9983480"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Classic embedded feature selection algorithms are often divided in two large groups: tree-based algorithms and LASSO variants. Both approaches are focused in different aspects: while the tree-based algorithms provide a clear explanation about which variables are being used to trigger a certain output, LASSO-like approaches sacrifice a detailed explanation in favor of increasing its accuracy. In th...]]></summary>
        <author>
            <name>Brais Cancela</name>
        </author>
        <author>
            <name>Verónica Bolón-Canedo</name>
        </author>
        <author>
            <name>Amparo Alonso-Betanzos</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms]]></title>
        <id>https://ieeexplore.ieee.org/document/9983478</id>
        <link href="https://ieeexplore.ieee.org/document/9983478"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[This paper focuses on conditional generative modeling (CGM) for image data with continuous, scalar conditions (termed regression labels). We propose the first model for this task which is called continuous conditional generative adversarial network (CcGAN). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels). Conditioning on regression labels is ma...]]></summary>
        <author>
            <name>Xin Ding</name>
        </author>
        <author>
            <name>Yongwei Wang</name>
        </author>
        <author>
            <name>Zuheng Xu</name>
        </author>
        <author>
            <name>William J. Welch</name>
        </author>
        <author>
            <name>Z. Jane Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EPNet++: Cascade Bi-Directional Fusion for Multi-Modal 3D Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/9983516</id>
        <link href="https://ieeexplore.ieee.org/document/9983516"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Recently, fusing the LiDAR point cloud and camera image to improve the performance and robustness of 3D object detection has received more and more attention, as these two modalities naturally possess strong complementarity. In this paper, we propose EPNet++ for multi-modal 3D object detection by introducing a novel Cascade Bi-directional Fusion (CB-Fusion) module and a Multi-Modal Consistency (MC...]]></summary>
        <author>
            <name>Zhe Liu</name>
        </author>
        <author>
            <name>Tengteng Huang</name>
        </author>
        <author>
            <name>Bingling Li</name>
        </author>
        <author>
            <name>Xiwu Chen</name>
        </author>
        <author>
            <name>Xi Wang</name>
        </author>
        <author>
            <name>Xiang Bai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Partial Domain Adaptation without Domain Alignment]]></title>
        <id>https://ieeexplore.ieee.org/document/9983498</id>
        <link href="https://ieeexplore.ieee.org/document/9983498"/>
        <updated>2023-04-27T04:15:42.608Z</updated>
        <summary type="html"><![CDATA[Unsupervised domain adaptation (UDA) aims to transfer knowledge from a well-labeled source domain to a related and unlabeled target domain with identical label space. The main workhorse in UDA is domain alignment and has proven successful. However, it is practically difficult to find an appropriate source domain with identical label space. A more practical scenario is partial domain adaptation (PD...]]></summary>
        <author>
            <name>Weikai Li</name>
        </author>
        <author>
            <name>Songcan Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentially Private Graph Neural Networks for Whole-Graph Classification]]></title>
        <id>https://ieeexplore.ieee.org/document/9980390</id>
        <link href="https://ieeexplore.ieee.org/document/9980390"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graph Neural Networks (GNNs) have established themselves as state-of-the-art for many machine learning applications such as the analysis of social and medical networks. Several among these datasets contain privacy-sensitive data. Machine learning with differential privacy is a promising technique to allow deriving insight from sensitive data while offering formal guarantees of privacy protection. ...]]></summary>
        <author>
            <name>Tamara T. Mueller</name>
        </author>
        <author>
            <name>Johannes C. Paetzold</name>
        </author>
        <author>
            <name>Chinmay Prabhakar</name>
        </author>
        <author>
            <name>Dmitrii Usynin</name>
        </author>
        <author>
            <name>Daniel Rueckert</name>
        </author>
        <author>
            <name>Georgios Kaissis</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PoseBERT: A Generic Transformer Module for Temporal 3D Human Modeling]]></title>
        <id>https://ieeexplore.ieee.org/document/9982410</id>
        <link href="https://ieeexplore.ieee.org/document/9982410"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Training state-of-the-art models for human pose estimation in videos requires datasets with annotations that are really hard and expensive to obtain. Although transformers have been recently utilized for body pose sequence modeling, related methods rely on pseudo-ground truth to augment the currently limited training data available for learning such models. In this paper, we introduce PoseBERT, a ...]]></summary>
        <author>
            <name>Fabien Baradel</name>
        </author>
        <author>
            <name>Romain Brégier</name>
        </author>
        <author>
            <name>Thibault Groueix</name>
        </author>
        <author>
            <name>Philippe Weinzaepfel</name>
        </author>
        <author>
            <name>Yannis Kalantidis</name>
        </author>
        <author>
            <name>Grégory Rogez</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Generic Graph-Based Neural Architecture Encoding Scheme With Multifaceted Information]]></title>
        <id>https://ieeexplore.ieee.org/document/9982412</id>
        <link href="https://ieeexplore.ieee.org/document/9982412"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Neural architecture search (NAS) can automatically discover well-performing architectures in a large search space and has been shown to bring improvements to various applications. However, the computational burden of NAS is huge, since exploring a large search space can need evaluating more than thousands of architecture samples. To improve the sample efficiency of search space exploration, predic...]]></summary>
        <author>
            <name>Xuefei Ning</name>
        </author>
        <author>
            <name>Yin Zheng</name>
        </author>
        <author>
            <name>Zixuan Zhou</name>
        </author>
        <author>
            <name>Tianchen Zhao</name>
        </author>
        <author>
            <name>Huazhong Yang</name>
        </author>
        <author>
            <name>Yu Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Orientational Distribution Learning with Hierarchical Spatial Attention for Open Set Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9978641</id>
        <link href="https://ieeexplore.ieee.org/document/9978641"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Open set recognition (OSR) aims to correctly recognize the known classes and reject the unknown classes for increasing the reliability of the recognition system. The distance-based loss is often employed in deep neural networks-based OSR methods to constrain the latent representation of known classes. However, the optimization is usually conducted using the nondirectional Euclidean distance in a s...]]></summary>
        <author>
            <name>Zhun-ga Liu</name>
        </author>
        <author>
            <name>Yi-min Fu</name>
        </author>
        <author>
            <name>Quan Pan</name>
        </author>
        <author>
            <name>Zuo-wei Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open World Entity Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9976289</id>
        <link href="https://ieeexplore.ieee.org/document/9976289"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We introduce a new image segmentation task, called Entity Segmentation (ES), which aims to segment all visual entities (objects and stuffs) in an image without predicting their semantic labels. By removing the need of class label prediction, the models trained for such task can focus more on improving segmentation quality. It has many practical applications such as image manipulation and editing w...]]></summary>
        <author>
            <name>Lu Qi</name>
        </author>
        <author>
            <name>Jason Kuen</name>
        </author>
        <author>
            <name>Yi Wang</name>
        </author>
        <author>
            <name>Jiuxiang Gu</name>
        </author>
        <author>
            <name>Hengshuang Zhao</name>
        </author>
        <author>
            <name>Philip Torr</name>
        </author>
        <author>
            <name>Zhe Lin</name>
        </author>
        <author>
            <name>Jiaya Jia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Trustworthy are Performance Evaluations for Basic Vision Tasks?]]></title>
        <id>https://ieeexplore.ieee.org/document/9976259</id>
        <link href="https://ieeexplore.ieee.org/document/9976259"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This paper examines performance evaluation criteria for basic vision tasks involving sets of objects namely, object detection, instance-level segmentation and multi-object tracking. The rankings of algorithms by an existing criterion can fluctuate with different choices of parameters, e.g. Intersection over Union (IoU) threshold, making their evaluations unreliable. More importantly, there is no m...]]></summary>
        <author>
            <name>Tran Thien Dat Nguyen</name>
        </author>
        <author>
            <name>Hamid Rezatofighi</name>
        </author>
        <author>
            <name>Ba-Ngu Vo</name>
        </author>
        <author>
            <name>Ba-Tuong Vo</name>
        </author>
        <author>
            <name>Silvio Savarese</name>
        </author>
        <author>
            <name>Ian Reid</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BoostTree and BoostForest for Ensemble Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9973329</id>
        <link href="https://ieeexplore.ieee.org/document/9973329"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Bootstrap aggregating (Bagging) and boosting are two popular ensemble learning approaches, which combine multiple base learners to generate a composite model for more accurate and more reliable performance. They have been widely used in biology, engineering, healthcare, etc. This paper proposes BoostForest, which is an ensemble learning approach using BoostTree as base learners and can be used for...]]></summary>
        <author>
            <name>Changming Zhao</name>
        </author>
        <author>
            <name>Dongrui Wu</name>
        </author>
        <author>
            <name>Jian Huang</name>
        </author>
        <author>
            <name>Ye Yuan</name>
        </author>
        <author>
            <name>Hai-Tao Zhang</name>
        </author>
        <author>
            <name>Ruimin Peng</name>
        </author>
        <author>
            <name>Zhenhua Shi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to See Through with Events]]></title>
        <id>https://ieeexplore.ieee.org/document/9973388</id>
        <link href="https://ieeexplore.ieee.org/document/9973388"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Although synthetic aperture imaging (SAI) can achieve the seeing-through effect by blurring out off-focus foreground occlusions while recovering in-focus occluded scenes from multi-view images, its performance is often deteriorated by dense occlusions and extreme lighting conditions. To address the problem, this paper presents an Event-based SAI (E-SAI) method by relying on the asynchronous events...]]></summary>
        <author>
            <name>Lei Yu</name>
        </author>
        <author>
            <name>Xiang Zhang</name>
        </author>
        <author>
            <name>Wei Liao</name>
        </author>
        <author>
            <name>Wen Yang</name>
        </author>
        <author>
            <name>Gui-Song Xia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interactive Object Segmentation with Inside-Outside Guidance]]></title>
        <id>https://ieeexplore.ieee.org/document/9971769</id>
        <link href="https://ieeexplore.ieee.org/document/9971769"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This work explores how to harvest precise object segmentation masks while minimizing the human interaction cost. To achieve this, we propose a simple yet effective interaction scheme, named Inside-Outside Guidance (IOG). Concretely, we leverage an inside point that is clicked near the object center and two outside points at the symmetrical corner locations (top-left and bottom-right or top-right a...]]></summary>
        <author>
            <name>Shiyin Zhang</name>
        </author>
        <author>
            <name>Shikui Wei</name>
        </author>
        <author>
            <name>Jun Hao Liew</name>
        </author>
        <author>
            <name>Kunyang Han</name>
        </author>
        <author>
            <name>Yao Zhao</name>
        </author>
        <author>
            <name>Yunchao Wei</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Lightweight Pixel-Wise Hallucination for Heterogeneous Face Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9971748</id>
        <link href="https://ieeexplore.ieee.org/document/9971748"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Cross-spectral face hallucination is an intuitive way to mitigate the modality discrepancy in Heterogeneous Face Recognition (HFR). However, due to imaging differences, the hallucination inevitably suffers from a shape misalignment between paired heterogeneous images. Rather than building complicated architectures to circumvent the problem like previous works, we propose a simple yet effective met...]]></summary>
        <author>
            <name>Chaoyou Fu</name>
        </author>
        <author>
            <name>Xiaoqiang Zhou</name>
        </author>
        <author>
            <name>Weizan He</name>
        </author>
        <author>
            <name>Ran He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Searching for Network Width With Bilaterally Coupled Network]]></title>
        <id>https://ieeexplore.ieee.org/document/9970301</id>
        <link href="https://ieeexplore.ieee.org/document/9970301"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Searching for a more compact network width recently serves as an effective way of channel pruning for the deployment of convolutional neural networks (CNNs) under hardware constraints. To fulfil the searching, a one-shot supernet is usually leveraged to efficiently evaluate the performance w.r.t. different network widths. However, current methods mainly follow a unilaterally augmented (UA) princip...]]></summary>
        <author>
            <name>Xiu Su</name>
        </author>
        <author>
            <name>Shan You</name>
        </author>
        <author>
            <name>Jiyang Xie</name>
        </author>
        <author>
            <name>Fei Wang</name>
        </author>
        <author>
            <name>Chen Qian</name>
        </author>
        <author>
            <name>Changshui Zhang</name>
        </author>
        <author>
            <name>Chang Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A New Outlier Removal Strategy Based on Reliability of Correspondence Graph for Fast Point Cloud Registration]]></title>
        <id>https://ieeexplore.ieee.org/document/9969937</id>
        <link href="https://ieeexplore.ieee.org/document/9969937"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Registration is a basic yet crucial task in point cloud processing. In correspondence-based point cloud registration, matching correspondences by point feature techniques may lead to an extremely high outlier (false correspondence) ratio. Current outlier removal methods still suffer from low efficiency, accuracy, and recall rate. We use an intuitive method to describe the 6-DOF (degree of freedom)...]]></summary>
        <author>
            <name>Li Yan</name>
        </author>
        <author>
            <name>Pengcheng Wei</name>
        </author>
        <author>
            <name>Hong Xie</name>
        </author>
        <author>
            <name>Jicheng Dai</name>
        </author>
        <author>
            <name>Hao Wu</name>
        </author>
        <author>
            <name>Ming Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Time Warping based Adversarial Framework for Time-Series Domain]]></title>
        <id>https://ieeexplore.ieee.org/document/9970291</id>
        <link href="https://ieeexplore.ieee.org/document/9970291"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Despite the rapid progress on research in adversarial robustness of deep neural networks (DNNs), there is little principled work for the time-series domain. Since time-series data arises in diverse applications including mobile health, finance, and smart grid, it is important to verify and improve the robustness of DNNs for the time-series domain. In this paper, we propose a novel framework for th...]]></summary>
        <author>
            <name>Taha Belkhouja</name>
        </author>
        <author>
            <name>Yan Yan</name>
        </author>
        <author>
            <name>Janardhan Rao Doppa</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Invariance from Generated Variance for Unsupervised Person Re-identification]]></title>
        <id>https://ieeexplore.ieee.org/document/9970293</id>
        <link href="https://ieeexplore.ieee.org/document/9970293"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This work focuses on unsupervised representation learning in person re-identification (ReID). Recent self-supervised contrastive learning methods learn invariance by maximizing the representation similarity between two augmented views of a same image. However, traditional data augmentation may bring to the fore undesirable distortions on identity features, which is not always favorable in id-sensi...]]></summary>
        <author>
            <name>Hao Chen</name>
        </author>
        <author>
            <name>Yaohui Wang</name>
        </author>
        <author>
            <name>Benoit Lagadec</name>
        </author>
        <author>
            <name>Antitza Dantcheva</name>
        </author>
        <author>
            <name>Francois Bremond</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rank-One Prior: Real-Time Scene Recovery]]></title>
        <id>https://ieeexplore.ieee.org/document/9969127</id>
        <link href="https://ieeexplore.ieee.org/document/9969127"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Scene recovery is a fundamental imaging task with several practical applications, including video surveillance and autonomous vehicles, etc. In this paper, we provide a new real-time scene recovery framework to restore degraded images under different weather/imaging conditions, such as underwater, sand dust and haze. A degraded image can actually be seen as a superimposition of a clear image with ...]]></summary>
        <author>
            <name>Jun Liu</name>
        </author>
        <author>
            <name>Ryan Wen Liu</name>
        </author>
        <author>
            <name>Jianing Sun</name>
        </author>
        <author>
            <name>Tieyong Zeng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Trifocal Relative Pose From Lines at Points]]></title>
        <id>https://ieeexplore.ieee.org/document/9969132</id>
        <link href="https://ieeexplore.ieee.org/document/9969132"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present a method for solving two minimal problems for relative camera pose estimation from three views, which are based on three view correspondences of (i) three points and one line and the novel case of (ii) three points and two lines through two of the points. These problems are too difficult to be efficiently solved by the state of the art Gröbner basis methods. Our method is based on a new...]]></summary>
        <author>
            <name>Ricardo Fabbri</name>
        </author>
        <author>
            <name>Timothy Duff</name>
        </author>
        <author>
            <name>Hongyi Fan</name>
        </author>
        <author>
            <name>Margaret H. Regan</name>
        </author>
        <author>
            <name>David da C. de Pinho</name>
        </author>
        <author>
            <name>Elias Tsigaridas</name>
        </author>
        <author>
            <name>Charles W. Wampler</name>
        </author>
        <author>
            <name>Jonathan D. Hauenstein</name>
        </author>
        <author>
            <name>Peter J. Giblin</name>
        </author>
        <author>
            <name>Benjamin Kimia</name>
        </author>
        <author>
            <name>Anton Leykin</name>
        </author>
        <author>
            <name>Tomas Pajdla</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimising for Interpretability: Convolutional Dynamic Alignment Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9968133</id>
        <link href="https://ieeexplore.ieee.org/document/9968133"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks (CoDA Nets), which are performant classifiers with a high degree of inherent interpretability. Their core building blocks are Dynamic Alignment Units (DAUs), which are optimised to transform their inputs with dynamically computed weight vectors that align with task-relevant patterns. As a result, CoD...]]></summary>
        <author>
            <name>Moritz Böhle</name>
        </author>
        <author>
            <name>Mario Fritz</name>
        </author>
        <author>
            <name>Bernt Schiele</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Sparse Tensor-Based Multiscale Representation for Point Cloud Geometry Compression]]></title>
        <id>https://ieeexplore.ieee.org/document/9968173</id>
        <link href="https://ieeexplore.ieee.org/document/9968173"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This study develops a unified Point Cloud Geometry (PCG) compression method through the processing of multiscale sparse tensor-based voxelized PCG. We call this compression method SparsePCGC. The proposed SparsePCGC is a low complexity solution because it only performs the convolutions on sparsely-distributed Most-Probable Positively-Occupied Voxels (MP-POV). The multiscale representation also all...]]></summary>
        <author>
            <name>Jianqiang Wang</name>
        </author>
        <author>
            <name>Dandan Ding</name>
        </author>
        <author>
            <name>Zhu Li</name>
        </author>
        <author>
            <name>Xiaoxing Feng</name>
        </author>
        <author>
            <name>Chuntong Cao</name>
        </author>
        <author>
            <name>Zhan Ma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[GH-Feat: Learning Versatile Generative Hierarchical Features From GANs]]></title>
        <id>https://ieeexplore.ieee.org/document/9968154</id>
        <link href="https://ieeexplore.ieee.org/document/9968154"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recent years witness the tremendous success of generative adversarial networks (GANs) in synthesizing photo-realistic images. GAN generator learns to compose realistic images and reproduce the real data distribution. Through that, a hierarchical visual feature with multi-level semantics spontaneously emerges. In this work we investigate that such a generative feature learned from image synthesis e...]]></summary>
        <author>
            <name>Yinghao Xu</name>
        </author>
        <author>
            <name>Yujun Shen</name>
        </author>
        <author>
            <name>Jiapeng Zhu</name>
        </author>
        <author>
            <name>Ceyuan Yang</name>
        </author>
        <author>
            <name>Bolei Zhou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Survey on Deep Learning Technique for Video Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9966836</id>
        <link href="https://ieeexplore.ieee.org/document/9966836"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Video segmentation—partitioning video frames into multiple segments or objects—plays a critical role in a broad range of practical applications, from enhancing visual effects in movie, to understanding scenes in autonomous driving, to creating virtual background in video conferencing. Recently, with the renaissance of connectionism in computer vision, there has been an influx of deep learning base...]]></summary>
        <author>
            <name>Tianfei Zhou</name>
        </author>
        <author>
            <name>Fatih Porikli</name>
        </author>
        <author>
            <name>David J. Crandall</name>
        </author>
        <author>
            <name>Luc Van Gool</name>
        </author>
        <author>
            <name>Wenguan Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Point Cloud Segmentation with Noisy Annotations]]></title>
        <id>https://ieeexplore.ieee.org/document/9966842</id>
        <link href="https://ieeexplore.ieee.org/document/9966842"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Point cloud segmentation is a fundamental task in 3D. Despite recent progress on point cloud segmentation with the power of deep networks, current learning methods based on the clean label assumptions may fail with noisy labels. Yet, class labels are often mislabeled at both instance-level and boundary-level in real-world datasets. In this work, we take the lead in solving the instance-level label...]]></summary>
        <author>
            <name>Shuquan Ye</name>
        </author>
        <author>
            <name>Dongdong Chen</name>
        </author>
        <author>
            <name>Songfang Han</name>
        </author>
        <author>
            <name>Jing Liao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Structure Evolution on Manifold for Graph Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9966846</id>
        <link href="https://ieeexplore.ieee.org/document/9966846"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graph has been widely used in various applications, while how to optimize the graph is still an open question. In this paper, we propose a framework to optimize the graph structure via structure evolution on graph manifold. We first define the graph manifold and search the best graph structure on this manifold. Concretely, associated with the data features and the prediction results of a given tas...]]></summary>
        <author>
            <name>Hai Wan</name>
        </author>
        <author>
            <name>Xinwei Zhang</name>
        </author>
        <author>
            <name>Yubo Zhang</name>
        </author>
        <author>
            <name>Xibin Zhao</name>
        </author>
        <author>
            <name>Shihui Ying</name>
        </author>
        <author>
            <name>Yue Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rectification-based Knowledge Retention for Task Incremental Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9966835</id>
        <link href="https://ieeexplore.ieee.org/document/9966835"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In the task incremental learning problem, deep learning models suffer from catastrophic forgetting of previously seen classes/tasks as they are trained on new classes/tasks. This problem becomes even harder when some of the test classes do not belong to the training class set, i.e., the task incremental generalized zero-shot learning problem. We propose a novel approach to address the task increme...]]></summary>
        <author>
            <name>Pratik Mazumder</name>
        </author>
        <author>
            <name>Pravendra Singh</name>
        </author>
        <author>
            <name>Piyush Rai</name>
        </author>
        <author>
            <name>Vinay P. Namboodiri</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[$\mathcal {X}$-Metric: An N-Dimensional Information-Theoretic Framework for Groupwise Registration and Deep Combined Computing]]></title>
        <id>https://ieeexplore.ieee.org/document/9965747</id>
        <link href="https://ieeexplore.ieee.org/document/9965747"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This paper presents a generic probabilistic framework for estimating the statistical dependency and finding the anatomical correspondences among an arbitrary number of medical images. The method builds on a novel formulation of the $N$-dimensional joint intensity distribution by representing the common anatomy as latent variables and estimating the appearance model with nonparametric estimators. T...]]></summary>
        <author>
            <name>Xinzhe Luo</name>
        </author>
        <author>
            <name>Xiahai Zhuang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spatial-Temporal Transformer for Video Snapshot Compressive Imaging]]></title>
        <id>https://ieeexplore.ieee.org/document/9965744</id>
        <link href="https://ieeexplore.ieee.org/document/9965744"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Video snapshot compressive imaging (SCI) captures multiple sequential video frames by a single measurement using the idea of computational imaging. The underlying principle is to modulate high-speed frames through different masks and these modulated frames are summed to a single measurement captured by a low-speed 2D sensor (dubbed optical encoder); following this, algorithms are employed to recon...]]></summary>
        <author>
            <name>Lishun Wang</name>
        </author>
        <author>
            <name>Miao Cao</name>
        </author>
        <author>
            <name>Yong Zhong</name>
        </author>
        <author>
            <name>Xin Yuan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Micro-supervised Disturbance Learning: A Perspective of Representation Probability Distribution]]></title>
        <id>https://ieeexplore.ieee.org/document/9965741</id>
        <link href="https://ieeexplore.ieee.org/document/9965741"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The instability is shown in the existing methods of representation learning based on Euclidean distance under a broad set of conditions. Furthermore, the scarcity and high cost of labels prompt us to explore more expressive representation learning methods which depends on as few labels as possible. To address above issues, the small-perturbation ideology is firstly introduced on the representation...]]></summary>
        <author>
            <name>Jielei Chu</name>
        </author>
        <author>
            <name>Jing Liu</name>
        </author>
        <author>
            <name>Hongjun Wang</name>
        </author>
        <author>
            <name>Hua Meng</name>
        </author>
        <author>
            <name>Zhiguo Gong</name>
        </author>
        <author>
            <name>Tianrui Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Supervised Anomaly Detection via Conditional Generative Adversarial Network and Ensemble Active Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9965739</id>
        <link href="https://ieeexplore.ieee.org/document/9965739"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Anomaly detection has wide applications in machine intelligence but is still a difficult unsolved problem. Major challenges include the rarity of labeled anomalies and it is a class highly imbalanced problem. Traditional unsupervised anomaly detectors are suboptimal while supervised models can easily make biased predictions towards normal data. In this paper, we present a new supervised anomaly de...]]></summary>
        <author>
            <name>Zhi Chen</name>
        </author>
        <author>
            <name>Jiang Duan</name>
        </author>
        <author>
            <name>Li Kang</name>
        </author>
        <author>
            <name>Guoping Qiu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[State-Regularized Recurrent Neural Networks to Extract Automata and Explain Predictions]]></title>
        <id>https://ieeexplore.ieee.org/document/9965745</id>
        <link href="https://ieeexplore.ieee.org/document/9965745"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recurrent neural networks are a widely used class of neural architectures. They have, however, two shortcomings. First, they are often treated as black-box models and as such it is difficult to understand what exactly they learn as well as how they arrive at a particular prediction. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in prin...]]></summary>
        <author>
            <name>Cheng Wang</name>
        </author>
        <author>
            <name>Carolin Lawrence</name>
        </author>
        <author>
            <name>Mathias Niepert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[One-Hot Graph Encoder Embedding]]></title>
        <id>https://ieeexplore.ieee.org/document/9964227</id>
        <link href="https://ieeexplore.ieee.org/document/9964227"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this paper we propose a lightning fast graph embedding method called one-hot graph encoder embedding. It has a linear computational complexity and the capacity to process billions of edges within minutes on standard PC — making it an ideal candidate for huge graph processing. It is applicable to either adjacency matrix or graph Laplacian, and can be viewed as a transformation of the spectral em...]]></summary>
        <author>
            <name>Cencheng Shen</name>
        </author>
        <author>
            <name>Qizhe Wang</name>
        </author>
        <author>
            <name>Carey E. Priebe</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geodesic Models with Convexity Shape Prior]]></title>
        <id>https://ieeexplore.ieee.org/document/9964444</id>
        <link href="https://ieeexplore.ieee.org/document/9964444"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The minimal geodesic models established upon the eikonal equation framework are capable of finding suitable solutions in various image segmentation scenarios. Existing geodesic-based segmentation approaches usually exploit image features in conjunction with geometric regularization terms, such as Euclidean curve length or curvature-penalized length, for computing geodesic curves. In this paper, we...]]></summary>
        <author>
            <name>Da Chen</name>
        </author>
        <author>
            <name>Jean-Marie Mirebeau</name>
        </author>
        <author>
            <name>Minglei Shu</name>
        </author>
        <author>
            <name>Xuecheng Tai</name>
        </author>
        <author>
            <name>Laurent D. Cohen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning by Seeing More Classes]]></title>
        <id>https://ieeexplore.ieee.org/document/9964413</id>
        <link href="https://ieeexplore.ieee.org/document/9964413"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Traditional pattern recognition models usually assume a fixed and identical number of classes during both training and inference stages. In this paper, we study an interesting but ignored question: can increasing the number of classes during training improve the generalization and reliability performance? For a $k$-class problem, instead of training with only these $k$ classes, we propose to learn...]]></summary>
        <author>
            <name>Fei Zhu</name>
        </author>
        <author>
            <name>Xu-Yao Zhang</name>
        </author>
        <author>
            <name>Rui-Qi Wang</name>
        </author>
        <author>
            <name>Cheng-Lin Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TransCenter: Transformers With Dense Representations for Multiple-Object Tracking]]></title>
        <id>https://ieeexplore.ieee.org/document/9964258</id>
        <link href="https://ieeexplore.ieee.org/document/9964258"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Transformers have proven superior performance for a wide variety of tasks since they were introduced. In recent years, they have drawn attention from the vision community in tasks such as image classification and object detection. Despite this wave, an accurate and efficient multiple-object tracking (MOT) method based on transformers is yet to be designed. We argue that the direct application of a...]]></summary>
        <author>
            <name>Yihong Xu</name>
        </author>
        <author>
            <name>Yutong Ban</name>
        </author>
        <author>
            <name>Guillaume Delorme</name>
        </author>
        <author>
            <name>Chuang Gan</name>
        </author>
        <author>
            <name>Daniela Rus</name>
        </author>
        <author>
            <name>Xavier Alameda-Pineda</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Differentiable Perspective for Multi-View Spectral Clustering With Flexible Extension]]></title>
        <id>https://ieeexplore.ieee.org/document/9964300</id>
        <link href="https://ieeexplore.ieee.org/document/9964300"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multi-view clustering aims to discover common patterns from multi-source data, whose generality is remarkable. Compared with traditional methods, deep learning methods are data-driven and have a larger search space for solutions, which may find a better solution to the problem. In addition, more considerations can be introduced by loss functions, so deep models are highly reusable. However, compar...]]></summary>
        <author>
            <name>Zhoumin Lu</name>
        </author>
        <author>
            <name>Feiping Nie</name>
        </author>
        <author>
            <name>Rong Wang</name>
        </author>
        <author>
            <name>Xuelong Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable by Design: Learning Predictors by Composing Interpretable Queries]]></title>
        <id>https://ieeexplore.ieee.org/document/9964439</id>
        <link href="https://ieeexplore.ieee.org/document/9964439"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[There is a growing concern about typically opaque decision-making with high-performance machine learning algorithms. Providing an explanation of the reasoning process in domain-specific terms can be crucial for adoption in risk-sensitive domains such as healthcare. We argue that machine learning algorithms should be interpretable by design and that the language in which these interpretations are e...]]></summary>
        <author>
            <name>Aditya Chattopadhyay</name>
        </author>
        <author>
            <name>Stewart Slocum</name>
        </author>
        <author>
            <name>Benjamin D. Haeffele</name>
        </author>
        <author>
            <name>René Vidal</name>
        </author>
        <author>
            <name>Donald Geman</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TransVOD: End-to-End Video Object Detection With Spatial-Temporal Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/9960850</id>
        <link href="https://ieeexplore.ieee.org/document/9960850"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Detection Transformer (DETR) and Deformable DETR have been proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance as previous complex hand-crafted detectors. However, their performance on Video Object Detection (VOD) has not been well explored. In this paper, we present TransVOD, the first end-to-end video object detection system b...]]></summary>
        <author>
            <name>Qianyu Zhou</name>
        </author>
        <author>
            <name>Xiangtai Li</name>
        </author>
        <author>
            <name>Lu He</name>
        </author>
        <author>
            <name>Yibo Yang</name>
        </author>
        <author>
            <name>Guangliang Cheng</name>
        </author>
        <author>
            <name>Yunhai Tong</name>
        </author>
        <author>
            <name>Lizhuang Ma</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Curriculum-Based Asymmetric Multi-Task Reinforcement Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9960813</id>
        <link href="https://ieeexplore.ieee.org/document/9960813"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We introduce CAMRL, the first curriculum-based asymmetric multi-task learning (AMTL) algorithm for dealing with multiple reinforcement learning (RL) tasks altogether. To mitigate the negative influence of customizing the one-off training order in curriculum-based AMTL, CAMRL switches its training mode between parallel single-task RL and asymmetric multi-task RL (MTRL), according to an indicator re...]]></summary>
        <author>
            <name>Hanchi Huang</name>
        </author>
        <author>
            <name>Deheng Ye</name>
        </author>
        <author>
            <name>Li Shen</name>
        </author>
        <author>
            <name>Wei Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cell Multi-Bernoulli (Cell-MB) Sensor Control for Multi-Object Search-While-Tracking (SWT)]]></title>
        <id>https://ieeexplore.ieee.org/document/9960819</id>
        <link href="https://ieeexplore.ieee.org/document/9960819"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Information-driven control can be used to develop intelligent sensors that can optimize their measurement value based on environmental feedback. In object tracking applications, sensor actions are chosen based on the expected reduction in uncertainty also known as information gain. Random finite set (RFS) theory provides a formalism for quantifying and estimating information gain in multi-object t...]]></summary>
        <author>
            <name>Keith A. LeGrand</name>
        </author>
        <author>
            <name>Pingping Zhu</name>
        </author>
        <author>
            <name>Silvia Ferrari</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ABINet++: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Spotting]]></title>
        <id>https://ieeexplore.ieee.org/document/9960802</id>
        <link href="https://ieeexplore.ieee.org/document/9960802"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Scene text spotting is of great importance to the computer vision community due to its wide variety of applications. Recent methods attempt to introduce linguistic knowledge for challenging recognition rather than pure visual classification. However, how to effectively model the linguistic rules in end-to-end deep networks remains a research challenge. In this paper, we argue that the limited capa...]]></summary>
        <author>
            <name>Shancheng Fang</name>
        </author>
        <author>
            <name>Zhendong Mao</name>
        </author>
        <author>
            <name>Hongtao Xie</name>
        </author>
        <author>
            <name>Yuxin Wang</name>
        </author>
        <author>
            <name>Chenggang Yan</name>
        </author>
        <author>
            <name>Yongdong Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intrinsic Image Transfer for Illumination Manipulation]]></title>
        <id>https://ieeexplore.ieee.org/document/9961945</id>
        <link href="https://ieeexplore.ieee.org/document/9961945"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This paper presents a novel intrinsic image transfer (IIT) algorithm for image illumination manipulation, which creates a local image translation between two illumination surfaces. This model is built on an optimization-based framework composed of illumination, reflectance and content photo-realistic losses, respectively. Each loss is firstly defined on the corresponding sub-layers factorized by a...]]></summary>
        <author>
            <name>Junqing Huang</name>
        </author>
        <author>
            <name>Michael Ruzhansky</name>
        </author>
        <author>
            <name>Qianying Zhang</name>
        </author>
        <author>
            <name>Haihui Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SuperFast: 200$\boldsymbol{\times }$ Video Frame Interpolation via Event Camera]]></title>
        <id>https://ieeexplore.ieee.org/document/9962797</id>
        <link href="https://ieeexplore.ieee.org/document/9962797"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Traditional frame-based video frame interpolation (VFI) methods rely on the linear motion assumption and brightness invariance assumption, which may lead to fatal errors confronting the scenarios with high-speed motions. To tackle the above challenge, inspired by the advantages of event cameras on asynchronously recording brightness changes at each pixel, we propose a Fast-Slow joint synthesis fra...]]></summary>
        <author>
            <name>Yue Gao</name>
        </author>
        <author>
            <name>Siqi Li</name>
        </author>
        <author>
            <name>Yipeng Li</name>
        </author>
        <author>
            <name>Yandong Guo</name>
        </author>
        <author>
            <name>Qionghai Dai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Global and Local Homography Estimation with Motion Basis Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9956874</id>
        <link href="https://ieeexplore.ieee.org/document/9956874"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this paper, we introduce a new framework for unsupervised deep homography estimation. Our contributions are 3 folds. First, unlike previous methods that regress 4 offsets for a homography, we propose a homography flow representation, which can be estimated by a weighted sum of 8 pre-defined homography flow bases. Second, considering a homography contains 8 Degree-of-Freedoms (DOFs) that is much...]]></summary>
        <author>
            <name>Shuaicheng Liu</name>
        </author>
        <author>
            <name>Yuhang Lu</name>
        </author>
        <author>
            <name>Hai Jiang</name>
        </author>
        <author>
            <name>Nianjin Ye</name>
        </author>
        <author>
            <name>Chuan Wang</name>
        </author>
        <author>
            <name>Bing Zeng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PatchMix Augmentation to Identify Causal Features in Few-shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9956886</id>
        <link href="https://ieeexplore.ieee.org/document/9956886"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The task of Few-shot learning (FSL) aims to transfer the knowledge learned from base categories with sufficient labelled data to novel categories with scarce known information. It is currently an important research question and has great practical values in the real-world applications. Despite extensive previous efforts are made on few-shot learning tasks, we emphasize that most existing methods d...]]></summary>
        <author>
            <name>Chengming Xu</name>
        </author>
        <author>
            <name>Chen Liu</name>
        </author>
        <author>
            <name>Xinwei Sun</name>
        </author>
        <author>
            <name>Siqian Yang</name>
        </author>
        <author>
            <name>Yabiao Wang</name>
        </author>
        <author>
            <name>Chengjie Wang</name>
        </author>
        <author>
            <name>Yanwei Fu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Dense Feature Matching with Transformers and its Applications in Multiple-View Geometry]]></title>
        <id>https://ieeexplore.ieee.org/document/9956767</id>
        <link href="https://ieeexplore.ieee.org/document/9956767"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present a novel method for local image feature matching. Instead of performing image feature detection, description, and matching sequentially, we propose to first establish pixel-wise dense matches at a coarse level and later refine the good matches at a fine level. In contrast to dense methods that use a cost volume to search correspondences, we use self and cross attention layers in Transfor...]]></summary>
        <author>
            <name>Zehong Shen</name>
        </author>
        <author>
            <name>Jiaming Sun</name>
        </author>
        <author>
            <name>Yuang Wang</name>
        </author>
        <author>
            <name>Xingyi He</name>
        </author>
        <author>
            <name>Hujun Bao</name>
        </author>
        <author>
            <name>Xiaowei Zhou</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reward-Adaptive Reinforcement Learning: Dynamic Policy Gradient Optimization for Bipedal Locomotion]]></title>
        <id>https://ieeexplore.ieee.org/document/9956746</id>
        <link href="https://ieeexplore.ieee.org/document/9956746"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Controlling a non-statically bipedal robot is challenging due to the complex dynamics and multi-criterion optimization involved. Recent works have demonstrated the effectiveness of deep reinforcement learning (DRL) for simulation and physical robots. In these methods, the rewards from different criteria are normally summed to learn a scalar function. However, a scalar is less informative and may b...]]></summary>
        <author>
            <name>Changxin Huang</name>
        </author>
        <author>
            <name>Guangrun Wang</name>
        </author>
        <author>
            <name>Zhibo Zhou</name>
        </author>
        <author>
            <name>Ronghui Zhang</name>
        </author>
        <author>
            <name>Liang Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Positive Sample Propagation along the Audio-Visual Event Line]]></title>
        <id>https://ieeexplore.ieee.org/document/9956870</id>
        <link href="https://ieeexplore.ieee.org/document/9956870"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Visual and audio signals often coexist in natural environments, forming audio-visual events (AVEs). Given a video, we aim to localize video segments containing an AVE and identify its category. It is pivotal to learn the discriminative features for each video segment. Unlike existing work focusing on audio-visual feature fusion, in this paper, we propose a new contrastive positive sample propagati...]]></summary>
        <author>
            <name>Jinxing Zhou</name>
        </author>
        <author>
            <name>Dan Guo</name>
        </author>
        <author>
            <name>Meng Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[AlphaPose: Whole-Body Regional Multi-Person Pose Estimation and Tracking in Real-Time]]></title>
        <id>https://ieeexplore.ieee.org/document/9954214</id>
        <link href="https://ieeexplore.ieee.org/document/9954214"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Accurate whole-body multi-person pose estimation and tracking is an important yet challenging topic in computer vision. To capture the subtle actions of humans for complex behavior analysis, whole-body pose estimation including the face, body, hand and foot is essential over conventional body-only pose estimation. In this paper, we present AlphaPose, a system that can perform accurate whole-body p...]]></summary>
        <author>
            <name>Hao-Shu Fang</name>
        </author>
        <author>
            <name>Jiefeng Li</name>
        </author>
        <author>
            <name>Hongyang Tang</name>
        </author>
        <author>
            <name>Chao Xu</name>
        </author>
        <author>
            <name>Haoyi Zhu</name>
        </author>
        <author>
            <name>Yuliang Xiu</name>
        </author>
        <author>
            <name>Yong-Lu Li</name>
        </author>
        <author>
            <name>Cewu Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Granularity Anchor-Contrastive Representation Learning for Semi-Supervised Skeleton-Based Action Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9954217</id>
        <link href="https://ieeexplore.ieee.org/document/9954217"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In the semi-supervised skeleton-based action recognition task, obtaining more discriminative information from both labeled and unlabeled data is a challenging problem. As the current mainstream approach, contrastive learning can learn more representations of augmented data, which can be considered as the pretext task of action recognition. However, such a method still confronts three main limitati...]]></summary>
        <author>
            <name>Xiangbo Shu</name>
        </author>
        <author>
            <name>Binqian Xu</name>
        </author>
        <author>
            <name>Liyan Zhang</name>
        </author>
        <author>
            <name>Jinhui Tang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Differentiable Hierarchical Optimal Transport for Robust Multi-View Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9953569</id>
        <link href="https://ieeexplore.ieee.org/document/9953569"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Traditional multi-view learning methods often rely on two assumptions: ($i$) the samples in different views are well-aligned, and ($ii$) their representations obey the same distribution in a latent space. Unfortunately, these two assumptions may be questionable in practice, which limits the application of multi-view learning. In this work, we propose a differentiable hierarchical optimal transport...]]></summary>
        <author>
            <name>Dixin Luo</name>
        </author>
        <author>
            <name>Hongteng Xu</name>
        </author>
        <author>
            <name>Lawrence Carin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mutual-Assistance Learning for Standalone Mono-Modality Survival Analysis of Human Cancers]]></title>
        <id>https://ieeexplore.ieee.org/document/9953577</id>
        <link href="https://ieeexplore.ieee.org/document/9953577"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Current survival analysis of cancer confronts two key issues. While comprehensive perspectives provided by data from multiple modalities often promote the performance of survival models, data with inadequate modalities at testing phase are more ubiquitous in clinical scenarios, which makes multi-modality approaches not applicable. Additionally, incomplete observations (i.e., censored instances) br...]]></summary>
        <author>
            <name>Zhenyuan Ning</name>
        </author>
        <author>
            <name>Zhangxin Zhao</name>
        </author>
        <author>
            <name>Qianjin Feng</name>
        </author>
        <author>
            <name>Wufan Chen</name>
        </author>
        <author>
            <name>Qing Xiao</name>
        </author>
        <author>
            <name>Yu Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geometry Regularized Autoencoders]]></title>
        <id>https://ieeexplore.ieee.org/document/9950332</id>
        <link href="https://ieeexplore.ieee.org/document/9950332"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[A fundamental task in data exploration is to extract low dimensional representations that capture intrinsic geometry in data, especially for faithfully visualizing data in two or three dimensions. Common approaches use kernel methods for manifold learning. However, these methods typically only provide an embedding of the input data and cannot extend naturally to new data points. Autoencoders have ...]]></summary>
        <author>
            <name>Andres F. Duque</name>
        </author>
        <author>
            <name>Sacha Morin</name>
        </author>
        <author>
            <name>Guy Wolf</name>
        </author>
        <author>
            <name>Kevin R. Moon</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning View-Based Graph Convolutional Network for Multi-View 3D Shape Analysis]]></title>
        <id>https://ieeexplore.ieee.org/document/9947327</id>
        <link href="https://ieeexplore.ieee.org/document/9947327"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[View-based approach that recognizes 3D shape through its projected 2D images has achieved state-of-the-art results for 3D shape recognition. The major challenges are how to aggregate multi-view features and deal with 3D shapes in arbitrary poses. We propose two versions of a novel view-based Graph Convolutional Network, dubbed view-GCN and view-GCN++, to recognize 3D shape based on graph represent...]]></summary>
        <author>
            <name>Xin Wei</name>
        </author>
        <author>
            <name>Ruixuan Yu</name>
        </author>
        <author>
            <name>Jian Sun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Referring Segmentation Via Encoder-Fused Cross-Modal Attention Network]]></title>
        <id>https://ieeexplore.ieee.org/document/9946403</id>
        <link href="https://ieeexplore.ieee.org/document/9946403"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This paper focuses on referring segmentation, which aims to selectively segment the corresponding visual region in an image (or video) according to the referring expression. However, the existing methods usually consider the interaction between multi-modal features at the decoding end of the network. Specifically, they interact the visual features of each scale with language respectively, thus ign...]]></summary>
        <author>
            <name>Guang Feng</name>
        </author>
        <author>
            <name>Lihe Zhang</name>
        </author>
        <author>
            <name>Jiayu Sun</name>
        </author>
        <author>
            <name>Zhiwei Hu</name>
        </author>
        <author>
            <name>Huchuan Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Bayesian Analysis for Deep Metric Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9946419</id>
        <link href="https://ieeexplore.ieee.org/document/9946419"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recent methods for deep metric learning have been focusing on designing different contrastive loss functions between positive and negative pairs of samples so that the learned feature embedding is able to pull positive samples of the same class closer and push negative samples from different classes away from each other. In this work, we recognize that there is a significant semantic gap between f...]]></summary>
        <author>
            <name>Shichao Kan</name>
        </author>
        <author>
            <name>Zhiquan He</name>
        </author>
        <author>
            <name>Yigang Cen</name>
        </author>
        <author>
            <name>Yang Li</name>
        </author>
        <author>
            <name>Vladimir Mladenovic</name>
        </author>
        <author>
            <name>Zhihai He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Conditional Wasserstein Generator]]></title>
        <id>https://ieeexplore.ieee.org/document/9944913</id>
        <link href="https://ieeexplore.ieee.org/document/9944913"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The statistical distance of conditional distributions is an essential element of generating target data given some data as in video prediction. We establish how the statistical distances between two joint distributions are related to those between two conditional distributions for three popular statistical distances: f-divergence, Wasserstein distance, and integral probability metrics. Such charac...]]></summary>
        <author>
            <name>Young-geun Kim</name>
        </author>
        <author>
            <name>Kyungbok Lee</name>
        </author>
        <author>
            <name>Myunghee Cho Paik</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DMRNet++: Learning Discriminative Features with Decoupled Networks and Enriched Pairs for One-Step Person Search]]></title>
        <id>https://ieeexplore.ieee.org/document/9944858</id>
        <link href="https://ieeexplore.ieee.org/document/9944858"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Person search aims at localizing and recognizing query persons from raw video frames, which is a combination of two sub-tasks, i.e., pedestrian detection and person re-identification. The dominant fashion is termed as the one-step person search that jointly optimizes detection and identification in a unified network, exhibiting higher efficiency. However, there remain major challenges: (i) conflic...]]></summary>
        <author>
            <name>Chuchu Han</name>
        </author>
        <author>
            <name>Zhedong Zheng</name>
        </author>
        <author>
            <name>Kai Su</name>
        </author>
        <author>
            <name>Dongdong Yu</name>
        </author>
        <author>
            <name>Zehuan Yuan</name>
        </author>
        <author>
            <name>Changxin Gao</name>
        </author>
        <author>
            <name>Nong Sang</name>
        </author>
        <author>
            <name>Yi Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Shape of Learning Curves: A Review]]></title>
        <id>https://ieeexplore.ieee.org/document/9944190</id>
        <link href="https://ieeexplore.ieee.org/document/9944190"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Learning curves provide insight into the dependence of a learner&#39;s generalization performance on the training set size. This important tool can be used for model selection, to predict the effect of more training data, and to reduce the computational complexity of model training and hyperparameter tuning. This review recounts the origins of the term, provides a formal definition of the learning cur...]]></summary>
        <author>
            <name>Tom Viering</name>
        </author>
        <author>
            <name>Marco Loog</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rethinking Label Flipping Attack: From Sample Masking to Sample Thresholding]]></title>
        <id>https://ieeexplore.ieee.org/document/9944159</id>
        <link href="https://ieeexplore.ieee.org/document/9944159"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Nowadays, machine learning (ML) and deep learning (DL) methods have become fundamental building blocks for a wide range of AI applications. The popularity of these methods also makes them widely exposed to malicious attacks, which may cause severe security concerns. To understand the security properties of the ML/DL methods, researchers have recently started to turn their focus to adversarial atta...]]></summary>
        <author>
            <name>Qianqian Xu</name>
        </author>
        <author>
            <name>Zhiyong Yang</name>
        </author>
        <author>
            <name>Yunrui Zhao</name>
        </author>
        <author>
            <name>Xiaochun Cao</name>
        </author>
        <author>
            <name>Qingming Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Adaptive Transfer Kernel Learning for Transfer Gaussian Process Regression]]></title>
        <id>https://ieeexplore.ieee.org/document/9937157</id>
        <link href="https://ieeexplore.ieee.org/document/9937157"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Transfer regression is a practical and challenging problem with important applications in various domains, such as engineering design and localization. Capturing the relatedness of different domains is the key of adaptive knowledge transfer. In this paper, we investigate an effective way of explicitly modelling domain relatedness through transfer kernel, a transfer-specified kernel that considers ...]]></summary>
        <author>
            <name>Pengfei Wei</name>
        </author>
        <author>
            <name>Yiping Ke</name>
        </author>
        <author>
            <name>Yew Soon Ong</name>
        </author>
        <author>
            <name>Zejun Ma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dual Instance-Consistent Network for Cross-Domain Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/9935311</id>
        <link href="https://ieeexplore.ieee.org/document/9935311"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Cross-domain object detection aims to transfer knowledge from a labeled dataset to an unlabeled dataset. Most existing methods apply a unified embedding model to generate the tightly coupled source and target descriptions for domain alignment, leading to the destroyed feature distribution of the target domain because the embedding model is mainly controlled by the source domain. To reduce the repr...]]></summary>
        <author>
            <name>Yifan Jiao</name>
        </author>
        <author>
            <name>Hantao Yao</name>
        </author>
        <author>
            <name>Changsheng Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning for Instance Retrieval: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9933854</id>
        <link href="https://ieeexplore.ieee.org/document/9933854"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In recent years a vast amount of visual content has been generated and shared from many fields, such as social media platforms, medical imaging, and robotics. This abundance of content creation and sharing has introduced new challenges, particularly that of searching databases for similar content — Content Based Image Retrieval (CBIR) — a long-established research area in which improved efficiency...]]></summary>
        <author>
            <name>Wei Chen</name>
        </author>
        <author>
            <name>Yu Liu</name>
        </author>
        <author>
            <name>Weiping Wang</name>
        </author>
        <author>
            <name>Erwin M. Bakker</name>
        </author>
        <author>
            <name>Theodoros Georgiou</name>
        </author>
        <author>
            <name>Paul Fieguth</name>
        </author>
        <author>
            <name>Li Liu</name>
        </author>
        <author>
            <name>Michael S. Lew</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Human Collective Intelligence Inspired Multi-View Representation Learning — Enabling View Communication by Simulating Human Communication Mechanism]]></title>
        <id>https://ieeexplore.ieee.org/document/9933914</id>
        <link href="https://ieeexplore.ieee.org/document/9933914"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In real-world applications, we often encounter multi-view learning tasks where we need to learn from multiple sources of data or use multiple sources of data to make decisions. Multi-view representation learning, which can learn a unified representation from multiple data sources, is a key pre-task of multi-view learning and plays a significant role in real-world applications. Accordingly, how to ...]]></summary>
        <author>
            <name>Xiaodong Jia</name>
        </author>
        <author>
            <name>Xiao-Yuan Jing</name>
        </author>
        <author>
            <name>Qixing Sun</name>
        </author>
        <author>
            <name>Songcan Chen</name>
        </author>
        <author>
            <name>Bo Du</name>
        </author>
        <author>
            <name>David Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transferring Knowledge from Text to Video: Zero-Shot Anticipation for Procedural Actions]]></title>
        <id>https://ieeexplore.ieee.org/document/9933901</id>
        <link href="https://ieeexplore.ieee.org/document/9933901"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Can we teach a robot to recognize and make predictions for activities that it has never seen before? We tackle this problem by learning models for video from text. This paper presents a hierarchical model that generalizes instructional knowledge from large-scale text corpora and transfers the knowledge to video. Given a portion of an instructional video, our model recognizes and predicts coherent ...]]></summary>
        <author>
            <name>Fadime Sener</name>
        </author>
        <author>
            <name>Rishabh Saraf</name>
        </author>
        <author>
            <name>Angela Yao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CATs++: Boosting Cost Aggregation with Convolutions and Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/9933865</id>
        <link href="https://ieeexplore.ieee.org/document/9933865"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Cost aggregation is a process in image matching tasks that aims to disambiguate the noisy matching scores. Existing methods generally tackle this by hand-crafted or CNN-based methods, which either lack robustness to severe deformations or inherit the limitation of CNNs that fail to discriminate incorrect matches due to limited receptive fields and inadaptability. In this paper, we introduce Cost A...]]></summary>
        <author>
            <name>Seokju Cho</name>
        </author>
        <author>
            <name>Sunghwan Hong</name>
        </author>
        <author>
            <name>Seungryong Kim</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Large-scale Unsupervised Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9933726</id>
        <link href="https://ieeexplore.ieee.org/document/9933726"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Empowered by large datasets, e.g., ImageNet and MS COCO, unsupervised learning on large-scale data has enabled significant advances for classification tasks. However, whether the large-scale unsupervised semantic segmentation can be achieved remains unknown. There are two major challenges: i) we need a large-scale benchmark for assessing algorithms; ii) we need to develop methods to simultaneously...]]></summary>
        <author>
            <name>Shanghua Gao</name>
        </author>
        <author>
            <name>Zhong-Yu Li</name>
        </author>
        <author>
            <name>Ming-Hsuan Yang</name>
        </author>
        <author>
            <name>Ming-Ming Cheng</name>
        </author>
        <author>
            <name>Junwei Han</name>
        </author>
        <author>
            <name>Philip Torr</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[When Age-Invariant Face Recognition Meets Face Age Synthesis: A Multi-Task Learning Framework and A New Benchmark]]></title>
        <id>https://ieeexplore.ieee.org/document/9931965</id>
        <link href="https://ieeexplore.ieee.org/document/9931965"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[To minimize the impact of age variation on face recognition, age-invariant face recognition (AIFR) extracts identity-related discriminative features by minimizing the correlation between identity- and age-related features while face age synthesis (FAS) eliminates age variation by converting the faces in different age groups to the same group. However, AIFR lacks visual results for model interpreta...]]></summary>
        <author>
            <name>Zhizhong Huang</name>
        </author>
        <author>
            <name>Junping Zhang</name>
        </author>
        <author>
            <name>Hongming Shan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NeX360: Real-time All-around View Synthesis with Neural Basis Expansion]]></title>
        <id>https://ieeexplore.ieee.org/document/9931981</id>
        <link href="https://ieeexplore.ieee.org/document/9931981"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present NeX, a new approach to novel view synthesis based on enhancements of multiplane images (MPI) that can reproduce view-dependent effects in real time. Unlike traditional MPI, our technique parameterizes each pixel as a linear combination of spherical basis functions learned from a neural network to model view-dependent effects and uses a hybrid implicit-explicit modeling strategy to impro...]]></summary>
        <author>
            <name>Pakkapon Phongthawee</name>
        </author>
        <author>
            <name>Suttisak Wizadwongsa</name>
        </author>
        <author>
            <name>Jiraphon Yenphraphai</name>
        </author>
        <author>
            <name>Supasorn Suwajanakorn</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9931970</id>
        <link href="https://ieeexplore.ieee.org/document/9931970"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose self-adaptive training—a unified training algorithm that dynamically calibrates and enhances training processes by model predictions without incurring an extra computational cost—to advance both supervised and self-supervised learning of deep neural networks. We analyze the training dynamics of deep networks on training data that are corrupted by, e.g., random noise and adversarial exam...]]></summary>
        <author>
            <name>Lang Huang</name>
        </author>
        <author>
            <name>Chao Zhang</name>
        </author>
        <author>
            <name>Hongyang Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VLT: Vision-Language Transformer and Query Generation for Referring Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9932025</id>
        <link href="https://ieeexplore.ieee.org/document/9932025"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose a Vision-Language Transformer (VLT) framework for referring segmentation to facilitate deep interactions among multi-modal information and enhance the holistic understanding to vision-language features. There are different ways to understand the dynamic emphasis of a language expression, especially when interacting with the image. However, the learned queries in existing transformer wor...]]></summary>
        <author>
            <name>Henghui Ding</name>
        </author>
        <author>
            <name>Chang Liu</name>
        </author>
        <author>
            <name>Suchen Wang</name>
        </author>
        <author>
            <name>Xudong Jiang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Neural Architecture Search via Proxy Validation]]></title>
        <id>https://ieeexplore.ieee.org/document/9931480</id>
        <link href="https://ieeexplore.ieee.org/document/9931480"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This paper searches for the optimal neural architecture by minimizing a proxy of validation loss. Existing neural architecture search (NAS) methods used to discover the optimal neural architecture that best fits the validation examples given the up-to-date network weights. These intermediate validation results are invaluable but have not been fully explored. We propose to approximate the validatio...]]></summary>
        <author>
            <name>Yanxi Li</name>
        </author>
        <author>
            <name>Minjing Dong</name>
        </author>
        <author>
            <name>Yunhe Wang</name>
        </author>
        <author>
            <name>Chang Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised Pre-Training for Detection Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/9926201</id>
        <link href="https://ieeexplore.ieee.org/document/9926201"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[DEtection TRansformer (DETR) for object detection reaches competitive performance compared with Faster R-CNN via a transformer encoder-decoder architecture. However, trained with scratch transformers, DETR needs large-scale training data and an extreme long training schedule even on COCO dataset. Inspired by the great success of pre-training transformers in natural language processing, we propose ...]]></summary>
        <author>
            <name>Zhigang Dai</name>
        </author>
        <author>
            <name>Bolun Cai</name>
        </author>
        <author>
            <name>Yugeng Lin</name>
        </author>
        <author>
            <name>Junying Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fast Differentiable Matrix Square Root and Inverse Square Root]]></title>
        <id>https://ieeexplore.ieee.org/document/9926140</id>
        <link href="https://ieeexplore.ieee.org/document/9926140"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Computing the matrix square root and its inverse in a differentiable manner is important in a variety of computer vision tasks. Previous methods either adopt the Singular Value Decomposition (SVD) to explicitly factorize the matrix or use the Newton-Schulz iteration (NS iteration) to derive the approximate solution. However, both methods are not computationally efficient enough in either the forwa...]]></summary>
        <author>
            <name>Yue Song</name>
        </author>
        <author>
            <name>Nicu Sebe</name>
        </author>
        <author>
            <name>Wei Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Representation for Clustering Via Prototype Scattering and Positive Sampling]]></title>
        <id>https://ieeexplore.ieee.org/document/9926200</id>
        <link href="https://ieeexplore.ieee.org/document/9926200"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Existing deep clustering methods rely on either contrastive or non-contrastive representation learning for downstream clustering task. Contrastive-based methods thanks to negative pairs learn uniform representations for clustering, in which negative pairs, however, may inevitably lead to the class collision issue and consequently compromise the clustering performance. Non-contrastive-based methods...]]></summary>
        <author>
            <name>Zhizhong Huang</name>
        </author>
        <author>
            <name>Jie Chen</name>
        </author>
        <author>
            <name>Junping Zhang</name>
        </author>
        <author>
            <name>Hongming Shan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/9914676</id>
        <link href="https://ieeexplore.ieee.org/document/9914676"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Tracking a time-varying indefinite number of objects in a video sequence over time remains a challenge despite recent advances in the field. Most existing approaches are not able to properly handle multi-object tracking challenges such as occlusion, in part because they ignore long-term temporal information. To address these shortcomings, we present MO3TR: a truly end-to-end Transformer-based onli...]]></summary>
        <author>
            <name>Tianyu Zhu</name>
        </author>
        <author>
            <name>Markus Hiller</name>
        </author>
        <author>
            <name>Mahsa Ehsanpour</name>
        </author>
        <author>
            <name>Rongkai Ma</name>
        </author>
        <author>
            <name>Tom Drummond</name>
        </author>
        <author>
            <name>Ian Reid</name>
        </author>
        <author>
            <name>Hamid Rezatofighi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interpretable Compositional Representations for Robust Few-Shot Generalization]]></title>
        <id>https://ieeexplore.ieee.org/document/9913725</id>
        <link href="https://ieeexplore.ieee.org/document/9913725"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose Recognition as Part Composition (RPC), an image encoding approach inspired by human cognition. It is based on the cognitive theory that humans recognize complex objects by components, and that they build a small compact vocabulary of concepts to represent each instance with. RPC encodes images by first decomposing them into salient parts, and then encoding each part as a mixture of a sm...]]></summary>
        <author>
            <name>Samarth Mishra</name>
        </author>
        <author>
            <name>Pengkai Zhu</name>
        </author>
        <author>
            <name>Venkatesh Saligrama</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revisiting Viewing Graph Solvability: an Effective Approach Based on Cycle Consistency]]></title>
        <id>https://ieeexplore.ieee.org/document/9913729</id>
        <link href="https://ieeexplore.ieee.org/document/9913729"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In the structure from motion, the viewing graph is a graph where the vertices correspond to cameras (or images) and the edges represent the fundamental matrices. We provide a new formulation and an algorithm for determining whether a viewing graph is solvable, i.e., uniquely determines a set of projective cameras. The known theoretical conditions either do not fully characterize the solvability of...]]></summary>
        <author>
            <name>Federica Arrigoni</name>
        </author>
        <author>
            <name>Andrea Fusiello</name>
        </author>
        <author>
            <name>Romeo Rizzi</name>
        </author>
        <author>
            <name>Elisa Ricci</name>
        </author>
        <author>
            <name>Tomas Pajdla</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards JPEG-Resistant Image Forgery Detection and Localization Via Self-Supervised Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/9904872</id>
        <link href="https://ieeexplore.ieee.org/document/9904872"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[With wide applications of image editing tools, forged images (splicing, copy-move, removal and etc.) have been becoming great public concerns. Although existing image forgery localization methods could achieve fairly good results on several public datasets, most of them perform poorly when the forged images are JPEG compressed as they are usually done in social networks. To tackle this issue, in t...]]></summary>
        <author>
            <name>Yuan Rao</name>
        </author>
        <author>
            <name>Jiangqun Ni</name>
        </author>
        <author>
            <name>Weizhe Zhang</name>
        </author>
        <author>
            <name>Jiwu Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Token Selection is a Simple Booster for Vision Transformers]]></title>
        <id>https://ieeexplore.ieee.org/document/9903081</id>
        <link href="https://ieeexplore.ieee.org/document/9903081"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Vision transformers have recently attained state-of-the-art results in visual recognition tasks. Their success is largely attributed to the self-attention component, which models the global dependencies among the image patches (tokens) and aggregates them into higher-level features. However, self-attention brings significant training difficulties to ViTs. Many recent works thus develop various new...]]></summary>
        <author>
            <name>Daquan Zhou</name>
        </author>
        <author>
            <name>Qibin Hou</name>
        </author>
        <author>
            <name>Linjie Yang</name>
        </author>
        <author>
            <name>Xiaojie Jin</name>
        </author>
        <author>
            <name>Jiashi Feng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MCTS with Refinement for Proposals Selection Games in Scene Understanding]]></title>
        <id>https://ieeexplore.ieee.org/document/9903516</id>
        <link href="https://ieeexplore.ieee.org/document/9903516"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose a novel method applicable in many scene understanding problems that adapts the Monte Carlo Tree Search (MCTS) algorithm, originally designed to learn to play games of high-state complexity. From a generated pool of proposals, our method jointly selects and optimizes proposals that minimize the objective term. In our first application for floor plan reconstruction from point clouds, our ...]]></summary>
        <author>
            <name>Sinisa Stekovic</name>
        </author>
        <author>
            <name>Mahdi Rad</name>
        </author>
        <author>
            <name>Alireza Moradi</name>
        </author>
        <author>
            <name>Friedrich Fraundorfer</name>
        </author>
        <author>
            <name>Vincent Lepetit</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transformer for Image Harmonization and Beyond]]></title>
        <id>https://ieeexplore.ieee.org/document/9893399</id>
        <link href="https://ieeexplore.ieee.org/document/9893399"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Image harmonization, aiming to make composite images look more realistic, is an important and challenging task. The composite, synthesized by combining foreground from one image with background from another image, inevitably suffers from the issue of inharmonious appearance caused by distinct imaging conditions, i.e., lights. Current solutions mainly adopt an encoder-decoder architecture with conv...]]></summary>
        <author>
            <name>Zonghui Guo</name>
        </author>
        <author>
            <name>Zhaorui Gu</name>
        </author>
        <author>
            <name>Bing Zheng</name>
        </author>
        <author>
            <name>Junyu Dong</name>
        </author>
        <author>
            <name>Haiyong Zheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BimodalPS: Causes and Corrections for Bimodal Multi-path in Phase-Shifting Structured Light Scanners]]></title>
        <id>https://ieeexplore.ieee.org/document/9889210</id>
        <link href="https://ieeexplore.ieee.org/document/9889210"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Structured light illumination is an active 3D scanning technique based on projecting and capturing a set of striped patterns and measuring the warping of the patterns as they reflect off a target object&#39;s surface. As designed, each pixel in the camera sees exactly one pixel from the projector; however, there are multi-path situations where a camera pixel sees light from multiple projector position...]]></summary>
        <author>
            <name>Yu Zhang</name>
        </author>
        <author>
            <name>Daniel L. Lau</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MPS-NeRF: Generalizable 3D Human Rendering From Multiview Images]]></title>
        <id>https://ieeexplore.ieee.org/document/9888037</id>
        <link href="https://ieeexplore.ieee.org/document/9888037"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[There has been rapid progress recently on 3D human rendering, including novel view synthesis and pose animation, based on the advances of neural radiance fields (NeRF). However, most existing methods focus on person-specific training and their training typically requires multi-view videos. This paper deals with a new challenging task – rendering novel views and novel poses for a person unseen in t...]]></summary>
        <author>
            <name>Xiangjun Gao</name>
        </author>
        <author>
            <name>Jiaolong Yang</name>
        </author>
        <author>
            <name>Jongyoo Kim</name>
        </author>
        <author>
            <name>Sida Peng</name>
        </author>
        <author>
            <name>Zicheng Liu</name>
        </author>
        <author>
            <name>Xin Tong</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[StARformer: Transformer with State-Action-Reward Representations for Robot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9878209</id>
        <link href="https://ieeexplore.ieee.org/document/9878209"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Reinforcement Learning (RL) can be considered as a sequence modeling task, where an agent employs a sequence of past state-action-reward experiences to predict a sequence of future actions. In this work, we propose State-Action-Reward Transformer (StARformer), a Transformer architecture for robot learning with image inputs, which explicitly models short-term state-action-reward representations (St...]]></summary>
        <author>
            <name>Jinghuan Shang</name>
        </author>
        <author>
            <name>Xiang Li</name>
        </author>
        <author>
            <name>Kumara Kahatapitiya</name>
        </author>
        <author>
            <name>Yu-Cheol Lee</name>
        </author>
        <author>
            <name>Michael S. Ryoo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Wide-Baseline Light Fields using Ellipsoidal Mirrors]]></title>
        <id>https://ieeexplore.ieee.org/document/9878227</id>
        <link href="https://ieeexplore.ieee.org/document/9878227"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Traditional hand-held light field cameras only observe a small fraction of the cone of light emitted by a scene point. As a consequence, the study of interesting angular effects like iridescence are beyond the scope of such cameras. This paper envisions a new design for sensing light fields with wide baselines, so as to sense a significantly larger fraction of the cone of light emitted by scene po...]]></summary>
        <author>
            <name>Michael De Zeeuw</name>
        </author>
        <author>
            <name>Aswin C. Sankaranarayanan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Bayesian Embeddings for Few-Shot Open World Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9875990</id>
        <link href="https://ieeexplore.ieee.org/document/9875990"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[As autonomous decision-making agents move from narrow operating environments to unstructured worlds, learning systems must move from a closed-world formulation to an open-world and few-shot setting in which agents continuously learn new classes from small amounts of information. This stands in stark contrast to modern machine learning systems that are typically designed with a known set of classes...]]></summary>
        <author>
            <name>John Willes</name>
        </author>
        <author>
            <name>James Harrison</name>
        </author>
        <author>
            <name>Ali Harakeh</name>
        </author>
        <author>
            <name>Chelsea Finn</name>
        </author>
        <author>
            <name>Marco Pavone</name>
        </author>
        <author>
            <name>Steven Waslander</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Physics to the Rescue: Deep Non-Line-of-Sight Reconstruction for High-Speed Imaging]]></title>
        <id>https://ieeexplore.ieee.org/document/9874257</id>
        <link href="https://ieeexplore.ieee.org/document/9874257"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Computational approach to imaging around the corner, or non-line-of-sight (NLOS) imaging, is becoming a reality thanks to major advances in imaging hardware and reconstruction algorithms. A recent development towards practical NLOS imaging, Nam et al. [1] demonstrated a high-speed non-confocal imaging system that operates at 5 Hz, 100x faster than the prior art. This enormous gain in acquisition r...]]></summary>
        <author>
            <name>Fangzhou Mu</name>
        </author>
        <author>
            <name>Sicheng Mo</name>
        </author>
        <author>
            <name>Jiayong Peng</name>
        </author>
        <author>
            <name>Xiaochun Liu</name>
        </author>
        <author>
            <name>Ji Hyun Nam</name>
        </author>
        <author>
            <name>Siddeshwar Raghavan</name>
        </author>
        <author>
            <name>Andreas Velten</name>
        </author>
        <author>
            <name>Yin Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Mixed-State Coded Diffraction Imaging]]></title>
        <id>https://ieeexplore.ieee.org/document/9872132</id>
        <link href="https://ieeexplore.ieee.org/document/9872132"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Coherent diffraction imaging (CDI) is a computational technique for reconstructing a complex-valued optical field from an intensity measurement. The approach is to illuminate an object with a coherent beam of light to form a diffraction pattern, and use a phase retrieval algorithm to reconstruct the object&#39;s complex transmittance from the measurement. However, as the name implies, conventional CDI...]]></summary>
        <author>
            <name>Benjamin Attal</name>
        </author>
        <author>
            <name>Matthew O'Toole</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[P2T: Pyramid Pooling Transformer for Scene Understanding]]></title>
        <id>https://ieeexplore.ieee.org/document/9870559</id>
        <link href="https://ieeexplore.ieee.org/document/9870559"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recently, the vision transformer has achieved great success by pushing the state-of-the-art of various vision tasks. One of the most challenging problems in the vision transformer is that the large sequence length of image tokens leads to high computational cost (quadratic complexity). A popular solution to this problem is to use a single pooling operation to reduce the sequence length. This paper...]]></summary>
        <author>
            <name>Yu-Huan Wu</name>
        </author>
        <author>
            <name>Yun Liu</name>
        </author>
        <author>
            <name>Xin Zhan</name>
        </author>
        <author>
            <name>Ming-Ming Cheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PS $^{2}$ F: Polarized Spiral Point Spread Function for Single-Shot 3D Sensing]]></title>
        <id>https://ieeexplore.ieee.org/document/9869297</id>
        <link href="https://ieeexplore.ieee.org/document/9869297"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose a compact snapshot monocular depth estimation technique that relies on an engineered point spread function (PSF). Traditional approaches used in microscopic super-resolution imaging such as the Double-Helix PSF (DHPSF) are ill-suited for scenes that are more complex than a sparse set of point light sources. We show, using the Cramér-Rao lower bound, that separating the two lobes of the ...]]></summary>
        <author>
            <name>Bhargav Ghanekar</name>
        </author>
        <author>
            <name>Vishwanath Saragadam</name>
        </author>
        <author>
            <name>Dushyant Mehra</name>
        </author>
        <author>
            <name>Anna-Karin Gustavsson</name>
        </author>
        <author>
            <name>Aswin C. Sankaranarayanan</name>
        </author>
        <author>
            <name>Ashok Veeraraghavan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Supervised and Unsupervised Deep Visual Learning: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9866825</id>
        <link href="https://ieeexplore.ieee.org/document/9866825"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[State-of-the-art deep learning models are often trained with a large amount of costly labeled training data. However, requiring exhaustive manual annotations may degrade the model&#39;s generalizability in the limited-label regime.Semi-supervised learning and unsupervised learning offer promising paradigms to learn from an abundance of unlabeled visual data. Recent progress in these paradigms has indi...]]></summary>
        <author>
            <name>Yanbei Chen</name>
        </author>
        <author>
            <name>Massimiliano Mancini</name>
        </author>
        <author>
            <name>Xiatian Zhu</name>
        </author>
        <author>
            <name>Zeynep Akata</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks]]></title>
        <id>https://ieeexplore.ieee.org/document/9864267</id>
        <link href="https://ieeexplore.ieee.org/document/9864267"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[New classes arise frequently in our ever-changing world, e.g., emerging topics in social media and new types of products in e-commerce. A model should recognize new classes and meanwhile maintain discriminability over old classes. Under severe circumstances, only limited novel instances are available to incrementally update the model. The task of recognizing few-shot new classes with...]]></summary>
        <author>
            <name>Da-Wei Zhou</name>
        </author>
        <author>
            <name>Han-Jia Ye</name>
        </author>
        <author>
            <name>Liang Ma</name>
        </author>
        <author>
            <name>Di Xie</name>
        </author>
        <author>
            <name>Shiliang Pu</name>
        </author>
        <author>
            <name>De-Chuan Zhan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Open Long-Tailed Recognition In A Dynamic World]]></title>
        <id>https://ieeexplore.ieee.org/document/9863702</id>
        <link href="https://ieeexplore.ieee.org/document/9863702"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Real world data often exhibits a long-tailed and open-ended (i.e., with unseen classes) distribution. A practical recognition system must balance between majority (head) and minority (tail) classes, generalize across the distribution, and acknowledge novelty upon the instances of unseen classes (open classes). We define Open Long-Tailed Recognition++ (OLTR++) as learning from such naturally...]]></summary>
        <author>
            <name>Ziwei Liu</name>
        </author>
        <author>
            <name>Zhongqi Miao</name>
        </author>
        <author>
            <name>Xiaohang Zhan</name>
        </author>
        <author>
            <name>Jiayun Wang</name>
        </author>
        <author>
            <name>Boqing Gong</name>
        </author>
        <author>
            <name>Stella X. Yu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving]]></title>
        <id>https://ieeexplore.ieee.org/document/9863660</id>
        <link href="https://ieeexplore.ieee.org/document/9863660"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[How should we integrate representations from complementary sensors for autonomous driving? Geometry-based fusion has shown promise for perception (e.g. object detection, motion forecasting). However, in the context of end-to-end driving, we find that imitation learning based on existing sensor fusion methods underperforms in complex driving scenarios with a high density of dynamic agents. Therefor...]]></summary>
        <author>
            <name>Kashyap Chitta</name>
        </author>
        <author>
            <name>Aditya Prakash</name>
        </author>
        <author>
            <name>Bernhard Jaeger</name>
        </author>
        <author>
            <name>Zehao Yu</name>
        </author>
        <author>
            <name>Katrin Renz</name>
        </author>
        <author>
            <name>Andreas Geiger</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-shot Font Generation with Weakly Supervised Localized Representations]]></title>
        <id>https://ieeexplore.ieee.org/document/9854803</id>
        <link href="https://ieeexplore.ieee.org/document/9854803"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Automatic few-shot font generation aims to solve a well-defined, real-world problem because manual font designs are expensive and sensitive to the expertise of designers. Existing methods learn to disentangle style and content elements by developing a universal style representation for each font style. However, this approach limits the model in representing diverse local styles because it is unsui...]]></summary>
        <author>
            <name>Song Park</name>
        </author>
        <author>
            <name>Sanghyuk Chun</name>
        </author>
        <author>
            <name>Junbum Cha</name>
        </author>
        <author>
            <name>Bado Lee</name>
        </author>
        <author>
            <name>Hyunjung Shim</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variable Imaging Projection Cloud Scattering Tomography]]></title>
        <id>https://ieeexplore.ieee.org/document/9847357</id>
        <link href="https://ieeexplore.ieee.org/document/9847357"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is a nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale is particularly important when the objects constitute large cloud fields, where volumetric recovery is ...]]></summary>
        <author>
            <name>Roi Ronen</name>
        </author>
        <author>
            <name>Vadim Holodovsky</name>
        </author>
        <author>
            <name>Yoav Y. Schechner</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation Exploitation]]></title>
        <id>https://ieeexplore.ieee.org/document/9847356</id>
        <link href="https://ieeexplore.ieee.org/document/9847356"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Few-shot object detection has been extensively investigated by incorporating meta-learning into region-based detection frameworks. Despite its success, the said paradigm is still constrained by several factors, such as (i) low-quality region proposals for novel classes and (ii) negligence of the inter-class correlation among different classes. Such limitations hinder the generalizati...]]></summary>
        <author>
            <name>Gongjie Zhang</name>
        </author>
        <author>
            <name>Zhipeng Luo</name>
        </author>
        <author>
            <name>Kaiwen Cui</name>
        </author>
        <author>
            <name>Shijian Lu</name>
        </author>
        <author>
            <name>Eric P. Xing</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Voxel-Mesh Network for Geodesic-Aware 3D Semantic Segmentation of Indoor Scenes]]></title>
        <id>https://ieeexplore.ieee.org/document/9844250</id>
        <link href="https://ieeexplore.ieee.org/document/9844250"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In recent years, sparse voxel-based methods have become the state-of-the-arts for 3D semantic segmentation of indoor scenes, thanks to the powerful 3D CNNs. Nevertheless, being oblivious to the underlying geometry, voxel-based methods suffer from ambiguous features on spatially close objects and struggle with handling complex and irregular geometries due to the lack of geodesic information. In vie...]]></summary>
        <author>
            <name>Zeyu Hu</name>
        </author>
        <author>
            <name>Xuyang Bai</name>
        </author>
        <author>
            <name>Jiaxiang Shang</name>
        </author>
        <author>
            <name>Runze Zhang</name>
        </author>
        <author>
            <name>Jiayu Dong</name>
        </author>
        <author>
            <name>Xin Wang</name>
        </author>
        <author>
            <name>Guangyuan Sun</name>
        </author>
        <author>
            <name>Hongbo Fu</name>
        </author>
        <author>
            <name>Chiew-Lan Tai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Remove Rain in Video With Self-Supervision]]></title>
        <id>https://ieeexplore.ieee.org/document/9815121</id>
        <link href="https://ieeexplore.ieee.org/document/9815121"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In heavy rain video, rain streak and rain accumulation are the most common causes of degradation. They occlude background information and can significantly impair the visibility. Most existing methods rely heavily on the synthetic training data, and thus raise the domain gap problem that prevents the trained models from performing adequately in real testing cases. Unlike these methods, we introduc...]]></summary>
        <author>
            <name>Wenhan Yang</name>
        </author>
        <author>
            <name>Robby T. Tan</name>
        </author>
        <author>
            <name>Shiqi Wang</name>
        </author>
        <author>
            <name>Alex C. Kot</name>
        </author>
        <author>
            <name>Jiaying Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RAgE: Robust Age Estimation Through Subject Anchoring with Consistency Regularisation]]></title>
        <id>https://ieeexplore.ieee.org/document/9810519</id>
        <link href="https://ieeexplore.ieee.org/document/9810519"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Modern facial age estimation systems can achieve high accuracy when training and test datasets are identically distributed and captured under similar conditions. However, domain shifts in data, encountered in practice, lead to a sharp drop in accuracy of most existing age estimation algorithms. In this work, we propose a novel method, namely RAgE, to improve the robustness and reduce the uncertain...]]></summary>
        <author>
            <name>Ali Akbari</name>
        </author>
        <author>
            <name>Muhammad Awais</name>
        </author>
        <author>
            <name>Soroush Fatemifar</name>
        </author>
        <author>
            <name>Syed Safwan Khalid</name>
        </author>
        <author>
            <name>Josef Kittler</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Optimizing Two-way Partial AUC with an End-to-end Framework]]></title>
        <id>https://ieeexplore.ieee.org/document/9804230</id>
        <link href="https://ieeexplore.ieee.org/document/9804230"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The Area Under the ROC Curve (AUC) is a crucial metric for machine learning, which evaluates the average performance over all possible True Positive Rates (TPRs) and False Positive Rates (FPRs). Based on the knowledge that a skillful classifier should simultaneously embrace a high TPR and a low FPR, we turn to study a more general variant called Two-way Partial AUC (TPAUC), where only the region w...]]></summary>
        <author>
            <name>Zhiyong Yang</name>
        </author>
        <author>
            <name>Qianqian Xu</name>
        </author>
        <author>
            <name>Shilong Bao</name>
        </author>
        <author>
            <name>Yuan He</name>
        </author>
        <author>
            <name>Xiaochun Cao</name>
        </author>
        <author>
            <name>Qingming Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Out-of-Domain Generalization From a Single Source: An Uncertainty Quantification Approach]]></title>
        <id>https://ieeexplore.ieee.org/document/9801711</id>
        <link href="https://ieeexplore.ieee.org/document/9801711"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We are concerned with a worst-case scenario in model generalization, in the sense that a model aims to perform well on many unseen domains while there is only one single domain available for training. We propose Meta-Learning based Adversarial Domain Augmentation to solve this Out-of-Domain generalization problem. The key idea is to leverage adversarial training to create &#x201C;fictitious&#x201D...]]></summary>
        <author>
            <name>Xi Peng</name>
        </author>
        <author>
            <name>Fengchun Qiao</name>
        </author>
        <author>
            <name>Long Zhao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[<italic>OpenGAN</italic>: Open-Set Recognition Via Open Data Generation]]></title>
        <id>https://ieeexplore.ieee.org/document/9799769</id>
        <link href="https://ieeexplore.ieee.org/document/9799769"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Real-world machine learning systems need to analyze test data that may differ from training data. In K-way classification, this is crisply formulated as open-set recognition, core to which is the ability to discriminate open-set data outside the K closed-set classes. Two conceptually elegant ideas for open-set discrimination are: 1) discriminatively learning an open-vs-closed binary discriminator ...]]></summary>
        <author>
            <name>Shu Kong</name>
        </author>
        <author>
            <name>Deva Ramanan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Image De-raining Transformer]]></title>
        <id>https://ieeexplore.ieee.org/document/9798773</id>
        <link href="https://ieeexplore.ieee.org/document/9798773"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Existing deep learning based de-raining approaches have resorted to the convolutional architectures. However, the intrinsic limitations of convolution, including local receptive fields and independence of input content, hinder the model&#x2019;s ability to capture long-range and complicated rainy artifacts. To overcome these limitations, we propose an effective and efficient transformer-based arch...]]></summary>
        <author>
            <name>Jie Xiao</name>
        </author>
        <author>
            <name>Xueyang Fu</name>
        </author>
        <author>
            <name>Aiping Liu</name>
        </author>
        <author>
            <name>Feng Wu</name>
        </author>
        <author>
            <name>Zheng-Jun Zha</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ordinal Unsupervised Domain Adaptation With Recursively Conditional Gaussian Imposed Variational Disentanglement]]></title>
        <id>https://ieeexplore.ieee.org/document/9796559</id>
        <link href="https://ieeexplore.ieee.org/document/9796559"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[There has been a growing interest in unsupervised domain adaptation (UDA) to alleviate the data scalability issue, while the existing works usually focus on classifying independently discrete labels. However, in many tasks (e.g., medical diagnosis), the labels are discrete and successively distributed. The UDA for ordinal classification requires inducing non-trivial ordinal distribution prior to t...]]></summary>
        <author>
            <name>Xiaofeng Liu</name>
        </author>
        <author>
            <name>Site Li</name>
        </author>
        <author>
            <name>Yubin Ge</name>
        </author>
        <author>
            <name>Pengyi Ye</name>
        </author>
        <author>
            <name>Jane You</name>
        </author>
        <author>
            <name>Jun Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ultra Fast Deep Lane Detection With Hybrid Anchor Driven Ordinal Classification]]></title>
        <id>https://ieeexplore.ieee.org/document/9795098</id>
        <link href="https://ieeexplore.ieee.org/document/9795098"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Modern methods mainly regard lane detection as a problem of pixel-wise segmentation, which is struggling to address the problems of efficiency and challenging scenarios like severe occlusions and extreme lighting conditions. Inspired by human perception, the recognition of lanes under severe occlusions and extreme lighting conditions is mainly based on contextual and global information. Motivated ...]]></summary>
        <author>
            <name>Zequn Qin</name>
        </author>
        <author>
            <name>Pengyi Zhang</name>
        </author>
        <author>
            <name>Xi Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fourier-based and Rational Graph Filters for Spectral Processing]]></title>
        <id>https://ieeexplore.ieee.org/document/9780026</id>
        <link href="https://ieeexplore.ieee.org/document/9780026"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Data are represented as graphs in a wide range of applications, such as Computer Vision (e.g., images) and Graphics (e.g., 3D meshes), network analysis (e.g., social networks), and bio-informatics (e.g., molecules). In this context, our overall goal is the definition of novel Fourier-based and graph filters induced by rational polynomials for graph processing, which generalise polynomial filters a...]]></summary>
        <author>
            <name>Giuseppe Patane'</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Answer Visual Questions from Web Videos]]></title>
        <id>https://ieeexplore.ieee.org/document/9770842</id>
        <link href="https://ieeexplore.ieee.org/document/9770842"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recent methods for visual question answering rely on large-scale annotated datasets. Manual annotation of questions and answers for videos, however, is tedious, expensive and prevents scalability. In this work, we propose to avoid manual annotation and generate a large-scale training dataset for video question answering making use of automatic cross-modal supervision. We leverage a question genera...]]></summary>
        <author>
            <name>Antoine Yang</name>
        </author>
        <author>
            <name>Antoine Miech</name>
        </author>
        <author>
            <name>Josef Sivic</name>
        </author>
        <author>
            <name>Ivan Laptev</name>
        </author>
        <author>
            <name>Cordelia Schmid</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graphical Modeling for Multi-Source Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/9767755</id>
        <link href="https://ieeexplore.ieee.org/document/9767755"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multi-Source Domain Adaptation (MSDA) focuses on transferring the knowledge from multiple source domains to the target domain, which is a more practical and challenging problem compared to the conventional single-source domain adaptation. In this problem, it is essential to model multiple source domains and target domain jointly, and an effective domain combination scheme is also highly required. ...]]></summary>
        <author>
            <name>Minghao Xu</name>
        </author>
        <author>
            <name>Hang Wang</name>
        </author>
        <author>
            <name>Bingbing Ni</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Looking Beyond Single Images for Weakly Supervised Semantic Segmentation Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9760057</id>
        <link href="https://ieeexplore.ieee.org/document/9760057"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This article studies the problem of learning weakly supervised semantic segmentation (WSSS) from image-level supervision only. Rather than previous efforts that primarily focus on intra-image information, we address the value of cross-image semantic relations for comprehensive object pattern mining. To achieve this, two neural co-attentions are incorporated into the classifier to complimentarily c...]]></summary>
        <author>
            <name>Wenguan Wang</name>
        </author>
        <author>
            <name>Guolei Sun</name>
        </author>
        <author>
            <name>Luc Van Gool</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reinforcing Generated Images via Meta-learning for One-Shot Fine-Grained Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9756906</id>
        <link href="https://ieeexplore.ieee.org/document/9756906"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[One-shot fine-grained visual recognition often suffers from the problem of training data scarcity for new fine-grained classes. To alleviate this problem, off-the-shelf image generation techniques based on Generative Adversarial Networks (GANs) can potentially create additional training images. However, these GAN-generated images are often not helpful for actually improving the accuracy of one-sho...]]></summary>
        <author>
            <name>Satoshi Tsutsui</name>
        </author>
        <author>
            <name>Yanwei Fu</name>
        </author>
        <author>
            <name>David Crandall</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Anti-Adversarially Manipulated Attributions for Weakly Supervised Semantic Segmentation and Object Localization]]></title>
        <id>https://ieeexplore.ieee.org/document/9756329</id>
        <link href="https://ieeexplore.ieee.org/document/9756329"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Obtaining accurate pixel-level localization from class labels is a crucial process in weakly supervised semantic segmentation and object localization. Attribution maps from a trained classifier are widely used to provide pixel-level localization, but their focus tends to be restricted to a small discriminative region of the target object. AdvCAM is an attribution map of an image that is manipulate...]]></summary>
        <author>
            <name>Jungbeom Lee</name>
        </author>
        <author>
            <name>Eunji Kim</name>
        </author>
        <author>
            <name>Jisoo Mok</name>
        </author>
        <author>
            <name>Sungroh Yoon</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Adverse Weather Conditions Adaptation for Object Detection via Causal Intervention]]></title>
        <id>https://ieeexplore.ieee.org/document/9756301</id>
        <link href="https://ieeexplore.ieee.org/document/9756301"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Most state-of-the-art object detection methods have achieved impressive perfomrace on several public benchmarks, which are trained with high definition images. However, existing detectors are often sensitive to the visual variations and out-of-distribution data due to the domain gap caused by various confounders, e.g. the adverse weathre conditions. To bridge the gap, previous methods have been ma...]]></summary>
        <author>
            <name>Hua Zhang</name>
        </author>
        <author>
            <name>Liqiang Xiao</name>
        </author>
        <author>
            <name>Xiaochun Cao</name>
        </author>
        <author>
            <name>Hassan Foroosh</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deeply Unsupervised Patch Re-Identification for Pre-training Object Detectors]]></title>
        <id>https://ieeexplore.ieee.org/document/9749837</id>
        <link href="https://ieeexplore.ieee.org/document/9749837"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Unsupervised pre-training aims at learning transferable features that are beneficial for downstream tasks. However, most state-of-the-art unsupervised methods concentrate on learning global representations for image-level classification tasks instead of discriminative local region representations, which limits their transferability to region-level downstream tasks, such as object detection. To imp...]]></summary>
        <author>
            <name>Jian Ding</name>
        </author>
        <author>
            <name>Enze Xie</name>
        </author>
        <author>
            <name>Hang Xu</name>
        </author>
        <author>
            <name>Chenhan Jiang</name>
        </author>
        <author>
            <name>Zhenguo Li</name>
        </author>
        <author>
            <name>Ping Luo</name>
        </author>
        <author>
            <name>Gui-Song Xia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Graph Embeddings for Open World Compositional Zero-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9745371</id>
        <link href="https://ieeexplore.ieee.org/document/9745371"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Compositional Zero-Shot learning (CZSL) aims to recognize unseen compositions of state and object visual primitives seen during training. A problem with standard CZSL is the assumption of knowing which unseen compositions will be available at test time. In this work, we overcome this assumption operating on the open world setting, where no limit is imposed on the compositional space at test time, ...]]></summary>
        <author>
            <name>Massimiliano Mancini</name>
        </author>
        <author>
            <name>Muhammad Ferjad Naeem</name>
        </author>
        <author>
            <name>Yongqin Xian</name>
        </author>
        <author>
            <name>Zeynep Akata</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Intra-Inter Domain Similarity for Unsupervised Person Re-Identification]]></title>
        <id>https://ieeexplore.ieee.org/document/9745321</id>
        <link href="https://ieeexplore.ieee.org/document/9745321"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Most of unsupervised person Re-Identification (Re-ID) works produce pseudo-labels by measuring the feature similarity without considering the domain discrepancy among cameras, leading to degraded accuracy in pseudo label computation. This paper targets to address this challenge by decomposing the similarity computation into two stage, i.e., the intra-domain and inter-domain computations, respectiv...]]></summary>
        <author>
            <name>Shiyu Xuan</name>
        </author>
        <author>
            <name>Shiliang Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[NPT-Loss: Demystifying face recognition losses with Nearest Proxies Triplet]]></title>
        <id>https://ieeexplore.ieee.org/document/9743810</id>
        <link href="https://ieeexplore.ieee.org/document/9743810"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Face recognition (FR) using deep convolutional neural networks (DCNNs) has seen remarkable success in recent years. One key ingredient of DCNN-based FR is the design of a loss function that ensures discrimination between various identities. The state-of-the-art (SOTA) solutions utilise normalised Softmax loss with additive and/or multiplicative margins. Despite being popular and effective, these l...]]></summary>
        <author>
            <name>Syed Safwan Khalid</name>
        </author>
        <author>
            <name>Muhammad Awais</name>
        </author>
        <author>
            <name>Zhenhua Feng</name>
        </author>
        <author>
            <name>Chi Ho Chan</name>
        </author>
        <author>
            <name>Ammarah Farooq</name>
        </author>
        <author>
            <name>Ali Akbari</name>
        </author>
        <author>
            <name>Josef Kittler</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-supervised Latent Space Optimization with Nebula Variational Coding]]></title>
        <id>https://ieeexplore.ieee.org/document/9740011</id>
        <link href="https://ieeexplore.ieee.org/document/9740011"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Deep learning approaches process data in a layer-by-layer way with intermediate (or latent) features. We aim at designing a general solution to optimize the latent manifolds to improve the performance on classification, segmentation, completion and/or reconstruction through probabilistic models. This paper proposes a variational inference model which leads to a clustered embedding. We introduce ad...]]></summary>
        <author>
            <name>Yida Wang</name>
        </author>
        <author>
            <name>David Joseph Tan</name>
        </author>
        <author>
            <name>Nassir Navab</name>
        </author>
        <author>
            <name>Federico Tombari</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-Shot Learning with a Strong Teacher]]></title>
        <id>https://ieeexplore.ieee.org/document/9737396</id>
        <link href="https://ieeexplore.ieee.org/document/9737396"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Few-shot learning (FSL) aims to generate a classifier using limited labeled examples. Many existing works take the meta-learning approach, constructing a few-shot learner (a meta-model) that can learn from few-shot examples to generate a classifier. The performance is measured by how well the resulting classifiers classify the test (\ie, query) examples of those tasks. In this paper, we point out ...]]></summary>
        <author>
            <name>Han-Jia Ye</name>
        </author>
        <author>
            <name>Lu Ming</name>
        </author>
        <author>
            <name>De-Chuan Zhan</name>
        </author>
        <author>
            <name>Wei-Lun Chao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Feature Re-Representation and Reliable Pseudo Label Retraining for Cross-Domain Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9733271</id>
        <link href="https://ieeexplore.ieee.org/document/9733271"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This paper presents a novel unsupervised domain adaptation method for semantic segmentation. We argue that a good representation of the target-domain data should keep both the knowledge from the source domain and the target-domain-specific information. To obtain the knowledge from the source domain, we first learn a set of bases to characterize the feature distribution of the source domain, then f...]]></summary>
        <author>
            <name>Jing Li</name>
        </author>
        <author>
            <name>Kang Zhou</name>
        </author>
        <author>
            <name>Shenhan Qian</name>
        </author>
        <author>
            <name>Wen Li</name>
        </author>
        <author>
            <name>Lixin Duan</name>
        </author>
        <author>
            <name>Shenghua Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Unsupervised and Semi-supervised Robust Spherical Space Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/9733209</id>
        <link href="https://ieeexplore.ieee.org/document/9733209"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Adversarial domain adaptation has been an effective approach for learning domain-invariant features by adversarial training. In this paper, we propose a novel adversarial domain adaptation approach defined in the spherical feature space, in which we define spherical classifier for label prediction and spherical domain discriminator for discriminating domain labels. In the spherical feature space, ...]]></summary>
        <author>
            <name>Xiang Gu</name>
        </author>
        <author>
            <name>Jian Sun</name>
        </author>
        <author>
            <name>Zongben Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recursive Least-Squares Estimator-Aided Online Learning for Visual Tracking]]></title>
        <id>https://ieeexplore.ieee.org/document/9729522</id>
        <link href="https://ieeexplore.ieee.org/document/9729522"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Tracking visual objects from a single initial exemplar in the testing phase has been broadly cast as a one-/few-shot problem, i.e., one-shot learning for initial adaptation and few-shot learning for online adaptation. The recent few-shot online adaptation methods incorporate the prior knowledge from large amounts of annotated training data via complex meta-learning optimization in the offline phas...]]></summary>
        <author>
            <name>Jin Gao</name>
        </author>
        <author>
            <name>Yan Lu</name>
        </author>
        <author>
            <name>Xiaojuan Qi</name>
        </author>
        <author>
            <name>Yutong Kou</name>
        </author>
        <author>
            <name>Bing Li</name>
        </author>
        <author>
            <name>Liang Li</name>
        </author>
        <author>
            <name>Shan Yu</name>
        </author>
        <author>
            <name>Weiming Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MetaKernel: Learning Variational Random Features with Limited Labels]]></title>
        <id>https://ieeexplore.ieee.org/document/9722994</id>
        <link href="https://ieeexplore.ieee.org/document/9722994"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Few-shot learning deals with the fundamental and challenging problem of learning from a few annotated samples, while being able to generalize well on new tasks. The crux of few-shot learning is to extract prior knowledge from related tasks to enable fast adaptation to a new task with a limited amount of data. In this paper, we propose meta-learning kernels with random Fourier features for few-shot...]]></summary>
        <author>
            <name>Yingjun Du</name>
        </author>
        <author>
            <name>Haoliang Sun</name>
        </author>
        <author>
            <name>Xiantong Zhen</name>
        </author>
        <author>
            <name>Jun Xu</name>
        </author>
        <author>
            <name>Yilong Yin</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
        <author>
            <name>Cees G.M. Snoek</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FINC: An Efficient and Effective Optimization Method for Normalized Cut]]></title>
        <id>https://ieeexplore.ieee.org/document/9706351</id>
        <link href="https://ieeexplore.ieee.org/document/9706351"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The optimization methods for solving the normalized cut model usually involve three steps, i.e., problem relaxation, problem solving and post-processing. However, these methods are problematic in both performance since they do not directly solve the original problem, and efficiency since they usually depend on the time-consuming eigendecomposition and k-means (or spectral rotation) for post-proces...]]></summary>
        <author>
            <name>Xiaojun Chen</name>
        </author>
        <author>
            <name>Zhicong Xiao</name>
        </author>
        <author>
            <name>Feiping Nie</name>
        </author>
        <author>
            <name>Joshua Zhexue Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantics-Guided Contrastive Network for Zero-Shot Object detection]]></title>
        <id>https://ieeexplore.ieee.org/document/9669022</id>
        <link href="https://ieeexplore.ieee.org/document/9669022"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Zero-shot object detection (ZSD), the task that extends conventional detection models to detecting objects from unseen categories, has emerged as a new challenge in computer vision. Most existing approaches on ZSD are based on a strict mapping-transfer strategy that learns a mapping function from visual to semantic space over seen categories, then directly generalizes the learned mapping function ...]]></summary>
        <author>
            <name>Caixia Yan</name>
        </author>
        <author>
            <name>Xiaojun Chang</name>
        </author>
        <author>
            <name>Minnan Luo</name>
        </author>
        <author>
            <name>Huan Liu</name>
        </author>
        <author>
            <name>Xiaoqin Zhang</name>
        </author>
        <author>
            <name>Qinghua Zheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Depth and Video Segmentation Based Visual Attention for Embodied Question Answering]]></title>
        <id>https://ieeexplore.ieee.org/document/9669060</id>
        <link href="https://ieeexplore.ieee.org/document/9669060"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Embodied Question Answering (EQA) is a newly defined research area where an agent is required to answer the users questions by exploring the real-world environment. It has attracted increasing research interests due to its broad applications in personal assistants and in-home robots. Most of the existing methods perform poorly in terms of answering and navigation accuracy due to the absence of fin...]]></summary>
        <author>
            <name>Haonan Luo</name>
        </author>
        <author>
            <name>Guosheng Lin</name>
        </author>
        <author>
            <name>Yazhou Yao</name>
        </author>
        <author>
            <name>Fayao Liu</name>
        </author>
        <author>
            <name>Zichuan Liu</name>
        </author>
        <author>
            <name>Zhenming Tang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Semantic Segmentation via Efficient Self-Training]]></title>
        <id>https://ieeexplore.ieee.org/document/9663011</id>
        <link href="https://ieeexplore.ieee.org/document/9663011"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Starting from the seminal work of Fully Convolutional Networks (FCN), there has been significant progress on semantic segmentation. However, deep learning models often require large amounts of pixelwise annotations to train accurate and robust models. Given the prohibitively expensive annotation cost of segmentation masks, we introduce a self-training framework in this paper to leverage pseudo lab...]]></summary>
        <author>
            <name>Yi Zhu</name>
        </author>
        <author>
            <name>Zhongyue Zhang</name>
        </author>
        <author>
            <name>Chongruo Wu</name>
        </author>
        <author>
            <name>Zhi Zhang</name>
        </author>
        <author>
            <name>Tong He</name>
        </author>
        <author>
            <name>Hang Zhang</name>
        </author>
        <author>
            <name>R Manmatha</name>
        </author>
        <author>
            <name>Mu Li</name>
        </author>
        <author>
            <name>Alexander J Smola</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Are Labels Always Necessary for Classifier Accuracy Evaluation]]></title>
        <id>https://ieeexplore.ieee.org/document/9655472</id>
        <link href="https://ieeexplore.ieee.org/document/9655472"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Understanding model decision under novel test scenarios is central to the community. A common practice is evaluating models on labeled test sets. However, many real-world scenarios see unlabeled test data, rendering the common supervised evaluation protocols infeasible. In this paper, we investigate such an important but under-explored problem, named Automatic model Evaluation (AutoEval). Specific...]]></summary>
        <author>
            <name>Weijian Deng</name>
        </author>
        <author>
            <name>Liang Zheng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation]]></title>
        <id>https://ieeexplore.ieee.org/document/9655492</id>
        <link href="https://ieeexplore.ieee.org/document/9655492"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[6D object pose estimation is a fundamental yet challenging problem in computer vision. Convolutional Neural Networks (CNNs) have recently proven to be capable of predicting reliable 6D pose estimates even under monocular settings. Nonetheless, CNNs are identified as being extremely data-driven, and acquiring adequate annotations is oftentimes very time-consuming and labor intensive. To overcome th...]]></summary>
        <author>
            <name>Gu Wang</name>
        </author>
        <author>
            <name>Fabian Manhardt</name>
        </author>
        <author>
            <name>Xingyu Liu</name>
        </author>
        <author>
            <name>Xiangyang Ji</name>
        </author>
        <author>
            <name>Federico Tombari</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MgSvF: Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9645290</id>
        <link href="https://ieeexplore.ieee.org/document/9645290"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[As a challenging problem, few-shot class-incremental learning (FSCIL) continually learns a sequence of tasks, confronting the dilemma between slow forgetting of old knowledge and fast adaptation to new knowledge. In this paper, we concentrate on this ‘`slow vs. fast’&#39; (SvF) dilemma to determine which knowledge components to be updated in a slow fashion or a fast fashion, and thereby balance old-kn...]]></summary>
        <author>
            <name>Hanbin Zhao</name>
        </author>
        <author>
            <name>Yongjian Fu</name>
        </author>
        <author>
            <name>Mintong Kang</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
        <author>
            <name>Fei Wu</name>
        </author>
        <author>
            <name>Xi Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Where and How to Transfer: Knowledge Aggregation-Induced Transferability Perception for Unsupervised Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/9616392</id>
        <link href="https://ieeexplore.ieee.org/document/9616392"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Unsupervised domain adaptation without accessing expensive annotation processes of target data has achieved remarkable successes in semantic segmentation. However, most existing state-of-the-art methods cannot explore whether semantic representations across domains are transferable or not, which may result in the negative transfer brought by irrelevant knowledge. To tackle this challenge, in this ...]]></summary>
        <author>
            <name>Jiahua Dong</name>
        </author>
        <author>
            <name>Yang Cong</name>
        </author>
        <author>
            <name>Gan Sun</name>
        </author>
        <author>
            <name>Zhen Fang</name>
        </author>
        <author>
            <name>Zhengming Ding</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Network and Spatiotemporal Transformer Attention for 3D Video Object Detection from Point Clouds]]></title>
        <id>https://ieeexplore.ieee.org/document/9609569</id>
        <link href="https://ieeexplore.ieee.org/document/9609569"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Previous works for LiDAR-based 3D object detection mainly focus on the single-frame paradigm. In this paper, we propose to detect 3D objects by exploiting temporal information in multiple frames, i.e., the point cloud videos. We empirically categorize the temporal information into short-term and long-term patterns. To encode the short-term data, we present a Grid Message Passing Network (GMPNet), ...]]></summary>
        <author>
            <name>Junbo Yin</name>
        </author>
        <author>
            <name>Jianbing Shen</name>
        </author>
        <author>
            <name>Xin Gao</name>
        </author>
        <author>
            <name>David Crandall</name>
        </author>
        <author>
            <name>Ruigang Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few-shot domain-adaptive anomaly detection for cross-site brain images]]></title>
        <id>https://ieeexplore.ieee.org/document/9606561</id>
        <link href="https://ieeexplore.ieee.org/document/9606561"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Early screening is essential for effective intervention and treatment of individuals with mental disorders. Functional magnetic resonance imaging (fMRI) is a noninvasive tool for depicting neural activity and has demonstrated strong potential as a technique for identifying mental disorders. Due to the difficulty in data collection and diagnosis, imaging data from patients are rare at a single site...]]></summary>
        <author>
            <name>Jianpo Su</name>
        </author>
        <author>
            <name>Hui Shen</name>
        </author>
        <author>
            <name>Limin Peng</name>
        </author>
        <author>
            <name>Dewen Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging Hand-Object Interactions in Assistive Egocentric Vision]]></title>
        <id>https://ieeexplore.ieee.org/document/9591443</id>
        <link href="https://ieeexplore.ieee.org/document/9591443"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Egocentric vision holds great promise for increasing access to visual information and improving the quality of life for blind people. While we strive to improve recognition performance, it remains difficult to identify which object is of interest to the user; the object may not even be included in the frame due to challenges in camera aiming without visual feedback. Also, gaze information, commonl...]]></summary>
        <author>
            <name>Kyungjun Lee</name>
        </author>
        <author>
            <name>Abhinav Shrivastava</name>
        </author>
        <author>
            <name>Hernisa Kacorri</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deconfounded Image Captioning: A Causal Retrospect]]></title>
        <id>https://ieeexplore.ieee.org/document/9583890</id>
        <link href="https://ieeexplore.ieee.org/document/9583890"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Dataset bias in vision-language tasks is becoming one of the main problems which hinders the progress of our community. Existing solutions lack a principled analysis about why modern image captioners easily collapse into dataset bias. In this paper, we present a novel perspective: Deconfounded Image Captioning (DIC), to find out the answer of this question, then retrospect modern neural image capt...]]></summary>
        <author>
            <name>Xu Yang</name>
        </author>
        <author>
            <name>Hanwang Zhang</name>
        </author>
        <author>
            <name>Jianfei Cai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical Rules]]></title>
        <id>https://ieeexplore.ieee.org/document/9582776</id>
        <link href="https://ieeexplore.ieee.org/document/9582776"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Knowledge graph embedding models have gained significant attention in AI research. The aim of knowledge graph embedding is to embed the graphs into a vector space in which the structure of the graph is preserved. Recent works have shown that the inclusion of background knowledge, such as logical rules, can improve the performance of embeddings in downstream machine learning tasks. However, so far,...]]></summary>
        <author>
            <name>Mojtaba Nayyeri</name>
        </author>
        <author>
            <name>Chengjin Xu</name>
        </author>
        <author>
            <name>Mirza Mohtashim Alam</name>
        </author>
        <author>
            <name>Jens Lehmann</name>
        </author>
        <author>
            <name>Hamed Shariat Yazdi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating Personalized Summaries of Day Long Egocentric Videos]]></title>
        <id>https://ieeexplore.ieee.org/document/9562265</id>
        <link href="https://ieeexplore.ieee.org/document/9562265"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The popularity of egocentric cameras and their always-on nature has lead to the abundance of day long first-person videos. The highly redundant nature of these videos and extreme camera-shakes make them difficult to watch from beginning to end. These videos require efficient summarization tools for consumption. However, traditional summarization techniques developed for static surveillance videos ...]]></summary>
        <author>
            <name>Pravin Nagar</name>
        </author>
        <author>
            <name>Anuj Rathore</name>
        </author>
        <author>
            <name>C. V. Jawahar</name>
        </author>
        <author>
            <name>Chetan Arora</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Incomplete Multiple Kernel Alignment Maximization for Clustering]]></title>
        <id>https://ieeexplore.ieee.org/document/9556554</id>
        <link href="https://ieeexplore.ieee.org/document/9556554"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multiple kernel alignment (MKA) maximization criterion has been widely applied into multiple kernel clustering (MKC) and many variants have been recently developed. Though demonstrating superior clustering performance in various applications, it is observed that none of them can effectively handle incomplete MKC, where parts or all of the pre-specified base kernel matrices are incomplete. To addre...]]></summary>
        <author>
            <name>Xinwang Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Holistically-Guided Decoder for Deep Representation Learning with Applications to Semantic Segmentation and Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/9551977</id>
        <link href="https://ieeexplore.ieee.org/document/9551977"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Both high-level and high-resolution feature representations are of great importance in various visual understanding tasks. In this paper, we propose one novel holistically-guided decoder which is introduced to obtain the high-resolution semantic-rich feature maps via the multi-scale features from the encoder. The decoding is achieved via novel holistic codeword generation and codeword assembly ope...]]></summary>
        <author>
            <name>Jianbo Liu</name>
        </author>
        <author>
            <name>Junjun He</name>
        </author>
        <author>
            <name>Yuanjie Zheng</name>
        </author>
        <author>
            <name>Shuai Yi</name>
        </author>
        <author>
            <name>Xiaogang Wang</name>
        </author>
        <author>
            <name>Hongsheng Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Recognizing Predictive Substructures with Subgraph Information Bottleneck]]></title>
        <id>https://ieeexplore.ieee.org/document/9537601</id>
        <link href="https://ieeexplore.ieee.org/document/9537601"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The emergence of Graph Convolutional Network (GCN) has greatly boosted the progress of graph learning. However, two disturbing factors, noise and redundancy in graph data, and lack of interpretation for prediction results, impede further development of GCN. One solution is to recognize a predictive yet compressed subgraph to get rid of the noise and redundancy and obtain the interpretable part of ...]]></summary>
        <author>
            <name>Junchi Yu</name>
        </author>
        <author>
            <name>Tingyang Xu</name>
        </author>
        <author>
            <name>Yu Rong</name>
        </author>
        <author>
            <name>Yatao Bian</name>
        </author>
        <author>
            <name>Junzhou Huang</name>
        </author>
        <author>
            <name>Ran He</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Large-scale Virtual Dataset and Egocentric Localization for Disaster Responses]]></title>
        <id>https://ieeexplore.ieee.org/document/9476992</id>
        <link href="https://ieeexplore.ieee.org/document/9476992"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[With the increasing social demands of disaster response, methods of visual observation for rescue and safety have become increasingly important. However, because of the shortage of datasets for disaster scenarios, there has been little progress in computer vision and robotics in this field. With this in mind, we present the first large-scale synthetic dataset of egocentric viewpoints for disaster ...]]></summary>
        <author>
            <name>Hae-Gon Jeon</name>
        </author>
        <author>
            <name>Sunghoon Im</name>
        </author>
        <author>
            <name>Byeong-Uk Lee</name>
        </author>
        <author>
            <name>Francois Rameau</name>
        </author>
        <author>
            <name>Dong-Geol Choi</name>
        </author>
        <author>
            <name>Jean Oh</name>
        </author>
        <author>
            <name>In So Kweon</name>
        </author>
        <author>
            <name>Martial Hebert</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Revisiting 2D Convolutional Neural Networks for Graph-based Applications]]></title>
        <id>https://ieeexplore.ieee.org/document/9440667</id>
        <link href="https://ieeexplore.ieee.org/document/9440667"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graph convolutional networks are widely used in graph-based applications such as graph classification and segmentation. However, current GCNs have limitations on implementation such as network architectures due to their irregular inputs. In contrast, convolutional neural networks are capable to extract rich features from large-scale input data, but they do not support general graph inputs. To brid...]]></summary>
        <author>
            <name>Yecheng Lyu</name>
        </author>
        <author>
            <name>Xinming Huang</name>
        </author>
        <author>
            <name>Ziming Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepGCNs: Making GCNs Go as Deep as CNNs]]></title>
        <id>https://ieeexplore.ieee.org/document/9408381</id>
        <link href="https://ieeexplore.ieee.org/document/9408381"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Convolutional Neural Networks have been very successful at solving a variety of computer vision tasks such as object classification and detection, semantic segmentation, activity understanding, to name just a few. One key enabling factor for their great performance has been the ability to train very deep networks. Despite their huge success in many tasks, CNNs do not work well with non-Euclidean d...]]></summary>
        <author>
            <name>Guohao Li</name>
        </author>
        <author>
            <name>Matthias Mueller</name>
        </author>
        <author>
            <name>Guocheng Qian</name>
        </author>
        <author>
            <name>Itzel Carolina Delgadillo Perez</name>
        </author>
        <author>
            <name>Abdulellah Abualshour</name>
        </author>
        <author>
            <name>Ali Kassem Thabet</name>
        </author>
        <author>
            <name>Bernard Ghanem</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[JRDB: A Dataset and Benchmark of Egocentric Robot Visual Perception of Humans in Built Environments]]></title>
        <id>https://ieeexplore.ieee.org/document/9394786</id>
        <link href="https://ieeexplore.ieee.org/document/9394786"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present JRDB, a novel egocentric dataset collected from our social mobile manipulator JackRabbot. The dataset includes 64 minutes of annotated multimodal sensor data including stereo cylindrical 360 RGB video at 15 fps, 3D point clouds from two Velodyne 16 Lidars, line 3D point clouds from two Sick Lidars, audio signal, RGB-D video at 30 fps, 360 spherical image from a fisheye camera and encode...]]></summary>
        <author>
            <name>Roberto Martin-Martin</name>
        </author>
        <author>
            <name>Mihir Patel</name>
        </author>
        <author>
            <name>Hamid Rezatofighi</name>
        </author>
        <author>
            <name>Abhijeet Shenoi</name>
        </author>
        <author>
            <name>Junyoung Gwak</name>
        </author>
        <author>
            <name>Eric Frankel</name>
        </author>
        <author>
            <name>Amir Sadeghian</name>
        </author>
        <author>
            <name>Silvio Savarese</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geodesic Multi-Class SVM with Stiefel Manifold Embedding]]></title>
        <id>https://ieeexplore.ieee.org/document/9390382</id>
        <link href="https://ieeexplore.ieee.org/document/9390382"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Manifold of geodesic plays an essential role in characterizing the intrinsic data geometry. However, the existing SVM methods have largely neglected the manifold structure. As such, functional degeneration may occur due to the potential polluted training. Even worse, the entire SVM model might collapse in the presence of excessive training contamination. To address these issues, this paper devises...]]></summary>
        <author>
            <name>Rui Zhang</name>
        </author>
        <author>
            <name>Xuelong Li</name>
        </author>
        <author>
            <name>Hongyuan Zhang</name>
        </author>
        <author>
            <name>Ziheng Jiao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Graph Convolutional Networks for Multi-Label Recognition and Applications]]></title>
        <id>https://ieeexplore.ieee.org/document/9369105</id>
        <link href="https://ieeexplore.ieee.org/document/9369105"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The task of multi-label image recognition is to predict a set of object labels that present in an image. As objects normally co-occur in an image, it is desirable to model label dependencies to improve recognition performance. To capture and explore such important information, we propose Graph Convolutional Networks based models for multi-label recognition, where directed graphs are constructed ov...]]></summary>
        <author>
            <name>Zhaomin Chen</name>
        </author>
        <author>
            <name>Xiu-Shen Wei</name>
        </author>
        <author>
            <name>Peng Wang</name>
        </author>
        <author>
            <name>Yanwen Guo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Dataset, Multitask Learning of Egocentric Vision Tasks]]></title>
        <id>https://ieeexplore.ieee.org/document/9361177</id>
        <link href="https://ieeexplore.ieee.org/document/9361177"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[For egocentric vision tasks such as action recognition, there is a relative scarcity of labeled data. This increases the risk of overfitting during training. In this paper, we address this issue by introducing a multitask learning scheme that employs related tasks as well as related datasets in the training process. Related tasks are indicative of the performed action, such as the presence of obje...]]></summary>
        <author>
            <name>Georgios Kapidis</name>
        </author>
        <author>
            <name>Ronald Poppe</name>
        </author>
        <author>
            <name>Remco C. Veltkamp</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Self-Regulated Learning for Egocentric Video Activity Anticipation]]></title>
        <id>https://ieeexplore.ieee.org/document/9356220</id>
        <link href="https://ieeexplore.ieee.org/document/9356220"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Future activity anticipation is a challenging problem in egocentric vision. As a standard future activity anticipation paradigm, recursive sequence prediction suffers from the accumulation of errors. To address this problem, we propose a simple and effective Self-Regulated Learning framework, which aims to regulate the intermediate representation consecutively to produce representation that (a) em...]]></summary>
        <author>
            <name>Zhaobo Qi</name>
        </author>
        <author>
            <name>Shuhui Wang</name>
        </author>
        <author>
            <name>Chi Su</name>
        </author>
        <author>
            <name>Li Su</name>
        </author>
        <author>
            <name>Qingming Huang</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Recognize Actions on Objects in Egocentric Video with Attention Dictionaries]]></title>
        <id>https://ieeexplore.ieee.org/document/9353268</id>
        <link href="https://ieeexplore.ieee.org/document/9353268"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present EgoACO, a deep neural architecture for video action recognition that learns to pool action-context-object descriptors from frame level features by leveraging the verb-noun structure of action labels in egocentric video datasets. The core component of EgoACO is class activation pooling (CAP), a differentiable pooling operation that combines ideas from bilinear pooling for fine-grained re...]]></summary>
        <author>
            <name>Swathikiran Sudhakaran</name>
        </author>
        <author>
            <name>Sergio Escalera</name>
        </author>
        <author>
            <name>Oswald Lanz</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Domain-Specific Priors and Meta Learning for Few-Shot First-Person Action Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9352536</id>
        <link href="https://ieeexplore.ieee.org/document/9352536"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The lack of large-scale real datasets with annotations makes transfer learning a necessity for video activity understanding. We aim to develop an effective method for few-shot transfer learning for first-person action classification. We leverage independently trained local visual cues to learn representations that can be transferred from a source domain, which provides primitive action labels, to ...]]></summary>
        <author>
            <name>Huseyin Coskun</name>
        </author>
        <author>
            <name>M. Zeeshan Zia</name>
        </author>
        <author>
            <name>Bugra Tekin</name>
        </author>
        <author>
            <name>Federica Bogo</name>
        </author>
        <author>
            <name>Nassir Navab</name>
        </author>
        <author>
            <name>Federico Tombari</name>
        </author>
        <author>
            <name>Harpreet Sawhney</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Forecasting Action through Contact Representations from First Person Video]]></title>
        <id>https://ieeexplore.ieee.org/document/9340014</id>
        <link href="https://ieeexplore.ieee.org/document/9340014"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Human visual understanding of action is reliant on anticipation of contact as is demonstrated by pioneering work in cognitive science. Taking inspiration from this, we introduce representations and models centered on contact, which we then use in action prediction and anticipation. We annotate a subset of the EPIC Kitchens dataset to include time-to-contact between hands and objects, as well as se...]]></summary>
        <author>
            <name>Eadom Dessalene</name>
        </author>
        <author>
            <name>Chinmaya Devaraj</name>
        </author>
        <author>
            <name>Michael Maynord</name>
        </author>
        <author>
            <name>Cornelia Fermuller</name>
        </author>
        <author>
            <name>Yiannis Aloimonos</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[In the Eye of the Beholder: Gaze and Actions in First Person Video]]></title>
        <id>https://ieeexplore.ieee.org/document/9325929</id>
        <link href="https://ieeexplore.ieee.org/document/9325929"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We address the task of jointly determining what a person is doing and where they are looking based on the analysis of video captured by a headworn camera. To facilitate our research, we first introduce the EGTEA Gaze+ dataset. Our dataset comes with videos, gaze tracking data, hand masks and action annotations, thereby providing the most comprehensive benchmark for First Person Vision (FPV). Movin...]]></summary>
        <author>
            <name>Yin Li</name>
        </author>
        <author>
            <name>Miao Liu</name>
        </author>
        <author>
            <name>Jame Rehg</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Global Context Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9307278</id>
        <link href="https://ieeexplore.ieee.org/document/9307278"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The Non-Local Network (NLNet) presents a pioneering approach for capturing long-range dependencies within an image, via aggregating query-specific global context to each query position. However, through a rigorous empirical analysis, we have found that the global contexts modeled by the non-local network are almost the same for different query positions. In this paper, we take advantage of this fi...]]></summary>
        <author>
            <name>Yue Cao</name>
        </author>
        <author>
            <name>Jiarui Xu</name>
        </author>
        <author>
            <name>Stephen Lin</name>
        </author>
        <author>
            <name>Fangyun Wei</name>
        </author>
        <author>
            <name>Han Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HiGCIN: Hierarchical Graph-based Cross Inference Network for Group Activity Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9241410</id>
        <link href="https://ieeexplore.ieee.org/document/9241410"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Group activity recognition (GAR) is a challenging task aimed at recognizing the behavior of a group of people. It is a complex inference process in which visual cues collected from individuals are integrated into the final prediction, being aware of the interaction between them. This paper goes one step further beyond the existing approaches by designing a Hierarchical Graph-based Cross Inference ...]]></summary>
        <author>
            <name>Rui Yan</name>
        </author>
        <author>
            <name>Lingxi Xie</name>
        </author>
        <author>
            <name>Jinhui Tang</name>
        </author>
        <author>
            <name>Xiangbo Shu</name>
        </author>
        <author>
            <name>Qi Tian</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Multi-View Interactional Skeleton Graph for Action Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9234715</id>
        <link href="https://ieeexplore.ieee.org/document/9234715"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Capturing the interactions of human articulations lies in the center of skeleton-based action recognition. Recent graph-based methods are inherently limited in the weak spatial context modeling capability due to fixed interaction pattern and inflexible shared weights of GCN. To address above problems, we propose the Multi-View Interactional Graph Network (MV-IGNet) which can construct, learn and i...]]></summary>
        <author>
            <name>Minsi Wang</name>
        </author>
        <author>
            <name>Bingbing Ni</name>
        </author>
        <author>
            <name>Xiaokang Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Multi-Attention Context Graph for Group-Based Re-Identification]]></title>
        <id>https://ieeexplore.ieee.org/document/9233968</id>
        <link href="https://ieeexplore.ieee.org/document/9233968"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Learning to re-identify a group of people across camera systems has important applications in video surveillance. However, most existing methods focus on person re-identification (re-id), ignoring the fact that people often walk in groups. In this work, we consider employing context information for group re-id. On the one hand, group re-id is more challenging than single person re-id, since it req...]]></summary>
        <author>
            <name>Yichao Yan</name>
        </author>
        <author>
            <name>Jie Qin</name>
        </author>
        <author>
            <name>Bingbing Ni</name>
        </author>
        <author>
            <name>Jiaxin Chen</name>
        </author>
        <author>
            <name>Li Liu</name>
        </author>
        <author>
            <name>Fan Zhu</name>
        </author>
        <author>
            <name>Wei-Shi Zheng</name>
        </author>
        <author>
            <name>Xiaokang Yang</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Co-embedding of Nodes and Edges with Graph Neural Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9224195</id>
        <link href="https://ieeexplore.ieee.org/document/9224195"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graph is ubiquitous in many real world applications ranging from social network analysis to biology. How to correctly and effectively learn and extract information from graph is essential for a large number of machine learning tasks. Graph embedding is a way to transform and encode data structure in high dimensional and Non-Euclidean feature space to a low dimensional and structural space. We have...]]></summary>
        <author>
            <name>Xiaodong Jiang</name>
        </author>
        <author>
            <name>Ronghang Zhu</name>
        </author>
        <author>
            <name>Sheng Li</name>
        </author>
        <author>
            <name>Pengsheng Ji</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[First- And Third-person Video Co-analysis By Learning Spatial-temporal Joint Attention]]></title>
        <id>https://ieeexplore.ieee.org/document/9220850</id>
        <link href="https://ieeexplore.ieee.org/document/9220850"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recent years have witnessed a tremendous increasing of first-person videos captured by wearable devices. Such videos record information from different perspectives than the traditional third-person view, and thus show a wide range of potential usages. However, techniques for analyzing videos from different views can be fundamentally different, not to mention co-analyzing on both views to explore t...]]></summary>
        <author>
            <name>Huangyue Yu</name>
        </author>
        <author>
            <name>Minjie Cai</name>
        </author>
        <author>
            <name>Yunfei Liu</name>
        </author>
        <author>
            <name>Feng Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera]]></title>
        <id>https://ieeexplore.ieee.org/document/9217955</id>
        <link href="https://ieeexplore.ieee.org/document/9217955"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present a solution to egocentric 3D body pose estimation from monocular images captured from downward looking fish-eye cameras installed on the rim of a head mounted VR device. This unusual viewpoint leads to images with unique visual appearance, with severe self-occlusions and perspective distortions that result in drastic differences in resolution between lower and upper body. We propose an e...]]></summary>
        <author>
            <name>Denis Tome</name>
        </author>
        <author>
            <name>Thiemo Alldieck</name>
        </author>
        <author>
            <name>Patrick Peluse</name>
        </author>
        <author>
            <name>Gerard Pons-Moll</name>
        </author>
        <author>
            <name>Lourdes Agapito</name>
        </author>
        <author>
            <name>Hernan Badino</name>
        </author>
        <author>
            <name>Fernando De la Torre</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[EgoCom: A Multi-person Multi-modal Egocentric Communications Dataset]]></title>
        <id>https://ieeexplore.ieee.org/document/9200754</id>
        <link href="https://ieeexplore.ieee.org/document/9200754"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multi-modal datasets in artificial intelligence (AI) often capture a third-person perspective, but our embodied human intelligence evolved with sensory input from the egocentric, first-person perspective. Towards embodied AI, we introduce the Egocentric Communications (EgoCom) dataset to advance the state-of-the-art in conversational AI, natural language, audio speech analysis, computer vision, an...]]></summary>
        <author>
            <name>Curtis Northcutt</name>
        </author>
        <author>
            <name>Shengxin Zha</name>
        </author>
        <author>
            <name>Steven Lovegrove</name>
        </author>
        <author>
            <name>Richard Newcombe</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Fashion Retrieval via Graph Reasoning Networks on a Similarity Pyramid]]></title>
        <id>https://ieeexplore.ieee.org/document/9200778</id>
        <link href="https://ieeexplore.ieee.org/document/9200778"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Matching clothing images from customers and online shopping stores has rich applications in E-commerce. Existing algorithms mostly encode an image as a global feature vector and perform retrieval via global representation matching. However, discriminative local information on clothes is submerged in this global representation, resulting in sub-optimal performance. To address this issue, we propose...]]></summary>
        <author>
            <name>Yiming Gao</name>
        </author>
        <author>
            <name>Zhanghui Kuang</name>
        </author>
        <author>
            <name>Guanbin Li</name>
        </author>
        <author>
            <name>Ping Luo</name>
        </author>
        <author>
            <name>Yimin Chen</name>
        </author>
        <author>
            <name>Liang Lin</name>
        </author>
        <author>
            <name>Wayne Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MS-TCN++: Multi-Stage Temporal Convolutional Network for Action Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9186840</id>
        <link href="https://ieeexplore.ieee.org/document/9186840"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[With the success of deep learning in classifying short trimmed videos, more attention has been focused on temporally segmenting and classifying activities in long untrimmed videos. State-of-the-art approaches for action segmentation utilize several layers of temporal convolution and temporal pooling. Despite the capabilities of these approaches in capturing temporal dependencies, their predictions...]]></summary>
        <author>
            <name>Shi-Jie Li</name>
        </author>
        <author>
            <name>Yazan AbuFarha</name>
        </author>
        <author>
            <name>Yun Liu</name>
        </author>
        <author>
            <name>Ming-Ming Cheng</name>
        </author>
        <author>
            <name>Juergen Gall</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment]]></title>
        <id>https://ieeexplore.ieee.org/document/9165005</id>
        <link href="https://ieeexplore.ieee.org/document/9165005"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this paper, we propose to tackle egocentric action recognition by suppressing background distractors and enhancing action-relevant interactions. The existing approaches usually utilize two independent branches to recognize egocentric actions, i.e., a verb branch and a noun branch. However, the mechanism to suppress distracting objects and exploit local human-object correlations is missing. To t...]]></summary>
        <author>
            <name>Xiaohan Wang</name>
        </author>
        <author>
            <name>Linchao Zhu</name>
        </author>
        <author>
            <name>Yu Wu</name>
        </author>
        <author>
            <name>Yi Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[FakeCatcher: Detection of Synthetic Portrait Videos using Biological Signals]]></title>
        <id>https://ieeexplore.ieee.org/document/9141516</id>
        <link href="https://ieeexplore.ieee.org/document/9141516"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The recent proliferation of fake portrait videos poses direct threats on society, law, and privacy [1]. Believing the fake video of a politician, distributing fake pornographic content of celebrities, fabricating impersonated fake videos as evidence in courts are just a few real world consequences of deep fakes. We present a novel approach to detect synthetic content in portrait videos, as a preve...]]></summary>
        <author>
            <name>Umur Aybars Ciftci</name>
        </author>
        <author>
            <name>Ilke Demir</name>
        </author>
        <author>
            <name>Lijun Yin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multiple Trajectory Prediction of Moving Agents with Memory Augmented Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9138768</id>
        <link href="https://ieeexplore.ieee.org/document/9138768"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Pedestrians and drivers are expected to safely navigate complex urban environments along with several non cooperating agents. Autonomous vehicles will soon replicate this capability. Each agent acquires a representation of the world from an egocentric perspective and must make decisions ensuring safety for itself and others. This requires to predict motion patterns of observed agents for a far eno...]]></summary>
        <author>
            <name>Francesco Marchetti</name>
        </author>
        <author>
            <name>Federico Becattini</name>
        </author>
        <author>
            <name>Lorenzo Seidenari</name>
        </author>
        <author>
            <name>Alberto Del Bimbo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CCNet: Criss-Cross Attention for Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9133304</id>
        <link href="https://ieeexplore.ieee.org/document/9133304"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Contextual information is vital in visual understanding problems, such as semantic segmentation and object detection. We propose a Criss-Cross Network (CCNet) for obtaining full-image contextual information in a very effective and efficient way. Concretely, for each pixel, a novel criss-cross attention module harvests the contextual information of all the pixels on its criss-cross path. By taking ...]]></summary>
        <author>
            <name>Zilong Huang</name>
        </author>
        <author>
            <name>Xinggang Wang</name>
        </author>
        <author>
            <name>Yunchao Wei</name>
        </author>
        <author>
            <name>Lichao Huang</name>
        </author>
        <author>
            <name>Humphrey Shi</name>
        </author>
        <author>
            <name>Wenyu Liu</name>
        </author>
        <author>
            <name>Thomas S. Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Combinatorial Learning of Robust Deep Graph Matching: an Embedding based Approach]]></title>
        <id>https://ieeexplore.ieee.org/document/9128045</id>
        <link href="https://ieeexplore.ieee.org/document/9128045"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graph matching aims to establish node correspondence between two graphs, which has been a fundamental problem for its NP-complete nature. One practical consideration is the effective modeling of the affinity function in the presence of noise, such that the mathematically optimal matching result is also physically meaningful. This paper resorts to deep neural networks to learn the node and edge fea...]]></summary>
        <author>
            <name>Runzhong Wang</name>
        </author>
        <author>
            <name>Junchi Yan</name>
        </author>
        <author>
            <name>Xiaokang Yang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Structured Knowledge Distillation for Dense Prediction]]></title>
        <id>https://ieeexplore.ieee.org/document/9115859</id>
        <link href="https://ieeexplore.ieee.org/document/9115859"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this work, we consider transferring the structure information from large networks to compact ones for dense prediction tasks in computer vision. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we ...]]></summary>
        <author>
            <name>Yifan Liu</name>
        </author>
        <author>
            <name>Changyong Shu</name>
        </author>
        <author>
            <name>Jingdong Wang</name>
        </author>
        <author>
            <name>Chunhua Shen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Second-Order Pooling for Graph Neural Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9104936</id>
        <link href="https://ieeexplore.ieee.org/document/9104936"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graph neural networks have achieved great success in learning node representations for graph tasks such as node classification and link prediction. Graph representation learning requires graph pooling to obtain graph representations from node representations. It is challenging to develop graph pooling methods due to the variable sizes and isomorphic structures of graphs. In this work, we propose t...]]></summary>
        <author>
            <name>Zhengyang Wang</name>
        </author>
        <author>
            <name>Shuiwang Ji</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Analysis of the hands in egocentric vision: A survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9064606</id>
        <link href="https://ieeexplore.ieee.org/document/9064606"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Egocentric vision (a.k.a. first-person vision - FPV) applications have thrived over the past few years, thanks to the availability of affordable wearable cameras and large annotated datasets. The position of the wearable camera (usually mounted on the head) allows recording exactly what the camera wearers have in front of them, in particular hands and manipulated objects. This intrinsic advantage ...]]></summary>
        <author>
            <name>Andrea Bandini</name>
        </author>
        <author>
            <name>José Zariffa</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contextualized Trajectory Parsing with Spatio-Temporal Graph]]></title>
        <id>https://ieeexplore.ieee.org/document/6517196</id>
        <link href="https://ieeexplore.ieee.org/document/6517196"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This work investigates how to automatically parse object trajectories in surveillance videos, that aims to jointly solve three subproblems: i) spatial segmentation, ii) temporal tracking, and iii) object categorization. We present a novel representation spatio-temporal graph (ST-Graph), in which: i) graph nodes express the motion primitives, each representing a short sequence of small-size patches...]]></summary>
        <author>
            <name>Xiaobai Liu</name>
        </author>
        <author>
            <name>Liang Lin</name>
        </author>
        <author>
            <name>Hai Jin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A CNN-based face detector with a simple feature map and a coarse-to-fine classifier - Withdrawn]]></title>
        <id>https://ieeexplore.ieee.org/document/4378386</id>
        <link href="https://ieeexplore.ieee.org/document/4378386"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Withdrawn.]]></summary>
        <author>
            <name>Ying-Nong Chen</name>
        </author>
        <author>
            <name>Chin-Chuan Han</name>
        </author>
        <author>
            <name>Cheng-Tzu Wang</name>
        </author>
        <author>
            <name>Bor-Shenn Jeng</name>
        </author>
        <author>
            <name>Kuo-Chin Fan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Self-Supervised Teacher-Student Network Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9944861</id>
        <link href="https://ieeexplore.ieee.org/document/9944861"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Lifelong learning (LLL) represents the ability of an artificial intelligence system to learn successively a sequence of different databases. In this paper we introduce the Dynamic Self-Supervised Teacher-Student Network (D-TS), representing a more general LLL framework, where the Teacher is implemented as a dynamically expanding mixture model which automatically increases its capacity to deal with...]]></summary>
        <author>
            <name>Fei Ye</name>
        </author>
        <author>
            <name>Adrian G. Bors</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Drinking From a Firehose: Continual Learning With Web-Scale Natural Language]]></title>
        <id>https://ieeexplore.ieee.org/document/9933017</id>
        <link href="https://ieeexplore.ieee.org/document/9933017"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Continual learning systems will interact with humans, with each other, and with the physical world through time – and continue to learn and adapt as they do. An important open problem for continual learning is a large-scale benchmark which enables realistic evaluation of algorithms. In this paper, we study a natural setting for continual learning on a massive scale. We introduce the problem of per...]]></summary>
        <author>
            <name>Hexiang Hu</name>
        </author>
        <author>
            <name>Ozan Sener</name>
        </author>
        <author>
            <name>Fei Sha</name>
        </author>
        <author>
            <name>Vladlen Koltun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Cycle Registration in Persistent Homology With Applications in Topological Bootstrap]]></title>
        <id>https://ieeexplore.ieee.org/document/9931659</id>
        <link href="https://ieeexplore.ieee.org/document/9931659"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose a novel approach for comparing the persistent homology representations of two spaces (or filtrations). Commonly used methods are based on numerical summaries such as persistence diagrams and persistence landscapes, along with suitable metrics (e.g., Wasserstein). These summaries are useful for computational purposes, but they are merely a marginal of the actual topological information t...]]></summary>
        <author>
            <name>Yohai Reani</name>
        </author>
        <author>
            <name>Omer Bobrowski</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[DeepEMD: Differentiable Earth Mover's Distance for Few-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9930675</id>
        <link href="https://ieeexplore.ieee.org/document/9930675"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this work, we develop methods for few-shot image classification from a new perspective of optimal matching between image regions. We employ the Earth Mover&#39;s Distance (EMD) as a metric to compute a structural distance between dense image representations to determine image relevance. The EMD generates the optimal matching flows between structural elements that have the minimum matching cost, whi...]]></summary>
        <author>
            <name>Chi Zhang</name>
        </author>
        <author>
            <name>Yujun Cai</name>
        </author>
        <author>
            <name>Guosheng Lin</name>
        </author>
        <author>
            <name>Chunhua Shen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implicit Annealing in Kernel Spaces: A Strongly Consistent Clustering Approach]]></title>
        <id>https://ieeexplore.ieee.org/document/9928792</id>
        <link href="https://ieeexplore.ieee.org/document/9928792"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Kernel $k$k-means clustering is a powerful tool for unsupervised learning of non-linearly separable data. Its merits are thoroughly validated on a suite of simulated datasets and real data benchmarks that feature nonlinear and multi-view separation. Since the earliest attempts, researchers have noted that such algorithms often become trapped by local minima arising from the non-convexity of the un...]]></summary>
        <author>
            <name>Debolina Paul</name>
        </author>
        <author>
            <name>Saptarshi Chakraborty</name>
        </author>
        <author>
            <name>Swagatam Das</name>
        </author>
        <author>
            <name>Jason Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Snowflake Point Deconvolution for Point Cloud Completion and Generation With Skip-Transformer]]></title>
        <id>https://ieeexplore.ieee.org/document/9928787</id>
        <link href="https://ieeexplore.ieee.org/document/9928787"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Most existing point cloud completion methods suffer from the discrete nature of point clouds and the unstructured prediction of points in local regions, which makes it difficult to reveal fine local geometric details. To resolve this issue, we propose SnowflakeNet with snowflake point deconvolution (SPD) to generate complete point clouds. SPD models the generation of point clouds as the snowflake-...]]></summary>
        <author>
            <name>Peng Xiang</name>
        </author>
        <author>
            <name>Xin Wen</name>
        </author>
        <author>
            <name>Yu-Shen Liu</name>
        </author>
        <author>
            <name>Yan-Pei Cao</name>
        </author>
        <author>
            <name>Pengfei Wan</name>
        </author>
        <author>
            <name>Wen Zheng</name>
        </author>
        <author>
            <name>Zhizhong Han</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Convolution for 3D Point Cloud Instance Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9928362</id>
        <link href="https://ieeexplore.ieee.org/document/9928362"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this paper, we come up with a simple yet effective approach for instance segmentation on 3D point cloud with strong robustness. Previous top-performing methods for this task adopt a bottom-up strategy, which often involves various inefficient operations or complex pipelines, such as grouping over-segmented components, introducing heuristic post-processing steps, and designing complex loss funct...]]></summary>
        <author>
            <name>Tong He</name>
        </author>
        <author>
            <name>Chunhua Shen</name>
        </author>
        <author>
            <name>Anton van den Hengel</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ST3D++: Denoised Self-Training for Unsupervised Domain Adaptation on 3D Object Detection]]></title>
        <id>https://ieeexplore.ieee.org/document/9927350</id>
        <link href="https://ieeexplore.ieee.org/document/9927350"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this paper, we present a self-training method, named ST3D++, with a holistic pseudo label denoising pipeline for unsupervised domain adaptation on 3D object detection. ST3D++ aims at reducing noise in pseudo label generation as well as alleviating the negative impacts of noisy pseudo labels on model training. First, ST3D++ pre-trains the 3D object detector on the labeled source domain with rand...]]></summary>
        <author>
            <name>Jihan Yang</name>
        </author>
        <author>
            <name>Shaoshuai Shi</name>
        </author>
        <author>
            <name>Zhe Wang</name>
        </author>
        <author>
            <name>Hongsheng Li</name>
        </author>
        <author>
            <name>Xiaojuan Qi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Rolling Shutter Inversion: Bring Rolling Shutter Images to High Framerate Global Shutter Video]]></title>
        <id>https://ieeexplore.ieee.org/document/9926197</id>
        <link href="https://ieeexplore.ieee.org/document/9926197"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[A single rolling-shutter (RS) image may be viewed as a row-wise combination of a sequence of global-shutter (GS) images captured by a (virtual) moving GS camera within the exposure duration. Although rolling-shutter cameras are widely used, the RS effect causes obvious image distortion especially in the presence of fast camera motion, hindering downstream computer vision tasks. In this paper, we p...]]></summary>
        <author>
            <name>Bin Fan</name>
        </author>
        <author>
            <name>Yuchao Dai</name>
        </author>
        <author>
            <name>Hongdong Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gaussian RBF Centered Kernel Alignment (CKA) in the Large-Bandwidth Limit]]></title>
        <id>https://ieeexplore.ieee.org/document/9926163</id>
        <link href="https://ieeexplore.ieee.org/document/9926163"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Centered kernel alignment (CKA), also known as centered kernel-target alignment, is useful as a similarity measure between kernels and as a kernel-based similarity measure between feature representations. We prove that CKA based on a Gaussian RBF kernel converges to linear CKA in the large-bandwidth limit. The result relies on mean-centering of the feature maps and on a Hilbert-Schmidt Independenc...]]></summary>
        <author>
            <name>Sergio A. Alvarez</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spherical Image Generation From a Few Normal-Field-of-View Images by Considering Scene Symmetry]]></title>
        <id>https://ieeexplore.ieee.org/document/9925617</id>
        <link href="https://ieeexplore.ieee.org/document/9925617"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Spherical images taken in all directions (360 degrees by 180 degrees) can represent an entire space including the subject, providing free direction viewing and an immersive experience to viewers. It is convenient and expands the usage scenarios to generate a spherical image from a few normal-field-of-view (NFOV) images, which are partial observations. The primary challenge is generating a plausibl...]]></summary>
        <author>
            <name>Takayuki Hara</name>
        </author>
        <author>
            <name>Yusuke Mukuta</name>
        </author>
        <author>
            <name>Tatsuya Harada</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Analytical Tensor Voting in ND Space and its Properties]]></title>
        <id>https://ieeexplore.ieee.org/document/9925111</id>
        <link href="https://ieeexplore.ieee.org/document/9925111"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This article aims to propose a novel Analytical Tensor Voting (ATV) mechanism, which enables robust perceptual grouping and salient information extraction for noisy $N-$N-dimensional (ND) data. Firstly, the approximation of the decaying function is investigated and adopted based on the idea of penalizing the $1-$1-tensor votes by distance and curvature, respectively, followed by the derivation of ...]]></summary>
        <author>
            <name>Hongbin Lin</name>
        </author>
        <author>
            <name>Dan Guo</name>
        </author>
        <author>
            <name>Jianing Wei</name>
        </author>
        <author>
            <name>Boran Guan</name>
        </author>
        <author>
            <name>Zeyu Chen</name>
        </author>
        <author>
            <name>Xiuping Peng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Continuous-Time Fitted Value Iteration for Robust Policies]]></title>
        <id>https://ieeexplore.ieee.org/document/9925102</id>
        <link href="https://ieeexplore.ieee.org/document/9925102"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Solving the Hamilton-Jacobi-Bellman equation is important in many domains including control, robotics and economics. Especially for continuous control, solving this differential equation and its extension the Hamilton-Jacobi-Isaacs equation, is important as it yields the optimal policy that achieves the maximum reward on a give task. In the case of the Hamilton-Jacobi-Isaacs equation, which includ...]]></summary>
        <author>
            <name>Michael Lutter</name>
        </author>
        <author>
            <name>Boris Belousov</name>
        </author>
        <author>
            <name>Shie Mannor</name>
        </author>
        <author>
            <name>Dieter Fox</name>
        </author>
        <author>
            <name>Animesh Garg</name>
        </author>
        <author>
            <name>Jan Peters</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Learning for Face Anti-Spoofing: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9925105</id>
        <link href="https://ieeexplore.ieee.org/document/9925105"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Face anti-spoofing (FAS) has lately attracted increasing attention due to its vital role in securing face recognition systems from presentation attacks (PAs). As more and more realistic PAs with novel types spring up, early-stage FAS methods based on handcrafted features become unreliable due to their limited representation capacity. With the emergence of large-scale academic datasets in the recen...]]></summary>
        <author>
            <name>Zitong Yu</name>
        </author>
        <author>
            <name>Yunxiao Qin</name>
        </author>
        <author>
            <name>Xiaobai Li</name>
        </author>
        <author>
            <name>Chenxu Zhao</name>
        </author>
        <author>
            <name>Zhen Lei</name>
        </author>
        <author>
            <name>Guoying Zhao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learn From Unpaired Data for Image Restoration: A Variational Bayes Approach]]></title>
        <id>https://ieeexplore.ieee.org/document/9924527</id>
        <link href="https://ieeexplore.ieee.org/document/9924527"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Collecting paired training data is difficult in practice, but the unpaired samples broadly exist. Current approaches aim at generating synthesized training data from unpaired samples by exploring the relationship between the corrupted and clean data. This work proposes LUD-VAE, a deep generative method to learn the joint probability density function from data sampled from marginal distributions. O...]]></summary>
        <author>
            <name>Dihan Zheng</name>
        </author>
        <author>
            <name>Xiaowen Zhang</name>
        </author>
        <author>
            <name>Kaisheng Ma</name>
        </author>
        <author>
            <name>Chenglong Bao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Optimize on Riemannian Manifolds]]></title>
        <id>https://ieeexplore.ieee.org/document/9925104</id>
        <link href="https://ieeexplore.ieee.org/document/9925104"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Many learning tasks are modeled as optimization problems with nonlinear constraints, such as principal component analysis and fitting a Gaussian mixture model. A popular way to solve such problems is resorting to Riemannian optimization algorithms, which yet heavily rely on both human involvement and expert knowledge about Riemannian manifolds. In this paper, we propose a Riemannian meta-optimizat...]]></summary>
        <author>
            <name>Zhi Gao</name>
        </author>
        <author>
            <name>Yuwei Wu</name>
        </author>
        <author>
            <name>Xiaomeng Fan</name>
        </author>
        <author>
            <name>Mehrtash Harandi</name>
        </author>
        <author>
            <name>Yunde Jia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RobustFusion: Robust Volumetric Performance Reconstruction Under Human-Object Interactions From Monocular RGBD Stream]]></title>
        <id>https://ieeexplore.ieee.org/document/9925090</id>
        <link href="https://ieeexplore.ieee.org/document/9925090"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[High-quality 4D reconstruction of human performance with complex interactions to various objects is essential in real-world scenarios, which enables numerous immersive VR/AR applications. However, recent advances still fail to provide reliable performance reconstruction, suffering from challenging interaction patterns and severe occlusions, especially for the monocular setting. To fill this gap, i...]]></summary>
        <author>
            <name>Zhuo Su</name>
        </author>
        <author>
            <name>Lan Xu</name>
        </author>
        <author>
            <name>Dawei Zhong</name>
        </author>
        <author>
            <name>Zhong Li</name>
        </author>
        <author>
            <name>Fan Deng</name>
        </author>
        <author>
            <name>Shuxue Quan</name>
        </author>
        <author>
            <name>Lu Fang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[The Proxy Step-Size Technique for Regularized Optimization on the Sphere Manifold]]></title>
        <id>https://ieeexplore.ieee.org/document/9925098</id>
        <link href="https://ieeexplore.ieee.org/document/9925098"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We give an effective solution to the regularized optimization problem $g (\boldsymbol{x}) + h (\boldsymbol{x})$g(x)+h(x), where $\boldsymbol{x}$x is constrained on the unit sphere $\Vert \boldsymbol{x} \Vert _{2} = 1$∥x∥2=1. Here $g (\cdot)$g(·) is a smooth cost with Lipschitz continuous gradient within the unit ball $\lbrace \boldsymbol{x} : \Vert \boldsymbol{x} \Vert _{2} \leq 1 \rbrace${x:∥x∥2≤...]]></summary>
        <author>
            <name>Fang Bai</name>
        </author>
        <author>
            <name>Adrien Bartoli</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Systematic Survey on Deep Generative Models for Graph Generation]]></title>
        <id>https://ieeexplore.ieee.org/document/9920219</id>
        <link href="https://ieeexplore.ieee.org/document/9920219"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to their wide range of applications, generative models for graphs, which have a rich history, howev...]]></summary>
        <author>
            <name>Xiaojie Guo</name>
        </author>
        <author>
            <name>Liang Zhao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Dual Memory Dictionaries for Blind Face Restoration]]></title>
        <id>https://ieeexplore.ieee.org/document/9921338</id>
        <link href="https://ieeexplore.ieee.org/document/9921338"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Blind face restoration is a challenging task due to the unknown, unsynthesizable and complex degradation, yet is valuable in many practical applications. To improve the performance of blind face restoration, recent works mainly treat the two aspects, i.e., generic and specific restoration, separately. In particular, generic restoration attempts to restore the results through general facial structu...]]></summary>
        <author>
            <name>Xiaoming Li</name>
        </author>
        <author>
            <name>Shiguang Zhang</name>
        </author>
        <author>
            <name>Shangchen Zhou</name>
        </author>
        <author>
            <name>Lei Zhang</name>
        </author>
        <author>
            <name>Wangmeng Zuo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Minimizing Estimated Risks on Unlabeled Data: A New Formulation for Semi-Supervised Medical Image Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9921323</id>
        <link href="https://ieeexplore.ieee.org/document/9921323"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Supervised segmentation can be costly, particularly in applications of biomedical image analysis where large scale manual annotations from experts are generally too expensive to be available. Semi-supervised segmentation, able to learn from both the labeled and unlabeled images, could be an efficient and effective alternative for such scenarios. In this work, we propose a new formulation based on ...]]></summary>
        <author>
            <name>Fuping Wu</name>
        </author>
        <author>
            <name>Xiahai Zhuang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Temporal Representation Learning on Monocular Videos for 3D Human Pose Estimation]]></title>
        <id>https://ieeexplore.ieee.org/document/9921314</id>
        <link href="https://ieeexplore.ieee.org/document/9921314"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this article we propose an unsupervised feature extraction method to capture temporal information on monocular videos, where we detect and encode subject of interest in each frame and leverage contrastive self-supervised (CSS) learning to extract rich latent vectors. Instead of simply treating the latent features of nearby frames as positive pairs and those of temporally-distant ones as negativ...]]></summary>
        <author>
            <name>Sina Honari</name>
        </author>
        <author>
            <name>Victor Constantin</name>
        </author>
        <author>
            <name>Helge Rhodin</name>
        </author>
        <author>
            <name>Mathieu Salzmann</name>
        </author>
        <author>
            <name>Pascal Fua</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Accurate and Robust Domain Adaptation Under Multiple Noisy Environments]]></title>
        <id>https://ieeexplore.ieee.org/document/9921307</id>
        <link href="https://ieeexplore.ieee.org/document/9921307"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In many non-stationary environments, machine learning algorithms usually confront the distribution shift scenarios. Previous domain adaptation methods have achieved great success. However, they would lose algorithm robustness in multiple noisy environments where the examples of source domain become corrupted by label noise, feature noise, or open-set noise. In this paper, we report our attempt tow...]]></summary>
        <author>
            <name>Zhongyi Han</name>
        </author>
        <author>
            <name>Xian-Jin Gui</name>
        </author>
        <author>
            <name>Haoliang Sun</name>
        </author>
        <author>
            <name>Yilong Yin</name>
        </author>
        <author>
            <name>Shuo Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[ASH: A Modern Framework for Parallel Spatial Hashing in 3D Perception]]></title>
        <id>https://ieeexplore.ieee.org/document/9918017</id>
        <link href="https://ieeexplore.ieee.org/document/9918017"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We present ASH, a modern and high-performance framework for parallel spatial hashing on GPU. Compared to existing GPU hash map implementations, ASH achieves higher performance, supports richer functionality, and requires fewer lines of code (LoC) when used for implementing spatially varying operations from volumetric geometry reconstruction to differentiable appearance reconstruction. Unlike exist...]]></summary>
        <author>
            <name>Wei Dong</name>
        </author>
        <author>
            <name>Yixing Lao</name>
        </author>
        <author>
            <name>Michael Kaess</name>
        </author>
        <author>
            <name>Vladlen Koltun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Geodesic-Based Bayesian Coherent Point Drift]]></title>
        <id>https://ieeexplore.ieee.org/document/9918058</id>
        <link href="https://ieeexplore.ieee.org/document/9918058"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Coherent point drift is a well-known algorithm for non-rigid registration, i.e., a procedure for deforming a shape to match another shape. Despite its prevalence, the algorithm has a major drawback that remains unsolved: It unnaturally deforms the different parts of a shape, e.g., human legs, when they are neighboring each other. The inappropriate deformations originate from a proximity-based defo...]]></summary>
        <author>
            <name>Osamu Hirose</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Losses for Learning Value Functions]]></title>
        <id>https://ieeexplore.ieee.org/document/9918637</id>
        <link href="https://ieeexplore.ieee.org/document/9918637"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Most value function learning algorithms in reinforcement learning are based on the mean squared (projected) Bellman error. However, squared errors are known to be sensitive to outliers, both skewing the solution of the objective and resulting in high-magnitude and high-variance gradients. To control these high-magnitude updates, typical strategies in RL involve clipping gradients, clipping rewards...]]></summary>
        <author>
            <name>Andrew Patterson</name>
        </author>
        <author>
            <name>Victor Liao</name>
        </author>
        <author>
            <name>Martha White</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MPED: Quantifying Point Cloud Distortion Based on Multiscale Potential Energy Discrepancy]]></title>
        <id>https://ieeexplore.ieee.org/document/9917335</id>
        <link href="https://ieeexplore.ieee.org/document/9917335"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this article, we propose a new distortion quantification method for point clouds, the multiscale potential energy discrepancy (MPED). Currently, there is a lack of effective distortion quantification for a variety of point cloud perception tasks. Specifically, in human vision tasks, a distortion quantification method is used to predict human subjective scores and optimize the selection of human...]]></summary>
        <author>
            <name>Qi Yang</name>
        </author>
        <author>
            <name>Yujie Zhang</name>
        </author>
        <author>
            <name>Siheng Chen</name>
        </author>
        <author>
            <name>Yiling Xu</name>
        </author>
        <author>
            <name>Jun Sun</name>
        </author>
        <author>
            <name>Zhan Ma</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An Efficient Fisher Matrix Approximation Method for Large-Scale Neural Network Optimization]]></title>
        <id>https://ieeexplore.ieee.org/document/9916144</id>
        <link href="https://ieeexplore.ieee.org/document/9916144"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Although the shapes of the parameters are not crucial for designing first-order optimization methods in large scale empirical risk minimization problems, they have important impact on the size of the matrix to be inverted when developing second-order type methods. In this article, we propose an efficient and novel second-order method based on the parameters in the real matrix space $\mathbb {R}^{m...]]></summary>
        <author>
            <name>Minghan Yang</name>
        </author>
        <author>
            <name>Dong Xu</name>
        </author>
        <author>
            <name>Qiwen Cui</name>
        </author>
        <author>
            <name>Zaiwen Wen</name>
        </author>
        <author>
            <name>Pengxiang Xu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Defensive Few-Shot Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9916072</id>
        <link href="https://ieeexplore.ieee.org/document/9916072"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This article investigates a new challenging problem called defensive few-shot learning in order to learn a robust few-shot model against adversarial attacks. Simply applying the existing adversarial defense methods to few-shot learning cannot effectively solve this problem. This is because the commonly assumed sample-level distribution consistency between the training and test sets can no longer b...]]></summary>
        <author>
            <name>Wenbin Li</name>
        </author>
        <author>
            <name>Lei Wang</name>
        </author>
        <author>
            <name>Xingxing Zhang</name>
        </author>
        <author>
            <name>Lei Qi</name>
        </author>
        <author>
            <name>Jing Huo</name>
        </author>
        <author>
            <name>Yang Gao</name>
        </author>
        <author>
            <name>Jiebo Luo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SMMP: A Stable-Membership-Based Auto-Tuning Multi-Peak Clustering Algorithm]]></title>
        <id>https://ieeexplore.ieee.org/document/9916156</id>
        <link href="https://ieeexplore.ieee.org/document/9916156"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Since most existing single-prototype clustering algorithms are unsuitable for complex-shaped clusters, many multi-prototype clustering algorithms have been proposed. Nevertheless, the automatic estimation of the number of clusters and the detection of complex shapes are still challenging, and to solve such problems usually relies on user-specified parameters and may be prohibitively time-consuming...]]></summary>
        <author>
            <name>Junyi Guan</name>
        </author>
        <author>
            <name>Sheng Li</name>
        </author>
        <author>
            <name>Xiongxiong He</name>
        </author>
        <author>
            <name>Jinhui Zhu</name>
        </author>
        <author>
            <name>Jiajia Chen</name>
        </author>
        <author>
            <name>Peng Si</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Structured Sparsity Optimization With Non-Convex Surrogates of $\ell _{2,0}$ℓ2,0-Norm: A Unified Algorithmic Framework]]></title>
        <id>https://ieeexplore.ieee.org/document/9916142</id>
        <link href="https://ieeexplore.ieee.org/document/9916142"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this article, we present a general optimization framework that leverages structured sparsity to achieve superior recovery results. The traditional method for solving the structured sparse objectives based on $\ell _{2,0}$ℓ2,0-norm is to use the $\ell _{2,1}$ℓ2,1-norm as a convex surrogate. However, such an approximation often yields a large performance gap. To tackle this issue, we first provid...]]></summary>
        <author>
            <name>Xiaoqin Zhang</name>
        </author>
        <author>
            <name>Jingjing Zheng</name>
        </author>
        <author>
            <name>Di Wang</name>
        </author>
        <author>
            <name>Guiying Tang</name>
        </author>
        <author>
            <name>Zhengyuan Zhou</name>
        </author>
        <author>
            <name>Zhouchen Lin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Class-Incremental Learning: Survey and Performance Evaluation on Image Classification]]></title>
        <id>https://ieeexplore.ieee.org/document/9915459</id>
        <link href="https://ieeexplore.ieee.org/document/9915459"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[For future learning systems, incremental learning is desirable because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new data; reduced memory usage by preventing or limiting the amount of data required to be stored – also important when privacy limitations are imposed; and learning that more closely resembles human learning. The main chal...]]></summary>
        <author>
            <name>Marc Masana</name>
        </author>
        <author>
            <name>Xialei Liu</name>
        </author>
        <author>
            <name>Bartłomiej Twardowski</name>
        </author>
        <author>
            <name>Mikel Menta</name>
        </author>
        <author>
            <name>Andrew D. Bagdanov</name>
        </author>
        <author>
            <name>Joost van de Weijer</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[HydraMarker: Efficient, Flexible, and Multifold Marker Field Generation]]></title>
        <id>https://ieeexplore.ieee.org/document/9913723</id>
        <link href="https://ieeexplore.ieee.org/document/9913723"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[An n-order marker field is a special binary matrix whose n×n subregions are all distinct from each other in four orientations. It is commonly used to guide the composing process of position-sensing markers, which can be detected and identified in a camera image with very limited scope or severe visibility problems. Despite the advantages, position-sensing markers are rare and overlooked because ge...]]></summary>
        <author>
            <name>Mingzhu Zhu</name>
        </author>
        <author>
            <name>Bingwei He</name>
        </author>
        <author>
            <name>Junzhi Yu</name>
        </author>
        <author>
            <name>Fusong Yuan</name>
        </author>
        <author>
            <name>Jiantao Liu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning With Nested Scene Modeling and Cooperative Architecture Search for Low-Light Vision]]></title>
        <id>https://ieeexplore.ieee.org/document/9914672</id>
        <link href="https://ieeexplore.ieee.org/document/9914672"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Images captured from low-light scenes often suffer from severe degradations, including low visibility, color casts, intensive noises, etc. These factors not only degrade image qualities, but also affect the performance of downstream Low-Light Vision (LLV) applications. A variety of deep networks have been proposed to enhance the visual quality of low-light images. However, they mostly rely on sign...]]></summary>
        <author>
            <name>Risheng Liu</name>
        </author>
        <author>
            <name>Long Ma</name>
        </author>
        <author>
            <name>Tengyu Ma</name>
        </author>
        <author>
            <name>Xin Fan</name>
        </author>
        <author>
            <name>Zhongxuan Luo</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Multi-Channel Attention Selection GANs for Guided Image-to-Image Translation]]></title>
        <id>https://ieeexplore.ieee.org/document/9913676</id>
        <link href="https://ieeexplore.ieee.org/document/9913676"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[We propose a novel model named Multi-Channel Attention Selection Generative Adversarial Network (SelectionGAN) for guided image-to-image translation, where we translate an input image into another while respecting an external semantic guidance. The proposed SelectionGAN explicitly utilizes the semantic guidance information and consists of two stages. In the first stage, the input image and the con...]]></summary>
        <author>
            <name>Hao Tang</name>
        </author>
        <author>
            <name>Philip H.S. Torr</name>
        </author>
        <author>
            <name>Nicu Sebe</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[SiMaN: Sign-to-Magnitude Network Binarization]]></title>
        <id>https://ieeexplore.ieee.org/document/9913704</id>
        <link href="https://ieeexplore.ieee.org/document/9913704"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Binary neural networks (BNNs) have attracted broad research interest due to their efficient storage and computational ability. Nevertheless, a significant challenge of BNNs lies in handling discrete constraints while ensuring bit entropy maximization, which typically makes their weight optimization very difficult. Existing methods relax the learning using the sign function, which simply encodes po...]]></summary>
        <author>
            <name>Mingbao Lin</name>
        </author>
        <author>
            <name>Rongrong Ji</name>
        </author>
        <author>
            <name>Zihan Xu</name>
        </author>
        <author>
            <name>Baochang Zhang</name>
        </author>
        <author>
            <name>Fei Chao</name>
        </author>
        <author>
            <name>Chia-Wen Lin</name>
        </author>
        <author>
            <name>Ling Shao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Theoretical Analysis of Null Foley-Sammon Transform and its Implications]]></title>
        <id>https://ieeexplore.ieee.org/document/9914807</id>
        <link href="https://ieeexplore.ieee.org/document/9914807"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Null Foley-Sammon Transform (NFST) has received increasing attention in the machine learning and pattern recognition literature. NFST finds a discriminative nullspace where all samples of the same class get mapped into a single point. It has a closed form solution and is free of parameters to tune. NFST has been leveraged in many areas including novelty detection, person or vehicle re-identificati...]]></summary>
        <author>
            <name>T M Feroz Ali</name>
        </author>
        <author>
            <name>Subhasis Chaudhuri</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Visual Object Tracking With Discriminative Filters and Siamese Networks: A Survey and Outlook]]></title>
        <id>https://ieeexplore.ieee.org/document/9913708</id>
        <link href="https://ieeexplore.ieee.org/document/9913708"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Accurate and robust visual object tracking is one of the most challenging and fundamental computer vision problems. It entails estimating the trajectory of the target in an image sequence, given only its initial location, and segmentation, or its rough approximation in the form of a bounding box. Discriminative Correlation Filters (DCFs) and deep Siamese Networks (SNs) have emerged as dominating t...]]></summary>
        <author>
            <name>Sajid Javed</name>
        </author>
        <author>
            <name>Martin Danelljan</name>
        </author>
        <author>
            <name>Fahad Shahbaz Khan</name>
        </author>
        <author>
            <name>Muhammad Haris Khan</name>
        </author>
        <author>
            <name>Michael Felsberg</name>
        </author>
        <author>
            <name>Jiri Matas</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks]]></title>
        <id>https://ieeexplore.ieee.org/document/9912362</id>
        <link href="https://ieeexplore.ieee.org/document/9912362"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Attention mechanisms, especially self-attention, have played an increasingly important role in deep feature representation for visual tasks. Self-attention updates the feature at each position by computing a weighted sum of features using pair-wise affinities across all positions to capture the long-range dependency within a single sample. However, self-attention has quadratic complexity and ignor...]]></summary>
        <author>
            <name>Meng-Hao Guo</name>
        </author>
        <author>
            <name>Zheng-Ning Liu</name>
        </author>
        <author>
            <name>Tai-Jiang Mu</name>
        </author>
        <author>
            <name>Shi-Min Hu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Towards Accurate Reconstruction of 3D Scene Shape From A Single Monocular Image]]></title>
        <id>https://ieeexplore.ieee.org/document/9912367</id>
        <link href="https://ieeexplore.ieee.org/document/9912367"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Despite significant progress made in the past few years, challenges remain for depth estimation using a single monocular image. First, it is nontrivial to train a metric-depth prediction model that can generalize well to diverse scenes mainly due to limited training data. Thus, researchers have built large-scale relative depth datasets that are much easier to collect. However, existing relative de...]]></summary>
        <author>
            <name>Wei Yin</name>
        </author>
        <author>
            <name>Jianming Zhang</name>
        </author>
        <author>
            <name>Oliver Wang</name>
        </author>
        <author>
            <name>Simon Niklaus</name>
        </author>
        <author>
            <name>Simon Chen</name>
        </author>
        <author>
            <name>Yifan Liu</name>
        </author>
        <author>
            <name>Chunhua Shen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Video Instance Segmentation via Temporal Pyramid Routing]]></title>
        <id>https://ieeexplore.ieee.org/document/9910001</id>
        <link href="https://ieeexplore.ieee.org/document/9910001"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Video Instance Segmentation (VIS) is a new and inherently multi-task problem, which aims to detect, segment, and track each instance in a video sequence. Existing approaches are mainly based on single-frame features or single-scale features of multiple frames, where either temporal information or multi-scale information is ignored. To incorporate both temporal and scale information, we propose a T...]]></summary>
        <author>
            <name>Xiangtai Li</name>
        </author>
        <author>
            <name>Hao He</name>
        </author>
        <author>
            <name>Yibo Yang</name>
        </author>
        <author>
            <name>Henghui Ding</name>
        </author>
        <author>
            <name>Kuiyuan Yang</name>
        </author>
        <author>
            <name>Guangliang Cheng</name>
        </author>
        <author>
            <name>Yunhai Tong</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Channel Exchanging Networks for Multimodal and Multitask Dense Image Prediction]]></title>
        <id>https://ieeexplore.ieee.org/document/9906429</id>
        <link href="https://ieeexplore.ieee.org/document/9906429"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multimodal fusion and multitask learning are two vital topics in machine learning. Despite the fruitful progress, existing methods for both problems are still brittle to the same challenge—it remains dilemmatic to integrate the common information across modalities (resp. tasks) meanwhile preserving the specific patterns of each modality (resp. task). Besides, while they are actually closely relate...]]></summary>
        <author>
            <name>Yikai Wang</name>
        </author>
        <author>
            <name>Fuchun Sun</name>
        </author>
        <author>
            <name>Wenbing Huang</name>
        </author>
        <author>
            <name>Fengxiang He</name>
        </author>
        <author>
            <name>Dacheng Tao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Small-Object Sensitive Segmentation Using Across Feature Map Attention]]></title>
        <id>https://ieeexplore.ieee.org/document/9906428</id>
        <link href="https://ieeexplore.ieee.org/document/9906428"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Semantic segmentation is an important step in understanding the scene for many practical applications such as autonomous driving. Although Deep Convolutional Neural Networks-based methods have significantly improved segmentation accuracy, small/thin objects remain challenging to segment due to convolutional and pooling operations that result in information loss, especially for small objects. This ...]]></summary>
        <author>
            <name>Shengtian Sang</name>
        </author>
        <author>
            <name>Yuyin Zhou</name>
        </author>
        <author>
            <name>Md Tauhidul Islam</name>
        </author>
        <author>
            <name>Lei Xing</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[CRIC: A VQA Dataset for Compositional Reasoning on Vision and Commonsense]]></title>
        <id>https://ieeexplore.ieee.org/document/9905976</id>
        <link href="https://ieeexplore.ieee.org/document/9905976"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Alternatively inferring on the visual facts and commonsense is fundamental for an advanced visual question answering (VQA) system. This ability requires models to go beyond the literal understanding of commonsense. The system should not just treat objects as the entrance to query background knowledge, but fully ground commonsense to the visual world and imagine the possible relationships between o...]]></summary>
        <author>
            <name>Difei Gao</name>
        </author>
        <author>
            <name>Ruiping Wang</name>
        </author>
        <author>
            <name>Shiguang Shan</name>
        </author>
        <author>
            <name>Xilin Chen</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semantic Probability Distribution Modeling for Diverse Semantic Image Synthesis]]></title>
        <id>https://ieeexplore.ieee.org/document/9904454</id>
        <link href="https://ieeexplore.ieee.org/document/9904454"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Semantic image synthesis, translating semantic layouts to photo-realistic images, is a one-to-many mapping problem. Though impressive progress has been recently made, diverse semantic synthesis that can efficiently produce semantic-level or even instance-level multimodal results, still remains a challenge. In this article, we propose a novel diverse semantic image synthesis framework from the pers...]]></summary>
        <author>
            <name>Zhentao Tan</name>
        </author>
        <author>
            <name>Qi Chu</name>
        </author>
        <author>
            <name>Menglei Chai</name>
        </author>
        <author>
            <name>Dongdong Chen</name>
        </author>
        <author>
            <name>Jing Liao</name>
        </author>
        <author>
            <name>Qiankun Liu</name>
        </author>
        <author>
            <name>Bin Liu</name>
        </author>
        <author>
            <name>Gang Hua</name>
        </author>
        <author>
            <name>Nenghai Yu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Depth Restoration in Under-Display Time-of-Flight Imaging]]></title>
        <id>https://ieeexplore.ieee.org/document/9903562</id>
        <link href="https://ieeexplore.ieee.org/document/9903562"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Under-display imaging has recently received considerable attention in both academia and industry. As a variation of this technique, under-display ToF (UD-ToF) cameras enable depth sensing for full-screen devices. However, it also brings problems of image blurring, signal-to-noise ratio and ranging accuracy reduction. To address these issues, we propose a cascaded deep network to improve the qualit...]]></summary>
        <author>
            <name>Xin Qiao</name>
        </author>
        <author>
            <name>Chenyang Ge</name>
        </author>
        <author>
            <name>Pengchao Deng</name>
        </author>
        <author>
            <name>Hao Wei</name>
        </author>
        <author>
            <name>Matteo Poggi</name>
        </author>
        <author>
            <name>Stefano Mattoccia</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Generating Hypergraph-Based High-Order Representations of Whole-Slide Histopathological Images for Survival Prediction]]></title>
        <id>https://ieeexplore.ieee.org/document/9903546</id>
        <link href="https://ieeexplore.ieee.org/document/9903546"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Patient survival prediction based on gigapixel whole-slide histopathological images (WSIs) has become increasingly prevalent in recent years. A key challenge of this task is achieving an informative survival-specific global representation from those WSIs with highly complicated data correlation. This article proposes a multi-hypergraph based learning framework, called “HGSurvNet,” to tackle this c...]]></summary>
        <author>
            <name>Donglin Di</name>
        </author>
        <author>
            <name>Changqing Zou</name>
        </author>
        <author>
            <name>Yifan Feng</name>
        </author>
        <author>
            <name>Haiyan Zhou</name>
        </author>
        <author>
            <name>Rongrong Ji</name>
        </author>
        <author>
            <name>Qionghai Dai</name>
        </author>
        <author>
            <name>Yue Gao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Graph Neural Networks in Network Neuroscience]]></title>
        <id>https://ieeexplore.ieee.org/document/9903566</id>
        <link href="https://ieeexplore.ieee.org/document/9903566"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Noninvasive medical neuroimaging has yielded many discoveries about the brain connectivity. Several substantial techniques mapping morphological, structural and functional brain connectivities were developed to create a comprehensive road map of neuronal activities in the human brain –namely brain graph. Relying on its non-euclidean data type, graph neural network (GNN) provides a clever way of le...]]></summary>
        <author>
            <name>Alaa Bessadok</name>
        </author>
        <author>
            <name>Mohamed Ali Mahjoub</name>
        </author>
        <author>
            <name>Islem Rekik</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Partial Convolution for Padding, Inpainting, and Image Synthesis]]></title>
        <id>https://ieeexplore.ieee.org/document/9903574</id>
        <link href="https://ieeexplore.ieee.org/document/9903574"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Partial convolution weights convolutions with binary masks and renormalizes on valid pixels. It was originally proposed for image inpainting task because a corrupted image processed by a standard convolutional often leads to artifacts. Therefore, binary masks are constructed that define the valid and corrupted pixels, so that partial convolution results are only calculated based on valid pixels. I...]]></summary>
        <author>
            <name>Guilin Liu</name>
        </author>
        <author>
            <name>Aysegul Dundar</name>
        </author>
        <author>
            <name>Kevin J. Shih</name>
        </author>
        <author>
            <name>Ting-Chun Wang</name>
        </author>
        <author>
            <name>Fitsum A. Reda</name>
        </author>
        <author>
            <name>Karan Sapra</name>
        </author>
        <author>
            <name>Zhiding Yu</name>
        </author>
        <author>
            <name>Xiaodong Yang</name>
        </author>
        <author>
            <name>Andrew Tao</name>
        </author>
        <author>
            <name>Bryan Catanzaro</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MaxMatch: Semi-Supervised Learning With Worst-Case Consistency]]></title>
        <id>https://ieeexplore.ieee.org/document/9897005</id>
        <link href="https://ieeexplore.ieee.org/document/9897005"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In recent years, great progress has been made to incorporate unlabeled data to overcome the inefficiently supervised problem via semi-supervised learning (SSL). Most state-of-the-art models are based on the idea of pursuing consistent model predictions over unlabeled data toward the input noise, which is called consistency regularization. Nonetheless, there is a lack of theoretical insights into t...]]></summary>
        <author>
            <name>Yangbangyan Jiang</name>
        </author>
        <author>
            <name>Xiaodan Li</name>
        </author>
        <author>
            <name>Yuefeng Chen</name>
        </author>
        <author>
            <name>Yuan He</name>
        </author>
        <author>
            <name>Qianqian Xu</name>
        </author>
        <author>
            <name>Zhiyong Yang</name>
        </author>
        <author>
            <name>Xiaochun Cao</name>
        </author>
        <author>
            <name>Qingming Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dynamic Graph Message Passing Networks]]></title>
        <id>https://ieeexplore.ieee.org/document/9895141</id>
        <link href="https://ieeexplore.ieee.org/document/9895141"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Modelling long-range dependencies is critical for scene understanding tasks in computer vision. Although convolution neural networks (CNNs) have excelled in many vision tasks, they are still limited in capturing long-range structured relationships as they typically consist of layers of local kernels. A fully-connected graph, such as the self-attention operation in Transformers, is beneficial for s...]]></summary>
        <author>
            <name>Li Zhang</name>
        </author>
        <author>
            <name>Mohan Chen</name>
        </author>
        <author>
            <name>Anurag Arnab</name>
        </author>
        <author>
            <name>Xiangyang Xue</name>
        </author>
        <author>
            <name>Philip H. S. Torr</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stylized Adversarial Defense]]></title>
        <id>https://ieeexplore.ieee.org/document/9895320</id>
        <link href="https://ieeexplore.ieee.org/document/9895320"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Deep Convolution Neural Networks (CNNs) can easily be fooled by subtle, imperceptible changes to the input images. To address this vulnerability, adversarial training creates perturbation patterns and includes them in the training set to robustify the model. In contrast to existing adversarial training methods that only use class-boundary information (e.g., using a cross-entropy loss), we propose ...]]></summary>
        <author>
            <name>Muzammal Naseer</name>
        </author>
        <author>
            <name>Salman Khan</name>
        </author>
        <author>
            <name>Munawar Hayat</name>
        </author>
        <author>
            <name>Fahad Shahbaz Khan</name>
        </author>
        <author>
            <name>Fatih Porikli</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Stereo Confidence Estimation via Locally Adaptive Fusion and Knowledge Distillation]]></title>
        <id>https://ieeexplore.ieee.org/document/9894086</id>
        <link href="https://ieeexplore.ieee.org/document/9894086"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Stereo confidence estimation aims to estimate the reliability of the estimated disparity by stereo matching. Different from the previous methods that exploit the limited input modality, we present a novel method that estimates confidence map of an initial disparity by making full use of tri-modal input, including matching cost, disparity, and color image through deep networks. The proposed network...]]></summary>
        <author>
            <name>Sunok Kim</name>
        </author>
        <author>
            <name>Seungryong Kim</name>
        </author>
        <author>
            <name>Dongbo Min</name>
        </author>
        <author>
            <name>Pascal Frossard</name>
        </author>
        <author>
            <name>Kwanghoon Sohn</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Efficient 3D Deep LiDAR Odometry]]></title>
        <id>https://ieeexplore.ieee.org/document/9893384</id>
        <link href="https://ieeexplore.ieee.org/document/9893384"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[An efficient 3D point cloud learning architecture, named EfficientLO-Net, for LiDAR odometry is first proposed in this article. In this architecture, the projection-aware representation of the 3D point cloud is proposed to organize the raw 3D point cloud into an ordered data form to achieve efficiency. The Pyramid, Warping, and Cost volume (PWC) structure for the LiDAR odometry task is built to es...]]></summary>
        <author>
            <name>Guangming Wang</name>
        </author>
        <author>
            <name>Xinrui Wu</name>
        </author>
        <author>
            <name>Shuyang Jiang</name>
        </author>
        <author>
            <name>Zhe Liu</name>
        </author>
        <author>
            <name>Hesheng Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PrintsGAN: Synthetic Fingerprint Generator]]></title>
        <id>https://ieeexplore.ieee.org/document/9893541</id>
        <link href="https://ieeexplore.ieee.org/document/9893541"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[A major impediment to researchers working in the area of fingerprint recognition is the lack of publicly available, large-scale, fingerprint datasets. The publicly available datasets that do exist contain very few identities and impressions per finger. This limits research on a number of topics, including e.g., using deep networks to learn fixed length fingerprint embeddings. Therefore, we propose...]]></summary>
        <author>
            <name>Joshua James Engelsma</name>
        </author>
        <author>
            <name>Steven Grosz</name>
        </author>
        <author>
            <name>Anil K. Jain</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Transitional Learning: Exploring the Transition States of Degradation for Blind Super-resolution]]></title>
        <id>https://ieeexplore.ieee.org/document/9893392</id>
        <link href="https://ieeexplore.ieee.org/document/9893392"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Being extremely dependent on iterative estimation of the degradation prior or optimization of the model from scratch, the existing blind super-resolution (SR) methods are generally time-consuming and less effective, as the estimation of degradation proceeds from a blind initialization and lacks interpretable representation of degradations. To address it, this article proposes a transitional learni...]]></summary>
        <author>
            <name>Yuanfei Huang</name>
        </author>
        <author>
            <name>Jie Li</name>
        </author>
        <author>
            <name>Yanting Hu</name>
        </author>
        <author>
            <name>Xinbo Gao</name>
        </author>
        <author>
            <name>Hua Huang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Progressive Hierarchical Alternating Least Squares Method for Symmetric Nonnegative Matrix Factorization]]></title>
        <id>https://ieeexplore.ieee.org/document/9891776</id>
        <link href="https://ieeexplore.ieee.org/document/9891776"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In this article, we study the symmetric nonnegative matrix factorization (SNMF) which is a powerful tool in data mining for dimension reduction and clustering. The main contributions of the present work include: (i) a new descent direction for the rank-one SNMF is derived and a strategy for choosing the step size along this descent direction is established; (ii) a progressive hierarchical alternat...]]></summary>
        <author>
            <name>Liangshao Hou</name>
        </author>
        <author>
            <name>Delin Chu</name>
        </author>
        <author>
            <name>Li-Zhi Liao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Class-Incremental Continual Learning Into the eXtended DER-Verse]]></title>
        <id>https://ieeexplore.ieee.org/document/9891836</id>
        <link href="https://ieeexplore.ieee.org/document/9891836"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The staple of human intelligence is the capability of acquiring knowledge in a continuous fashion. In stark contrast, Deep Networks forget catastrophically and, for this reason, the sub-field of Class-Incremental Continual Learning fosters methods that learn a sequence of tasks incrementally, blending sequentially-gained knowledge into a comprehensive prediction. This work aims at assessing and ov...]]></summary>
        <author>
            <name>Matteo Boschini</name>
        </author>
        <author>
            <name>Lorenzo Bonicelli</name>
        </author>
        <author>
            <name>Pietro Buzzega</name>
        </author>
        <author>
            <name>Angelo Porrello</name>
        </author>
        <author>
            <name>Simone Calderara</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deep Discriminative Feature Models (DDFMs) for Set Based Face Recognition and Distance Metric Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9888005</id>
        <link href="https://ieeexplore.ieee.org/document/9888005"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[This article introduces two methods that find compact deep feature models for approximating images in set based face recognition problems. The proposed method treats each image set as a nonlinear face manifold that is composed of linear components. To find linear components of the face manifold, we first split image sets into subsets containing face images which share similar appearances. Then, ou...]]></summary>
        <author>
            <name>Bedirhan Uzun</name>
        </author>
        <author>
            <name>Hakan Cevikalp</name>
        </author>
        <author>
            <name>Hasan Saribas</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[MCIBI++: Soft Mining Contextual Information Beyond Image for Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9888041</id>
        <link href="https://ieeexplore.ieee.org/document/9888041"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Co-occurrent visual pattern makes context aggregation become an essential paradigm for semantic segmentation. The existing studies focus on modeling the contexts within image while neglecting the valuable semantics of the corresponding category beyond image. To this end, we propose a novel soft mining contextual information beyond image paradigm named MCIBI++ to further boost the pixel-level repre...]]></summary>
        <author>
            <name>Zhenchao Jin</name>
        </author>
        <author>
            <name>Dongdong Yu</name>
        </author>
        <author>
            <name>Zehuan Yuan</name>
        </author>
        <author>
            <name>Lequan Yu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Searching a High Performance Feature Extractor for Text Recognition Network]]></title>
        <id>https://ieeexplore.ieee.org/document/9887897</id>
        <link href="https://ieeexplore.ieee.org/document/9887897"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Feature extractor plays a critical role in text recognition (TR), but customizing its architecture is relatively less explored due to expensive manual tweaking. In this article, inspired by the success of neural architecture search (NAS), we propose to search for suitable feature extractors. We design a domain-specific search space by exploring principles for having good feature extractors. The sp...]]></summary>
        <author>
            <name>Hui Zhang</name>
        </author>
        <author>
            <name>Quanming Yao</name>
        </author>
        <author>
            <name>James T. Kwok</name>
        </author>
        <author>
            <name>Xiang Bai</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[VOLO: Vision Outlooker for Visual Recognition]]></title>
        <id>https://ieeexplore.ieee.org/document/9888055</id>
        <link href="https://ieeexplore.ieee.org/document/9888055"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Recently, Vision Transformers (ViTs) have been broadly explored in visual recognition. With low efficiency in encoding fine-level features, the performance of ViTs is still inferior to the state-of-the-art CNNs when trained from scratch on a midsize dataset like ImageNet. Through experimental analysis, we find it is because of two reasons: 1) the simple tokenization of input images fails to model ...]]></summary>
        <author>
            <name>Li Yuan</name>
        </author>
        <author>
            <name>Qibin Hou</name>
        </author>
        <author>
            <name>Zihang Jiang</name>
        </author>
        <author>
            <name>Jiashi Feng</name>
        </author>
        <author>
            <name>Shuicheng Yan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A Principled Design of Image Representation: Towards Forensic Tasks]]></title>
        <id>https://ieeexplore.ieee.org/document/9881995</id>
        <link href="https://ieeexplore.ieee.org/document/9881995"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Image forensics is a rising topic as the trustworthy multimedia content is critical for modern society. Like other vision-related applications, forensic analysis relies heavily on the proper image representation. Despite the importance, current theoretical understanding for such representation remains limited, with varying degrees of neglect for its key role. For this gap, we attempt to investigat...]]></summary>
        <author>
            <name>Shuren Qi</name>
        </author>
        <author>
            <name>Yushu Zhang</name>
        </author>
        <author>
            <name>Chao Wang</name>
        </author>
        <author>
            <name>Jiantao Zhou</name>
        </author>
        <author>
            <name>Xiaochun Cao</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Regularized Multi-Output Gaussian Convolution Process With Domain Adaptation]]></title>
        <id>https://ieeexplore.ieee.org/document/9881867</id>
        <link href="https://ieeexplore.ieee.org/document/9881867"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multi-output Gaussian process (MGP) has been attracting increasing attention as a transfer learning method to model multiple outputs. Despite its high flexibility and generality, MGP still faces two critical challenges when applied to transfer learning. The first one is negative transfer, which occurs when there exists no shared information among the outputs. The second challenge is the input doma...]]></summary>
        <author>
            <name>Xinming Wang</name>
        </author>
        <author>
            <name>Chao Wang</name>
        </author>
        <author>
            <name>Xuan Song</name>
        </author>
        <author>
            <name>Levi Kirby</name>
        </author>
        <author>
            <name>Jianguo Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning to Discriminate Information for Online Action Detection: Analysis and Application]]></title>
        <id>https://ieeexplore.ieee.org/document/9881239</id>
        <link href="https://ieeexplore.ieee.org/document/9881239"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Online action detection, which aims to identify an ongoing action from a streaming video, is an important subject in real-world applications. For this task, previous methods use recurrent neural networks for modeling temporal relations in an input sequence. However, these methods overlook the fact that the input image sequence includes not only the action of interest but background and irrelevant ...]]></summary>
        <author>
            <name>Sumin Lee</name>
        </author>
        <author>
            <name>Hyunjun Eun</name>
        </author>
        <author>
            <name>Jinyoung Moon</name>
        </author>
        <author>
            <name>Seokeon Choi</name>
        </author>
        <author>
            <name>Yoonhyung Kim</name>
        </author>
        <author>
            <name>Chanho Jung</name>
        </author>
        <author>
            <name>Changick Kim</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[On the Convergence of Tsetlin Machines for the XOR Operator]]></title>
        <id>https://ieeexplore.ieee.org/document/9881240</id>
        <link href="https://ieeexplore.ieee.org/document/9881240"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[The Tsetlin Machine (TM) is a novel machine learning algorithm with several distinct properties, including transparent inference and learning using hardware-near building blocks. Although numerous papers explore the TM empirically, many of its properties have not yet been analyzed mathematically. In this article, we analyze the convergence of the TM when input is non-linearly related to output by ...]]></summary>
        <author>
            <name>Lei Jiao</name>
        </author>
        <author>
            <name>Xuan Zhang</name>
        </author>
        <author>
            <name>Ole-Christoffer Granmo</name>
        </author>
        <author>
            <name>Kuruge Darshana Abeyrathna</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Point Cloud Registration Framework Based on Deep Graph Matching]]></title>
        <id>https://ieeexplore.ieee.org/document/9878213</id>
        <link href="https://ieeexplore.ieee.org/document/9878213"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[3D point cloud registration is a fundamental problem in computer vision and robotics. Recently, learning-based point cloud registration methods have made great progress. However, these methods are sensitive to outliers, which lead to more incorrect correspondences. In this paper, we propose a novel deep graph matching-based framework for point cloud registration. Specifically, we first transform p...]]></summary>
        <author>
            <name>Kexue Fu</name>
        </author>
        <author>
            <name>Jiazheng Luo</name>
        </author>
        <author>
            <name>Xiaoyuan Luo</name>
        </author>
        <author>
            <name>Shaolei Liu</name>
        </author>
        <author>
            <name>Chenxi Zhang</name>
        </author>
        <author>
            <name>Manning Wang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Exact Decomposition of Joint Low Rankness and Local Smoothness Plus Sparse Matrices]]></title>
        <id>https://ieeexplore.ieee.org/document/9875963</id>
        <link href="https://ieeexplore.ieee.org/document/9875963"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[It is known that the decomposition in low-rank and sparse matrices (L+S for short) can be achieved by several Robust PCA techniques. Besides the low rankness, the local smoothness (LSS) is a vitally essential prior for many real-world matrix data such as hyperspectral images and surveillance videos, which makes such matrices have low-rankness and local smoothness property at the same time. This po...]]></summary>
        <author>
            <name>Jiangjun Peng</name>
        </author>
        <author>
            <name>Yao Wang</name>
        </author>
        <author>
            <name>Hongying Zhang</name>
        </author>
        <author>
            <name>Jianjun Wang</name>
        </author>
        <author>
            <name>Deyu Meng</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Explainability in Graph Neural Networks: A Taxonomic Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9875989</id>
        <link href="https://ieeexplore.ieee.org/document/9875989"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Deep learning methods are achieving ever-increasing performance on many artificial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved si...]]></summary>
        <author>
            <name>Hao Yuan</name>
        </author>
        <author>
            <name>Haiyang Yu</name>
        </author>
        <author>
            <name>Shurui Gui</name>
        </author>
        <author>
            <name>Shuiwang Ji</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Untrained Neural Network Priors for Inverse Imaging Problems: A Survey]]></title>
        <id>https://ieeexplore.ieee.org/document/9878048</id>
        <link href="https://ieeexplore.ieee.org/document/9878048"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In recent years, advancements in machine learning (ML) techniques, in particular, deep learning (DL) methods have gained a lot of momentum in solving inverse imaging problems, often surpassing the performance provided by hand-crafted approaches. Traditionally, analytical methods have been used to solve inverse imaging problems such as image restoration, inpainting, and superresolution. Unlike anal...]]></summary>
        <author>
            <name>Adnan Qayyum</name>
        </author>
        <author>
            <name>Inaam Ilahi</name>
        </author>
        <author>
            <name>Fahad Shamshad</name>
        </author>
        <author>
            <name>Farid Boussaid</name>
        </author>
        <author>
            <name>Mohammed Bennamoun</name>
        </author>
        <author>
            <name>Junaid Qadir</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Semi-Supervised Hierarchical Graph Classification]]></title>
        <id>https://ieeexplore.ieee.org/document/9875050</id>
        <link href="https://ieeexplore.ieee.org/document/9875050"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Node classification and graph classification are two graph learning problems that predict the class label of a node and the class label of a graph respectively. A node of a graph usually represents a real-world entity, e.g., a user in a social network, or a document in a document citation network. In this work, we consider a more challenging but practically useful setting, in which a node itself i...]]></summary>
        <author>
            <name>Jia Li</name>
        </author>
        <author>
            <name>Yongfeng Huang</name>
        </author>
        <author>
            <name>Heng Chang</name>
        </author>
        <author>
            <name>Yu Rong</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Variational Label Enhancement]]></title>
        <id>https://ieeexplore.ieee.org/document/9875104</id>
        <link href="https://ieeexplore.ieee.org/document/9875104"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Multi-label learning focuses on the ambiguity at the label side, i.e., one instance is associated with multiple class labels, where the logical labels are always adopted to partition class labels into relevant labels and irrelevant labels rigidly. However, the relevance or irrelevance of each label corresponding to one instance is essentially relative in real-world tasks and the label distribution...]]></summary>
        <author>
            <name>Ning Xu</name>
        </author>
        <author>
            <name>Jun Shu</name>
        </author>
        <author>
            <name>Renyi Zheng</name>
        </author>
        <author>
            <name>Xin Geng</name>
        </author>
        <author>
            <name>Deyu Meng</name>
        </author>
        <author>
            <name>Min-Ling Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[BiFuse++: Self-Supervised and Efficient Bi-Projection Fusion for 360° Depth Estimation]]></title>
        <id>https://ieeexplore.ieee.org/document/9874253</id>
        <link href="https://ieeexplore.ieee.org/document/9874253"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Due to the rise of spherical cameras, monocular 360$^\circ$∘ depth estimation becomes an important technique for many applications (e.g., autonomous systems). Thus, state-of-the-art frameworks for monocular 360$^\circ$∘ depth estimation such as bi-projection fusion in BiFuse are proposed. To train such a framework, a large number of panoramas along with the corresponding depth ground truths captur...]]></summary>
        <author>
            <name>Fu-En Wang</name>
        </author>
        <author>
            <name>Yu-Hsuan Yeh</name>
        </author>
        <author>
            <name>Yi-Hsuan Tsai</name>
        </author>
        <author>
            <name>Wei-Chen Chiu</name>
        </author>
        <author>
            <name>Min Sun</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory-Based Cross-Image Contexts for Weakly Supervised Semantic Segmentation]]></title>
        <id>https://ieeexplore.ieee.org/document/9873854</id>
        <link href="https://ieeexplore.ieee.org/document/9873854"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Weakly supervised semantic segmentation (WSSS) trains segmentation models by only weak labels, aiming to save the burden of expensive pixel-level annotations. This paper tackles the WSSS problem of utilizing image-level labels as the weak supervision. Previous approaches address this problem by focusing on generating better pseudo-masks from weak labels to train the segmentation model. However, th...]]></summary>
        <author>
            <name>Junsong Fan</name>
        </author>
        <author>
            <name>Zhaoxiang Zhang</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contrastive Learning With Stronger Augmentations]]></title>
        <id>https://ieeexplore.ieee.org/document/9873966</id>
        <link href="https://ieeexplore.ieee.org/document/9873966"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Representation learning has significantly been developed with the advance of contrastive learning methods. Most of those methods are benefited from various data augmentations that are carefully designated to maintain their identities so that the images transformed from the same instance can still be retrieved. However, those carefully designed transformations limited us to further explore the nove...]]></summary>
        <author>
            <name>Xiao Wang</name>
        </author>
        <author>
            <name>Guo-Jun Qi</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Parameterized Hamiltonian Learning With Quantum Circuit]]></title>
        <id>https://ieeexplore.ieee.org/document/9872139</id>
        <link href="https://ieeexplore.ieee.org/document/9872139"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Hamiltonian learning, as an important quantum machine learning technique, provides a significant approach for determining an accurate quantum system. This paper establishes parameterized Hamiltonian learning (PHL) and explores its application and implementation on quantum computers. A parameterized quantum circuit for Hamiltonian learning is first created by decomposing unitary operators to excite...]]></summary>
        <author>
            <name>Jinjing Shi</name>
        </author>
        <author>
            <name>Wenxuan Wang</name>
        </author>
        <author>
            <name>Xiaoping Lou</name>
        </author>
        <author>
            <name>Shichao Zhang</name>
        </author>
        <author>
            <name>Xuelong Li</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Blind Image Super-Resolution: A Survey and Beyond]]></title>
        <id>https://ieeexplore.ieee.org/document/9870558</id>
        <link href="https://ieeexplore.ieee.org/document/9870558"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Blind image super-resolution (SR), aiming to super-resolve low-resolution images with unknown degradation, has attracted increasing attention due to its significance in promoting real-world applications. Many novel and effective solutions have been proposed recently, especially with powerful deep learning techniques. Despite years of efforts, it still remains as a challenging research problem. Thi...]]></summary>
        <author>
            <name>Anran Liu</name>
        </author>
        <author>
            <name>Yihao Liu</name>
        </author>
        <author>
            <name>Jinjin Gu</name>
        </author>
        <author>
            <name>Yu Qiao</name>
        </author>
        <author>
            <name>Chao Dong</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Reformulating Optical Flow to Solve Image-Based Inverse Problems and Quantify Uncertainty]]></title>
        <id>https://ieeexplore.ieee.org/document/9870569</id>
        <link href="https://ieeexplore.ieee.org/document/9870569"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[From meteorology to medical imaging and cell mechanics, many scientific domains use inverse problems (IPs) to extract physical measurements from image movement. To this end, motion estimation methods such as optical flow (OF) pre-process images into motion data to feed the IP, which then inverts for the measurements through a physical model. However, this combined OFIP pipeline exacerbates the ill...]]></summary>
        <author>
            <name>Aleix Boquet-Pujadas</name>
        </author>
        <author>
            <name>Jean-Christophe Olivo-Marin</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Robust Online Tracking With Meta-Updater]]></title>
        <id>https://ieeexplore.ieee.org/document/9870567</id>
        <link href="https://ieeexplore.ieee.org/document/9870567"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[In a sequence, the appearance of both the target and background often changes dramatically. Offline-trained models may not handle huge appearance variations well, causing tracking failures. Most discriminative trackers address this issue by introducing an online update scheme, making the model dynamically adapt the changes of the target and background. Although the online update scheme plays an im...]]></summary>
        <author>
            <name>Jie Zhao</name>
        </author>
        <author>
            <name>Kenan Dai</name>
        </author>
        <author>
            <name>Pengyu Zhang</name>
        </author>
        <author>
            <name>Dong Wang</name>
        </author>
        <author>
            <name>Huchuan Lu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kernel-Based Generalized Median Computation for Consensus Learning]]></title>
        <id>https://ieeexplore.ieee.org/document/9869722</id>
        <link href="https://ieeexplore.ieee.org/document/9869722"/>
        <updated>2023-04-27T04:15:42.609Z</updated>
        <summary type="html"><![CDATA[Computing a consensus object from a set of given objects is a core problem in machine learning and pattern recognition. One popular approach is to formulate it as an optimization problem using the generalized median. Previous methods like the Prototype and Distance-Preserving Embedding methods transform objects into a vector space, solve the generalized median problem in this space, and inversely ...]]></summary>
        <author>
            <name>Andreas Nienkötter</name>
        </author>
        <author>
            <name>Xiaoyi Jiang</name>
        </author>
    </entry>
</feed>