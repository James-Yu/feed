<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
        <link>http://jamesyu.me/feed/TPAMI.rss</link>
        <description>IEEE Transactions on Pattern Analysis and Machine Intelligence</description>
        <lastBuildDate>Thu, 27 Apr 2023 04:15:42 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <copyright>MIT</copyright>
        <item>
            <title><![CDATA[SignBERT+: Hand-model-aware Self-supervised Pre-training for Sign Language Understanding]]></title>
            <link>https://ieeexplore.ieee.org/document/10109128</link>
            <guid>https://ieeexplore.ieee.org/document/10109128</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Hand gesture serves as a crucial role during the expression of sign language. Current deep learning based methods for sign language understanding (SLU) are prone to over-fitting due to insufficient sign data resource and suffer limited interpretability. In this paper, we propose the first self-supervised pre-trainable SignBERT+ framework with model-aware hand prior incorporated. In our framework, ...]]></description>
        </item>
        <item>
            <title><![CDATA[Source-Free Progressive Graph Learning for Open-Set Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/10107906</link>
            <guid>https://ieeexplore.ieee.org/document/10107906</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Open-set domain adaptation (OSDA) has gained considerable attention in many visual recognition tasks. The aim of OSDA is to transfer knowledge from a label-rich source domain to a label-scarce target domain while addressing the disturbances from the irrelevant target classes that are not present in the source data. However, most existing OSDA approaches are limited due to three main reasons, inclu...]]></description>
        </item>
        <item>
            <title><![CDATA[High-Order Correlation-Guided Slide-Level Histology Retrieval With Self-Supervised Hashing]]></title>
            <link>https://ieeexplore.ieee.org/document/10107814</link>
            <guid>https://ieeexplore.ieee.org/document/10107814</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Histopathological Whole Slide Images (WSIs) play a crucial role in cancer diagnosis. It is of significant importance for pathologists to search for images sharing similar content with the query WSI, especially in the case-based diagnosis. While slide-level retrieval could be more intuitive and practical in clinical applications, most methods are designed for patch-level retrieval. A few recently u...]]></description>
        </item>
        <item>
            <title><![CDATA[NExT-OOD: Overcoming Dual Multiple-choice VQA Biases]]></title>
            <link>https://ieeexplore.ieee.org/document/10107423</link>
            <guid>https://ieeexplore.ieee.org/document/10107423</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In recent years, multiple-choice Visual Question Answering (VQA) has become topical and achieved remarkable progress. However, most pioneer multiple-choice VQA models are heavily driven by statistical correlations in datasets, which cannot perform well on multimodal understanding and suffer from poor generalization. In this paper, we identify two kinds of spurious correlations, i.e., a Vision-Answ...]]></description>
        </item>
        <item>
            <title><![CDATA[An integrated fast Hough transform for multidimensional data]]></title>
            <link>https://ieeexplore.ieee.org/document/10106423</link>
            <guid>https://ieeexplore.ieee.org/document/10106423</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Line, plane and hyperplane detection in multidimensional data has many applications in computer vision and artificial intelligence. We propose Integrated Fast Hough Transform (IFHT), a highly-efficient multidimensional Hough transform algorithm based on a new mathematical model. The parameter space of IFHT can be represented with a single k-tree to support hierarchical storage and “coarse-to-fine”...]]></description>
        </item>
        <item>
            <title><![CDATA[Variational Relational Point Completion Network for Robust 3D Classification]]></title>
            <link>https://ieeexplore.ieee.org/document/10106495</link>
            <guid>https://ieeexplore.ieee.org/document/10106495</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Real-scanned point clouds are often incomplete due to viewpoint, occlusion, and noise, which hampers 3D geometric modeling and perception. Existing point cloud completion methods tend to generate global shape skeletons and hence lack fine local details. Furthermore, they mostly learn a deterministic partial-to-complete mapping, but overlook structural relations in man-made objects. To tackle these...]]></description>
        </item>
        <item>
            <title><![CDATA[An Information-Theoretic Method to Automatic Shortcut Avoidance and Domain Generalization for Dense Prediction Tasks]]></title>
            <link>https://ieeexplore.ieee.org/document/10106000</link>
            <guid>https://ieeexplore.ieee.org/document/10106000</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep convolutional neural networks for dense prediction tasks are commonly optimized using synthetic data, as generating pixel-wise annotations for real-world data is laborious. However, the synthetically trained models do not generalize well to real-world environments. This poor “synthetic to real” (S2R) generalization we address through the lens of shortcut learning. We demonstrate that the lear...]]></description>
        </item>
        <item>
            <title><![CDATA[Global Aligned Structured Sparsity Learning for Efficient Image Super-Resolution]]></title>
            <link>https://ieeexplore.ieee.org/document/10106130</link>
            <guid>https://ieeexplore.ieee.org/document/10106130</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Efficient image super-resolution (SR) has witnessed rapid progress thanks to novel lightweight architectures or model compression techniques (e.g., neural architecture search and knowledge distillation). Nevertheless, these methods consume considerable resources or/and neglect to squeeze out the network redundancy at a more fine-grained convolution filter level. Network pruning is a promising alte...]]></description>
        </item>
        <item>
            <title><![CDATA[Deformable Part Region Learning and Feature Aggregation Tree Representation for Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10106088</link>
            <guid>https://ieeexplore.ieee.org/document/10106088</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Region-based object detection infers object regions for one or more categories in an image. Due to the recent advances in deep learning and region proposal methods, object detectors based on convolutional neural networks (CNNs) have been flourishing and provided promising detection results. However, the accuracy of the convolutional object detectors can be degraded often due to the low feature dis...]]></description>
        </item>
        <item>
            <title><![CDATA[RelTR: Relation Transformer for Scene Graph Generation]]></title>
            <link>https://ieeexplore.ieee.org/document/10105507</link>
            <guid>https://ieeexplore.ieee.org/document/10105507</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Different objects in the same scene are more or less related to each other, but only a limited number of these relationships are noteworthy. Inspired by Detection Transformer, which excels in object detection, we view scene graph generation as a set prediction problem. In this paper, we propose an end-to-end scene graph generation model Relation Transformer (RelTR), which has an encoder-decoder ar...]]></description>
        </item>
        <item>
            <title><![CDATA[Representing Multimodal Behaviors With Mean Location for Pedestrian Trajectory Prediction]]></title>
            <link>https://ieeexplore.ieee.org/document/10105525</link>
            <guid>https://ieeexplore.ieee.org/document/10105525</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Representing multimodal behaviors is a critical challenge for pedestrian trajectory prediction. Previous methods commonly represent this multimodality with multiple latent variables repeatedly sampled from a latent space, encountering difficulties in interpretable trajectory prediction. Moreover, the latent space is usually built by encoding global interaction into future trajectory, which inevita...]]></description>
        </item>
        <item>
            <title><![CDATA[Dual Vision Transformer]]></title>
            <link>https://ieeexplore.ieee.org/document/10105499</link>
            <guid>https://ieeexplore.ieee.org/document/10105499</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent advances have presented several strategies to mitigate the computations of self-attention mechanism with high-resolution inputs. Many of these works consider decomposing the global self-attention procedure over image patches into regional and local feature extraction procedures that each incurs a smaller computational complexity. Despite good efficiency, these approaches seldom explore the ...]]></description>
        </item>
        <item>
            <title><![CDATA[REDRESS: Generating Compressed Models for Edge Inference Using Tsetlin Machines]]></title>
            <link>https://ieeexplore.ieee.org/document/10105493</link>
            <guid>https://ieeexplore.ieee.org/document/10105493</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Inference at-the-edge using embedded machine learning models is associated with challenging trade-offs between resource metrics, such as energy and memory footprint, and the performance metrics, such as computation time and accuracy. In this work, we go beyond the conventional Neural Network based approaches to explore Tsetlin Machine (TM), an emerging machine learning algorithm, that uses learnin...]]></description>
        </item>
        <item>
            <title><![CDATA[Mutual Voting for Ranking 3D Correspondences]]></title>
            <link>https://ieeexplore.ieee.org/document/10105460</link>
            <guid>https://ieeexplore.ieee.org/document/10105460</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Consistent correspondences between point clouds are vital to 3D vision tasks such as registration and recognition. In this paper, we present a mutual voting method for ranking 3D correspondences. The key insight is to achieve reliable scoring results for correspondences by refining both voters and candidates in a mutual voting scheme. First, a graph is constructed for the initial correspondence se...]]></description>
        </item>
        <item>
            <title><![CDATA[LRRNet: A Novel Representation Learning Guided Fusion Network for Infrared and Visible Images]]></title>
            <link>https://ieeexplore.ieee.org/document/10105495</link>
            <guid>https://ieeexplore.ieee.org/document/10105495</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep learning based fusion methods have been achieving promising performance in image fusion tasks. This is attributed to the network architecture that plays a very important role in the fusion process. However, in general, it is hard to specify a good fusion architecture, and consequently, the design of fusion networks is still a black art, rather than science. To address this problem, we formula...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Long-Tailed Learning: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/10105457</link>
            <guid>https://ieeexplore.ieee.org/document/10105457</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep long-tailed learning, one of the most challenging problems in visual recognition, aims to train well-performing deep models from a large number of images that follow a long-tailed class distribution. In the last decade, deep learning has emerged as a powerful recognition model for learning high-quality image representations and has led to remarkable breakthroughs in generic visual recognition...]]></description>
        </item>
        <item>
            <title><![CDATA[Attention Weighted Local Descriptors]]></title>
            <link>https://ieeexplore.ieee.org/document/10105519</link>
            <guid>https://ieeexplore.ieee.org/document/10105519</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Local features detection and description are widely used in many vision applications with high industrial and commercial demands. With large-scale applications, these tasks raise high expectations for both the accuracy and speed of local features. Most existing studies on local features learning focus on the local descriptions of individual keypoints, which neglect their relationships established ...]]></description>
        </item>
        <item>
            <title><![CDATA[Visual Reasoning: From State to Transformation]]></title>
            <link>https://ieeexplore.ieee.org/document/10105523</link>
            <guid>https://ieeexplore.ieee.org/document/10105523</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Most existing visual reasoning tasks, such as CLEVR in VQA, ignore an important factor, i.e. transformation. They are solely defined to test how well machines understand concepts and relations within static settings, like one image. Such state driven visual reasoning has limitations in reflecting the ability to infer the dynamics between different states, which has shown to be equally important fo...]]></description>
        </item>
        <item>
            <title><![CDATA[Gate-Shift-Fuse for Video Action Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10105518</link>
            <guid>https://ieeexplore.ieee.org/document/10105518</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Convolutional Neural Networks are the de facto models for image recognition. However 3D CNNs, the straight forward extension of 2D CNNs for video recognition, have not achieved the same success on standard action recognition benchmarks. One of the main reasons for this reduced performance of 3D CNNs is the increased computational complexity requiring large scale annotated datasets to train them in...]]></description>
        </item>
        <item>
            <title><![CDATA[Prior Image Guided Snapshot Compressive Spectral Imaging]]></title>
            <link>https://ieeexplore.ieee.org/document/10098166</link>
            <guid>https://ieeexplore.ieee.org/document/10098166</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Spectral images with rich spatial and spectral information have wide usage, however, traditional spectral imaging techniques undeniably take a long time to capture scenes. We consider the computational imaging problem of the snapshot spectral spectrometer, i.e., the Coded Aperture Snapshot Spectral Imaging (CASSI) system. For the sake of a fast and generalized reconstruction algorithm, we propose ...]]></description>
        </item>
        <item>
            <title><![CDATA[Temporal Pixel-Level Semantic Understanding Through the VSPW Dataset]]></title>
            <link>https://ieeexplore.ieee.org/document/10098665</link>
            <guid>https://ieeexplore.ieee.org/document/10098665</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Scene understanding through pixel-level semantic parsing is one of the main problems in computer vision. Till now, image-based methods and datasets for scene parsing have been well explored. However, the real world is naturally dynamic instead of a static state. Thus, learning to perform video scene parsing is more practical for real-world applications. Considering that few datasets cover an exten...]]></description>
        </item>
        <item>
            <title><![CDATA[Base and Meta: A New Perspective on Few-Shot Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10098188</link>
            <guid>https://ieeexplore.ieee.org/document/10098188</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Despite the progress made by few-shot segmentation (FSS) in low-data regimes, the generalization capability of most previous works could be fragile when countering hard query samples with seen-class objects. This paper proposes a fresh and powerful scheme to tackle such an intractable bias problem, dubbed base and meta (BAM). Concretely, we apply an auxiliary branch (base learner) to the conventio...]]></description>
        </item>
        <item>
            <title><![CDATA[Sparse-to-Dense Matching Network for Large-scale LiDAR Point Cloud Registration]]></title>
            <link>https://ieeexplore.ieee.org/document/10097640</link>
            <guid>https://ieeexplore.ieee.org/document/10097640</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Point cloud registration is a fundamental problem in 3D computer vision. Previous learning-based methods for LiDAR point cloud registration can be categorized into two schemes: dense-to-dense matching methods and sparse-to-sparse matching methods. However, for large-scale outdoor LiDAR point clouds, solving dense point correspondences is time-consuming, whereas sparse keypoint matching easily suff...]]></description>
        </item>
        <item>
            <title><![CDATA[PSLT: A Light-weight Vision Transformer with Ladder Self-Attention and Progressive Shift]]></title>
            <link>https://ieeexplore.ieee.org/document/10097573</link>
            <guid>https://ieeexplore.ieee.org/document/10097573</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Vision Transformer (ViT) has shown great potential for various visual tasks due to its ability to model long-range dependency. However, ViT requires a large amount of computing resource to compute the global self-attention. In this work, we propose a ladder self-attention block with multiple branches and a progressive shift mechanism to develop a light-weight transformer backbone that requires les...]]></description>
        </item>
        <item>
            <title><![CDATA[CP3: Unifying Point Cloud Completion by Pretrain-Prompt-Predict Paradigm]]></title>
            <link>https://ieeexplore.ieee.org/document/10097548</link>
            <guid>https://ieeexplore.ieee.org/document/10097548</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Point cloud completion aims to predict complete shape from its partial observation. Current approaches mainly consist of generation and refinement stages in a coarse-to-fine style. However, the generation stage often lacks robustness to tackle different incomplete variations, while the refinement stage blindly recovers point clouds without the semantic awareness. To tackle these challenges, we uni...]]></description>
        </item>
        <item>
            <title><![CDATA[Prioritized Subnet Sampling for Resource-Adaptive Supernet Training]]></title>
            <link>https://ieeexplore.ieee.org/document/10094012</link>
            <guid>https://ieeexplore.ieee.org/document/10094012</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[A resource-adaptive supernet adjusts its subnets for inference to fit the dynamically available resources. In this paper, we propose prioritized subnet sampling to train a resource-adaptive supernet, termed PSS-Net. We maintain multiple subnet pools, each of which stores the information of substantial subnets with similar resource consumption. Considering a resource constraint, subnets conditioned...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Gaussian Scale Mixture Prior for Image Reconstruction]]></title>
            <link>https://ieeexplore.ieee.org/document/10094019</link>
            <guid>https://ieeexplore.ieee.org/document/10094019</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image reconstruction from partial observations has attracted increasing attention. Conventional image reconstruction methods with hand-crafted priors often fail to recover fine image details due to the poor representation capability of the hand-crafted priors. Deep learning methods attack this problem by directly learning mapping functions between the observations and the targeted images can achie...]]></description>
        </item>
        <item>
            <title><![CDATA[The cluster structure function]]></title>
            <link>https://ieeexplore.ieee.org/document/10093042</link>
            <guid>https://ieeexplore.ieee.org/document/10093042</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[For each partition of a data set into a given number of parts there is a partition such that every part is as much as possible a good model (an “algorithmic sufficient statistic”) for the data in that part. Since this can be done for every number between one and the number of data, the result is a function, the cluster structure function. It maps the number of parts of a partition to values relate...]]></description>
        </item>
        <item>
            <title><![CDATA[GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector]]></title>
            <link>https://ieeexplore.ieee.org/document/10093066</link>
            <guid>https://ieeexplore.ieee.org/document/10093066</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we present a novel end-to-end group collaborative learning network, termed GCoNet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. The proposed GCoNet+ achieves the new state-of-the-art performance for co-salient object detection (CoSOD) through mining consensus representations based on the following two essential criteria: 1) intra-gr...]]></description>
        </item>
        <item>
            <title><![CDATA[Surrogate modeling for Bayesian optimization beyond a single Gaussian process]]></title>
            <link>https://ieeexplore.ieee.org/document/10093035</link>
            <guid>https://ieeexplore.ieee.org/document/10093035</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Bayesian optimization (BO) has well-documented merits for optimizing black-box functions with an expensive evaluation cost. Such functions emerge in applications as diverse as hyperparameter tuning, drug discovery, and robotics. BO hinges on a Bayesian surrogate model to sequentially select query points so as to balance exploration with exploitation of the search space. Most existing works rely on...]]></description>
        </item>
        <item>
            <title><![CDATA[Bias-Compensated Integral Regression for Human Pose Estimation]]></title>
            <link>https://ieeexplore.ieee.org/document/10093110</link>
            <guid>https://ieeexplore.ieee.org/document/10093110</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In human and hand pose estimation, heatmaps are a crucial intermediate representation for a body or hand keypoint. Two popular methods to decode the heatmap into a final joint coordinate are via an argmax, as done in heatmap detection, or via softmax and expectation, as done in integral regression. Integral regression is learnable end-to-end, but has lower accuracy than detection. This paper uncov...]]></description>
        </item>
        <item>
            <title><![CDATA[Point Cloud Scene Completion with Joint Color and Semantic Estimation from Single RGB-D Image]]></title>
            <link>https://ieeexplore.ieee.org/document/10093076</link>
            <guid>https://ieeexplore.ieee.org/document/10093076</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present a deep reinforcement learning method of progressive view inpainting for colored semantic point cloud scene completion under volume guidance, achieving high-quality scene reconstruction from only a single RGB-D image with severe occlusion. Our approach is end-to-end, consisting of three modules: 3D scene volume reconstruction, 2D RGB-D and segmentation image inpainting, and multi-view se...]]></description>
        </item>
        <item>
            <title><![CDATA[QGORE: Quadratic-Time Guaranteed Outlier Removal for Point Cloud Registration]]></title>
            <link>https://ieeexplore.ieee.org/document/10091912</link>
            <guid>https://ieeexplore.ieee.org/document/10091912</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[With the development of 3D matching technology, correspondence-based point cloud registration gains more attention. Unfortunately, 3D keypoint techniques inevitably produce a large number of outliers, i.e., outlier rate is often larger than 95%. Guaranteed outlier removal (GORE) [1] has shown very good robustness to extreme outliers. However, the high computational cost (exponential in the worst c...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning by Restoring Broken 3D Geometry]]></title>
            <link>https://ieeexplore.ieee.org/document/10091218</link>
            <guid>https://ieeexplore.ieee.org/document/10091218</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The key point for an experienced craftsman to repair broken objects effectively is that he must know about them deeply. Similarly, we believe that a model can capture rich geometry information from a shape/scene and generate discriminative representations if it is able to find distorted parts of shapes/scenes and restore them. Inspired by this observation, we propose a novel self-supervised 3D lea...]]></description>
        </item>
        <item>
            <title><![CDATA[Sparse Quadratic Approximation for Graph Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10091452</link>
            <guid>https://ieeexplore.ieee.org/document/10091452</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Learning graphs represented by $M$-matrices via an $\ell _{1}$-regularized Gaussian maximum-likelihood method is a popular approach, but also one that poses computational challenges for large scale datasets. Recently proposed methods cast this problem as a constrained optimization variant of precision matrix estimation. In this paper, we build on a state-of-the-art sparse precision matrix estimati...]]></description>
        </item>
        <item>
            <title><![CDATA[GFNet: Global Filter Networks for Visual Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10091201</link>
            <guid>https://ieeexplore.ieee.org/document/10091201</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent advances in self-attention and pure multi-layer perceptrons (MLP) models for vision have shown great potential in achieving promising performance with fewer inductive biases. These models are generally based on learning interaction among spatial locations from raw data. The complexity of self-attention and MLP grows quadratically as the image size increases, which makes these models hard to...]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Spatial Sparsification for Efficient Vision Transformers and Convolutional Neural Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10091227</link>
            <guid>https://ieeexplore.ieee.org/document/10091227</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we present a new approach for model acceleration by exploiting spatial sparsity in visual data. We observe that the final prediction in vision Transformers is only based on a subset of the most informative regions, which is sufficient for accurate image recognition. Based on this observation, we propose a dynamic token sparsification framework to prune redundant tokens progressively...]]></description>
        </item>
        <item>
            <title><![CDATA[Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap]]></title>
            <link>https://ieeexplore.ieee.org/document/10089511</link>
            <guid>https://ieeexplore.ieee.org/document/10089511</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent advances in transformer-based architectures have shown promise in several machine learning tasks. In the audio domain, such architectures have been successfully utilised in the field of speech emotion recognition (SER). However, existing works have not evaluated the influence of model size and pre-training data on downstream performance, and have shown limited attention to generalisation, r...]]></description>
        </item>
        <item>
            <title><![CDATA[Depth-Guided Optimization of Neural Radiance Fields for Indoor Multi-View Stereo]]></title>
            <link>https://ieeexplore.ieee.org/document/10089515</link>
            <guid>https://ieeexplore.ieee.org/document/10089515</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this work, we present a new multi-view depth estimation method NerfingMVS that utilizes both conventional reconstruction and learning-based priors over the recently proposed neural radiance fields (NeRF). Unlike existing neural network based optimization method that relies on estimated correspondences, our method directly optimizes over implicit volumes, eliminating the challenging step of matc...]]></description>
        </item>
        <item>
            <title><![CDATA[GradMDM: Adversarial Attack on Dynamic Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10089510</link>
            <guid>https://ieeexplore.ieee.org/document/10089510</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Dynamic neural networks can greatly reduce computation redundancy without compromising accuracy by adapting their structures based on the input. In this paper, we explore the robustness of dynamic neural networks against energy-oriented attacks targeted at reducing their efficiency. Specifically, we attack dynamic models with our novel algorithm GradMDM. GradMDM is a technique that adjusts the dir...]]></description>
        </item>
        <item>
            <title><![CDATA[Geometry- and Accuracy-Preserving Random Forest Proximities]]></title>
            <link>https://ieeexplore.ieee.org/document/10089875</link>
            <guid>https://ieeexplore.ieee.org/document/10089875</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Random forests are considered one of the best out-of-the-box classification and regression algorithms due to their high level of predictive performance with relatively little tuning. Pairwise proximities can be computed from a trained random forest and measure the similarity between data points relative to the supervised task. Random forest proximities have been used in many applications including...]]></description>
        </item>
        <item>
            <title><![CDATA[Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features]]></title>
            <link>https://ieeexplore.ieee.org/document/10089190</link>
            <guid>https://ieeexplore.ieee.org/document/10089190</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Decoding human visual neural representations is a challenging task with great scientific significance in revealing vision-processing mechanisms and developing brain-like intelligent machines. Most existing methods are difficult to generalize to novel categories that have no corresponding neural data for training. The two main reasons are 1) the under-exploitation of the multimodal semantic knowled...]]></description>
        </item>
        <item>
            <title><![CDATA[Visible and Infrared Image Fusion Using Deep Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10088423</link>
            <guid>https://ieeexplore.ieee.org/document/10088423</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Visible and infrared image fusion (VIF) has attracted a lot of interest in recent years due to its application in many tasks, such as object detection, object tracking, scene segmentation, and crowd counting. In addition to conventional VIF methods, an increasing number of deep learning-based VIF methods have been proposed in the last five years. Different types of methods, such as CNN-based, auto...]]></description>
        </item>
        <item>
            <title><![CDATA[Missingness-Pattern-Adaptive Learning With Incomplete Data]]></title>
            <link>https://ieeexplore.ieee.org/document/10086606</link>
            <guid>https://ieeexplore.ieee.org/document/10086606</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Many real-world problems deal with collections of data with missing values, e.g., RNA sequential analytics, image completion, video processing, etc. Usually, such missing data is a serious impediment to a good learning achievement. Existing methods tend to use a universal model for all incomplete data, resulting in a suboptimal model for each missingness pattern. In this paper, we present a genera...]]></description>
        </item>
        <item>
            <title><![CDATA[CRNet: A Fast Continual Learning Framework With Random Theory]]></title>
            <link>https://ieeexplore.ieee.org/document/10086692</link>
            <guid>https://ieeexplore.ieee.org/document/10086692</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Artificial neural networks are prone to suffer from catastrophic forgetting. Networks trained on something new tend to rapidly forget what was learned previously, a common phenomenon within connectionist models. In this work, we propose an effective and efficient continual learning framework using random theory, together with Bayes&#39; rule, to equip a single model with the ability to learn streaming...]]></description>
        </item>
        <item>
            <title><![CDATA[Automatic Transformation Search Against Deep Leakage from Gradients]]></title>
            <link>https://ieeexplore.ieee.org/document/10086616</link>
            <guid>https://ieeexplore.ieee.org/document/10086616</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Collaborative learning has gained great popularity due to its benefit of data privacy protection: participants can jointly train a Deep Learning model without sharing their training sets. However, recent works discovered that an adversary can fully recover the sensitive training samples from the shared gradients. Such reconstruction attacks pose severe threats to collaborative learning. Hence, eff...]]></description>
        </item>
        <item>
            <title><![CDATA[SDV-LOAM: Semi-Direct Visual-LiDAR Odometry and Mapping]]></title>
            <link>https://ieeexplore.ieee.org/document/10086694</link>
            <guid>https://ieeexplore.ieee.org/document/10086694</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Visual-LiDAR odometry and mapping (V-LOAM), which fuses complementary information of a camera and a LiDAR, is an attractive solution for accurate and robust pose estimation and mapping. However, existing systems could suffer nontrivial tracking errors arising from 1) association between 3D LiDAR points and sparse 2D features (i.e. 3D-2D depth association) and 2) obvious drifts in the vertical dire...]]></description>
        </item>
        <item>
            <title><![CDATA[muxGNN: Multiplex Graph Neural Network for Heterogeneous Graphs]]></title>
            <link>https://ieeexplore.ieee.org/document/10086644</link>
            <guid>https://ieeexplore.ieee.org/document/10086644</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph neural networks (GNNs) have become effective learning techniques for many downstream network mining tasks including node and graph classification, link prediction, and network reconstruction. However, most GNN methods have been developed for homogeneous networks with only a single type of node and edge. In this work we present muxGNN, a multiplex graph neural network for heterogeneous graphs...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised Point Cloud Representation Learning with Deep Neural Networks: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/10086697</link>
            <guid>https://ieeexplore.ieee.org/document/10086697</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Point cloud data have been widely explored due to its superior accuracy and robustness under various adverse situations. Meanwhile, deep neural networks (DNNs) have achieved very impressive success in various applications such as surveillance and autonomous driving. The convergence of point cloud and DNNs has led to many deep point cloud models, largely trained under the supervision of large-scale...]]></description>
        </item>
        <item>
            <title><![CDATA[Efficient Robustness Assessment Via Adversarial Spatial-Temporal Focus on Videos]]></title>
            <link>https://ieeexplore.ieee.org/document/10086664</link>
            <guid>https://ieeexplore.ieee.org/document/10086664</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Adversarial robustness assessment for video recognition models has raised concerns owing to their wide applications on safety-critical tasks. Compared with images, videos have much high dimension, which brings huge computational costs when generating adversarial videos. This is especially serious for the query-based black-box attacks where gradient estimation for the threat models is usually utili...]]></description>
        </item>
        <item>
            <title><![CDATA[Measuring Perceptual Color Differences of Smartphone Photographs]]></title>
            <link>https://ieeexplore.ieee.org/document/10083226</link>
            <guid>https://ieeexplore.ieee.org/document/10083226</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Measuring perceptual color differences (CDs) is of great importance in modern smartphone photography. Despite the long history, most CD measures have been constrained by psychophysical data of homogeneous color patches or a limited number of simplistic natural photographic images. It is thus questionable whether existing CD measures generalize in the age of smartphone photography characterized by ...]]></description>
        </item>
        <item>
            <title><![CDATA[Local-Global Context Aware Transformer for Language-Guided Video Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10083244</link>
            <guid>https://ieeexplore.ieee.org/document/10083244</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We explore the task of language-guided video segmentation (LVS). Previous algorithms mostly adopt 3D CNNs to learn video representation, struggling to capture long-term context and easily suffering from visual-linguistic misalignment. In light of this, we present Locater (local-global context aware Transformer), which augments the Transformer architecture with a finite memory so as to query the en...]]></description>
        </item>
        <item>
            <title><![CDATA[Performance-aware Approximation of Global Channel Pruning for Multitask CNNs]]></title>
            <link>https://ieeexplore.ieee.org/document/10083285</link>
            <guid>https://ieeexplore.ieee.org/document/10083285</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Global channel pruning (GCP) aims to remove a subset of channels (filters) across different layers from a deep model without hurting the performance. Previous works focus on either single task model pruning or simply adapting it to multitask scenario, and still face the following problems when handling multitask pruning: 1) Due to the task mismatch, a well-pruned backbone for classification task f...]]></description>
        </item>
        <item>
            <title><![CDATA[CaCo: Both Positive and Negative Samples are Directly Learnable via Cooperative-adversarial Contrastive Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10083274</link>
            <guid>https://ieeexplore.ieee.org/document/10083274</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[As a representative self-supervised method, contrastive learning has achieved great successes in unsupervised training of representations. It trains an encoder by distinguishing positive samples from negative ones given query anchors. These positive and negative samples play critical roles in defining the objective to learn the discriminative encoder, avoiding it from learning trivial features. Wh...]]></description>
        </item>
        <item>
            <title><![CDATA[Progressive Instance-Aware Feature Learning for Compositional Action Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10082892</link>
            <guid>https://ieeexplore.ieee.org/document/10082892</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In order to enable the model to generalize to unseen “action-objects” (compositional action), previous methods encode multiple pieces of information (i.e., the appearance, position, and identity of visual instances) independently and concatenate them for classification. However, these methods ignore the potential supervisory role of instance information (i.e., position and identity) in the process...]]></description>
        </item>
        <item>
            <title><![CDATA[Diffusion Models in Vision: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/10081412</link>
            <guid>https://ieeexplore.ieee.org/document/10081412</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Denoising diffusion models represent a recent emerging topic in computer vision, demonstrating remarkable results in the area of generative modeling. A diffusion model is a deep generative model that is based on two stages, a forward diffusion stage and a reverse diffusion stage. In the forward diffusion stage, the input data is gradually perturbed over several steps by adding Gaussian noise. In t...]]></description>
        </item>
        <item>
            <title><![CDATA[Extracting Semantic Knowledge from GANs with Unsupervised Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10081465</link>
            <guid>https://ieeexplore.ieee.org/document/10081465</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, unsupervised learning has made impressive progress on various tasks. Despite the dominance of discriminative models, increasing attention is drawn to representations learned by generative models and in particular, Generative Adversarial Networks (GANs). Previous works on the interpretation of GANs reveal that GANs encode semantics in feature maps in a linearly separable form. In this wor...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Learn Task-Adaptive Hyperparameters for Few-Shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10080995</link>
            <guid>https://ieeexplore.ieee.org/document/10080995</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The objective of few-shot learning is to design a system that can adapt to a given task with only few examples while achieving generalization. Model-agnostic meta-learning (MAML), which has recently gained the popularity for its simplicity and flexibility, learns a good initialization for fast adaptation to a task under few-data regime. However, its performance has been relatively limited especial...]]></description>
        </item>
        <item>
            <title><![CDATA[Matrix Completion with Cross-Concentrated Sampling: Bridging Uniform Sampling and CUR Sampling]]></title>
            <link>https://ieeexplore.ieee.org/document/10079176</link>
            <guid>https://ieeexplore.ieee.org/document/10079176</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[While uniform sampling has been widely studied in the matrix completion literature, CUR sampling approximates a low-rank matrix via row and column samples. Unfortunately, both sampling models lack flexibility for various circumstances in real-world applications. In this work, we propose a novel and easy-to-implement sampling strategy, coined Cross-Concentrated Sampling (CCS). By bridging uniform s...]]></description>
        </item>
        <item>
            <title><![CDATA[Robust Face Alignment via Inherent Relation Learning and Uncertainty Estimation]]></title>
            <link>https://ieeexplore.ieee.org/document/10079153</link>
            <guid>https://ieeexplore.ieee.org/document/10079153</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Human tends to locate the facial landmarks with heavy occlusion by their relative position to the easily identified landmarks. The clue is defined as the landmark inherent relation while it is ignored by most existing methods. In this paper, we present Dynamic Sparse Local Patch Transformer (DSLPT), a novel face alignment framework for the inherent relation learning and uncertainty estimation. Unl...]]></description>
        </item>
        <item>
            <title><![CDATA[Training Compact CNNs for Image Classification using Dynamic-coded Filter Fusion]]></title>
            <link>https://ieeexplore.ieee.org/document/10078845</link>
            <guid>https://ieeexplore.ieee.org/document/10078845</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The mainstream approach for filter pruning is usually either to force a hard-coded importance estimation upon a computation-heavy pretrained model to select “important” filters, or to impose a hyperparameter-sensitive sparse constraint on the loss objective to regularize the network training. In this paper, we present a novel filter pruning method, dubbed dynamic-coded filter fusion (DCFF), to der...]]></description>
        </item>
        <item>
            <title><![CDATA[Insights from Generative Modeling for Neural Video Compression]]></title>
            <link>https://ieeexplore.ieee.org/document/10078276</link>
            <guid>https://ieeexplore.ieee.org/document/10078276</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[While recent machine learning research has revealed connections between deep generative models such as VAEs and rate-distortion losses used in learned compression, most of this work has focused on images. In a similar spirit, we view recently proposed neural video coding algorithms through the lens of deep autoregressive and latent variable modeling. We present these codecs as instances of a gener...]]></description>
        </item>
        <item>
            <title><![CDATA[Guaranteed Tensor Recovery Fused Low-rankness and Smoothness]]></title>
            <link>https://ieeexplore.ieee.org/document/10078018</link>
            <guid>https://ieeexplore.ieee.org/document/10078018</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Vast visual data like multi-spectral images and multi-frame videos are essentially with the tensor format. However, due to the defects of signal acquisition equipments, the practically collected tensor data are always with evident degradations like corruptions or missing values. The tensor data recovery task has thus attracted much research attention in recent years. Solving such an ill-posed prob...]]></description>
        </item>
        <item>
            <title><![CDATA[GeoTransformer: Fast and Robust Point Cloud Registration With Geometric Transformer]]></title>
            <link>https://ieeexplore.ieee.org/document/10076895</link>
            <guid>https://ieeexplore.ieee.org/document/10076895</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We study the problem of extracting accurate correspondences for point cloud registration. Recent keypoint-free methods have shown great potential through bypassing the detection of repeatable keypoints which is difficult to do especially in low-overlap scenarios. They seek correspondences over downsampled superpoints, which are then propagated to dense points. Superpoints are matched based on whet...]]></description>
        </item>
        <item>
            <title><![CDATA[Linear Complexity Self-Attention with $3^{\text{rd}}$ Order Polynomials]]></title>
            <link>https://ieeexplore.ieee.org/document/10076897</link>
            <guid>https://ieeexplore.ieee.org/document/10076897</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Self-attention mechanisms and non-local blocks have become crucial building blocks for state-of-the-art neural architectures thanks to their unparalleled ability in capturing long-range dependencies in the input. However their cost is quadratic with the number of spatial positions hence making their use impractical in many real case applications. In this work, we analyze these methods through a po...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised 3D Pose Transfer With Cross Consistency and Dual Reconstruction]]></title>
            <link>https://ieeexplore.ieee.org/document/10076900</link>
            <guid>https://ieeexplore.ieee.org/document/10076900</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The goal of 3D pose transfer is to transfer the pose from the source mesh to the target mesh while preserving the identity information (e.g., face, body shape) of the target mesh. Deep learning-based methods improved the efficiency and performance of 3D pose transfer. However, most of them are trained under the supervision of the ground truth, whose availability is limited in real-world scenarios....]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Rates for Nonconvex Pairwise Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10076835</link>
            <guid>https://ieeexplore.ieee.org/document/10076835</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Pairwise learning is receiving increasing attention since it covers many important machine learning tasks, e.g., metric learning, AUC maximization, and ranking. Investigating the generalization behavior of pairwise learning is thus of great significance. However, existing generalization analysis mainly focuses on the convex objective functions, leaving the nonconvex pairwise learning far less expl...]]></description>
        </item>
        <item>
            <title><![CDATA[CoReS: Compatible Representations via Stationarity]]></title>
            <link>https://ieeexplore.ieee.org/document/10077426</link>
            <guid>https://ieeexplore.ieee.org/document/10077426</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Compatible features enable the direct comparison of old and new learned features allowing to use them interchangeably over time. In visual search systems, this eliminates the need to extract new features from the gallery-set when the representation model is upgraded with novel data. This has a big value in real applications as re-indexing the gallery-set can be computationally expensive when the g...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised Domain Adaptation of Object Detectors: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/10075484</link>
            <guid>https://ieeexplore.ieee.org/document/10075484</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent advances in deep learning have led to the development of accurate and efficient models for various computer vision applications such as classification, segmentation, and detection. However, learning highly accurate models relies on the availability of large-scale annotated datasets. Due to this, model performance drops drastically when evaluated on label-scarce datasets having visually dist...]]></description>
        </item>
        <item>
            <title><![CDATA[Temporal Sentence Grounding in Videos: A Survey and Future Directions]]></title>
            <link>https://ieeexplore.ieee.org/document/10075491</link>
            <guid>https://ieeexplore.ieee.org/document/10075491</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Temporal sentence grounding in videos (TSGV), a.k.a. natural language video localization (NLVL) or video moment retrieval (VMR), aims to retrieve a temporal moment that semantically corresponds to a language query from an untrimmed video. Connecting computer vision and natural language, TSGV has drawn significant attention from researchers in both communities. This survey attempts to provide a sum...]]></description>
        </item>
        <item>
            <title><![CDATA[Random Cycle Loss and Its Application to Voice Conversion]]></title>
            <link>https://ieeexplore.ieee.org/document/10073591</link>
            <guid>https://ieeexplore.ieee.org/document/10073591</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Speech disentanglement aims to decompose independent causal factors of speech signals into separate codes. Perfect disentanglement benefits to a broad range of speech processing tasks. This paper presents a simple but effective disentanglement approach based on cycle consistency loss and random factor substitution. This leads to a novel random cycle (RC) loss that enforces analysis-and-resynthesis...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised Learning of Graph Matching With Mixture of Modes Via Discrepancy Minimization]]></title>
            <link>https://ieeexplore.ieee.org/document/10073537</link>
            <guid>https://ieeexplore.ieee.org/document/10073537</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph matching (GM) has been a long-standing combinatorial problem due to its NP-hard nature. Recently (deep) learning-based approaches have shown their superiority over the traditional solvers while the methods are almost based on supervised learning which can be expensive or even impractical. We develop a unified unsupervised framework from matching two graphs to multiple graphs, without corresp...]]></description>
        </item>
        <item>
            <title><![CDATA[DAQE: Enhancing the Quality of Compressed Images by Exploiting the Inherent Characteristic of Defocus]]></title>
            <link>https://ieeexplore.ieee.org/document/10073543</link>
            <guid>https://ieeexplore.ieee.org/document/10073543</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image defocus is inherent in the physics of image formation caused by the optical aberration of lenses, providing plentiful information on image quality. Unfortunately, existing quality enhancement approaches for compressed images neglect the inherent characteristic of defocus, resulting in inferior performance. This paper finds that in compressed images, significantly defocused regions have bette...]]></description>
        </item>
        <item>
            <title><![CDATA[Online Knowledge Distillation Via Mutual Contrastive Learning for Visual Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10073628</link>
            <guid>https://ieeexplore.ieee.org/document/10073628</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The teacher-free online Knowledge Distillation (KD) aims to train an ensemble of multiple student models collaboratively and distill knowledge from each other. Although existing online KD methods achieve desirable performance, they often focus on class probabilities as the core knowledge type, ignoring the valuable feature representational information. We present a Mutual Contrastive Learning (MCL...]]></description>
        </item>
        <item>
            <title><![CDATA[Brain-Machine Coupled Learning Method for Facial Emotion Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10073607</link>
            <guid>https://ieeexplore.ieee.org/document/10073607</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Neural network models of machine learning have shown promising prospects for visual tasks, such as facial emotion recognition (FER). However, the generalization of the model trained from a dataset with a few samples is limited. Unlike the machine, the human brain can effectively realize the required information from a few samples to complete the visual tasks. To learn the generalization ability of...]]></description>
        </item>
        <item>
            <title><![CDATA[Affine Subspace Robust Low-Rank Self-Representation: from Matrix to Tensor]]></title>
            <link>https://ieeexplore.ieee.org/document/10070813</link>
            <guid>https://ieeexplore.ieee.org/document/10070813</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Low-rank self-representation based subspace learning has confirmed its great effectiveness in a broad range of applications. Nevertheless, existing studies mainly focus on exploring the global linear subspace structure, and cannot commendably handle the case where the samples approximately (i.e., the samples contain data errors) lie in several more general affine subspaces. To overcome this drawba...]]></description>
        </item>
        <item>
            <title><![CDATA[When Object Detection Meets Knowledge Distillation: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/10070820</link>
            <guid>https://ieeexplore.ieee.org/document/10070820</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Object detection (OD) is a basic computer vision task. To date, there have been many OD algorithms or models for solving different problems. The performance of the current models has gradually improved and their applications have expanded. However, the models have also become more complex, with larger numbers of parameters, making them unsuitable for industrial applications. The knowledge distilla...]]></description>
        </item>
        <item>
            <title><![CDATA[Physics-Informed Guided Disentanglement In generative networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10070869</link>
            <guid>https://ieeexplore.ieee.org/document/10070869</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image-to-image translation (i2i) networks suffer from entanglement effects in presence of physics-related phenomena in target domain (such as occlusions, fog, etc), lowering altogether the translation quality, controllability and variability. In this paper, we propose a general framework to disentangle visual traits in target images. Primarily, we build upon collection of simple physics models, gu...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning with Asymmetric Kernels: Least Squares and Feature Interpretation]]></title>
            <link>https://ieeexplore.ieee.org/document/10070836</link>
            <guid>https://ieeexplore.ieee.org/document/10070836</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Asymmetric kernels naturally exist in real life, e.g., for conditional probability and directed graphs. However, most of the existing kernel-based learning methods require kernels to be symmetric, which prevents the use of asymmetric kernels. This paper addresses the asymmetric kernel-based learning in the framework of the least squares support vector machine named AsK-LS, resulting in the first c...]]></description>
        </item>
        <item>
            <title><![CDATA[Graph Theory Based Large-Scale Machine Learning with Multi-Dimensional Constrained Optimization Approaches for Exact Epidemiological Modelling of Pandemic Diseases]]></title>
            <link>https://ieeexplore.ieee.org/document/10068311</link>
            <guid>https://ieeexplore.ieee.org/document/10068311</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multi-dimensional prediction models of the pandemic diseases should be constructed in a way to reflect their peculiar epidemiological characters. In this paper, a graph theory-based constrained multi-dimensional (CM) mathematical and meta-heuristic algorithms (MA) are formed to learn the unknown parameters of a large-scale epidemiological model. The specified parameter signs and the coupling param...]]></description>
        </item>
        <item>
            <title><![CDATA[Fast and Informative Model Selection using Learning Curve Cross-Validation]]></title>
            <link>https://ieeexplore.ieee.org/document/10064171</link>
            <guid>https://ieeexplore.ieee.org/document/10064171</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Common cross-validation (CV) methods like k-fold cross-validation or Monte Carlo cross-validation estimate the predictive performance of a learner by repeatedly training it on a large portion of the given data and testing it on the remaining data. These techniques have two major drawbacks. First, they can be unnecessarily slow on large datasets. Second, beyond an estimation of the final performanc...]]></description>
        </item>
        <item>
            <title><![CDATA[Free-HeadGAN: Neural Talking Head Synthesis with Explicit Gaze Control]]></title>
            <link>https://ieeexplore.ieee.org/document/10061572</link>
            <guid>https://ieeexplore.ieee.org/document/10061572</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present Free-HeadGAN, a person-generic neural talking head synthesis system. We show that modeling faces with sparse 3D facial landmarks is sufficient for achieving state-of-the-art generative performance, without relying on strong statistical priors of the face, such as 3D Morphable Models. Apart from 3D pose and facial expressions, our method is capable of fully transferring the eye gaze, fro...]]></description>
        </item>
        <item>
            <title><![CDATA[Jointly Defending DeepFake Manipulation and Adversarial Attack using Decoy Mechanism]]></title>
            <link>https://ieeexplore.ieee.org/document/10061274</link>
            <guid>https://ieeexplore.ieee.org/document/10061274</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Highly realistic imaging and video synthesis have become possible and relatively simple tasks with the rapid growth of generative adversarial networks (GANs). GAN-related applications, such as DeepFake image and video manipulation and adversarial attacks, have been used to disrupt and confound the truth in images and videos over social media. DeepFake technology aims to synthesize high visual qual...]]></description>
        </item>
        <item>
            <title><![CDATA[Contrastive Multi-View Kernel Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10061269</link>
            <guid>https://ieeexplore.ieee.org/document/10061269</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Kernel method is a proven technique in multi-view learning. It implicitly defines a Hilbert space where samples can be linearly separated. Most kernel-based multi-view learning algorithms compute a kernel function aggregating and compressing the views into a single kernel. However, existing approaches compute the kernels independently for each view. This ignores complementary information across vi...]]></description>
        </item>
        <item>
            <title><![CDATA[Clustered Task-Aware Meta-Learning by Learning From Learning Paths]]></title>
            <link>https://ieeexplore.ieee.org/document/10061493</link>
            <guid>https://ieeexplore.ieee.org/document/10061493</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[To enable effective learning of new tasks with only a few examples, meta-learning acquires common knowledge from the existing tasks with a globally shared meta-learner. To further address the problem of task heterogeneity, recent developments balance between customization and generalization by incorporating task clustering to generate task-aware modulation to be applied to the global meta-learner....]]></description>
        </item>
        <item>
            <title><![CDATA[Persistent Homology with Improved Locality Information for more Effective Delineation]]></title>
            <link>https://ieeexplore.ieee.org/document/10057132</link>
            <guid>https://ieeexplore.ieee.org/document/10057132</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Persistent Homology (PH) has been successfully used to train networks to detect curvilinear structures and to improve the topological quality of their results. However, existing methods are very global and ignore the location of topological features. In this paper, we remedy this by introducing a new filtration function that fuses two earlier approaches: thresholding-based filtration, previously u...]]></description>
        </item>
        <item>
            <title><![CDATA[Low-Rank Matrix Completion Theory via Plücker Coordinates]]></title>
            <link>https://ieeexplore.ieee.org/document/10056236</link>
            <guid>https://ieeexplore.ieee.org/document/10056236</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Despite the popularity of low-rank matrix completion, the majority of its theory has been developed under the assumption of random observation patterns, whereas very little is known about the practically relevant case of non-random patterns. Specifically, a fundamental yet largely open question is to describe patterns that allow for unique or finitely many completions. This paper provides three su...]]></description>
        </item>
        <item>
            <title><![CDATA[Normalization Techniques in Training DNNs: Methodology, Analysis and Application]]></title>
            <link>https://ieeexplore.ieee.org/document/10056354</link>
            <guid>https://ieeexplore.ieee.org/document/10056354</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Normalization techniques are essential for accelerating the training and improving the generalization of deep neural networks (DNNs), and have successfully been used in various applications. This paper reviews and comments on the past, present and future of normalization methods in the context of DNN training. We provide a unified picture of the main motivation behind different approaches from the...]]></description>
        </item>
        <item>
            <title><![CDATA[Augmentation Pathways Network for Visual Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10056356</link>
            <guid>https://ieeexplore.ieee.org/document/10056356</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Data augmentation is practically helpful for visual recognition, especially at the time of data scarcity. However, such success is only limited to quite a few light augmentations (e.g., random crop, flip). Heavy augmentations are either unstable or show adverse effects during training, owing to the big gap between the original and augmented images. This paper introduces a novel network design, not...]]></description>
        </item>
        <item>
            <title><![CDATA[PDC-Net+: Enhanced Probabilistic Dense Correspondence Network]]></title>
            <link>https://ieeexplore.ieee.org/document/10054148</link>
            <guid>https://ieeexplore.ieee.org/document/10054148</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Establishing robust and accurate correspondences between a pair of images is a long-standing computer vision problem with numerous applications. While classically dominated by sparse methods, emerging dense approaches offer a compelling alternative paradigm that avoids the keypoint detection step. However, dense flow estimation is often inaccurate in the case of large displacements, occlusions, or...]]></description>
        </item>
        <item>
            <title><![CDATA[Personalized Latent Structure Learning for Recommendation]]></title>
            <link>https://ieeexplore.ieee.org/document/10053625</link>
            <guid>https://ieeexplore.ieee.org/document/10053625</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In recommender systems, users&#39; behavior data are driven by the interactions of user-item latent factors. To improve recommendation effectiveness and robustness, recent advances focus on latent factor disentanglement via variational inference. Despite significant progress, uncovering the underlying interactions, i.e., dependencies of latent factors, remains largely neglected by the literature. To b...]]></description>
        </item>
        <item>
            <title><![CDATA[Localization Distillation for Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10052761</link>
            <guid>https://ieeexplore.ieee.org/document/10052761</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Previous knowledge distillation (KD) methods for object detection mostly focus on feature imitation instead of mimicking the prediction logits due to its inefficiency in distilling the localization information. In this paper, we investigate whether logit mimicking always lags behind feature imitation. Towards this goal, we first present a novel localization distillation (LD) method which can effic...]]></description>
        </item>
        <item>
            <title><![CDATA[Adaptive Search-and-Training for Robust and Efficient Network Pruning]]></title>
            <link>https://ieeexplore.ieee.org/document/10052756</link>
            <guid>https://ieeexplore.ieee.org/document/10052756</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Both network pruning and neural architecture search (NAS) can be interpreted as techniques to automate the design and optimization of artificial neural networks. In this paper, we challenge the conventional wisdom of training before pruning by proposing a joint search-and-training approach to learn a compact network directly from scratch. Using pruning as a search strategy, we advocate three new i...]]></description>
        </item>
        <item>
            <title><![CDATA[ADPL: Adaptive Dual Path Learning for Domain Adaptation of Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10050808</link>
            <guid>https://ieeexplore.ieee.org/document/10050808</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[To alleviate the need for large-scale pixel-wise annotations, domain adaptation for semantic segmentation trains segmentation models on synthetic data (source) with computer-generated annotations, which can be then generalized to segment realistic images (target). Recently, self-supervised learning (SSL) with a combination of image-to-image translation shows great effectiveness in adaptive segment...]]></description>
        </item>
        <item>
            <title><![CDATA[Few-Shot Drug Synergy Prediction With a Prior-Guided Hypernetwork Architecture]]></title>
            <link>https://ieeexplore.ieee.org/document/10050784</link>
            <guid>https://ieeexplore.ieee.org/document/10050784</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Predicting drug synergy is critical to tailoring feasible drug combination treatment regimens for cancer patients. However, most of the existing computational methods only focus on data-rich cell lines, and hardly work on data-poor cell lines. To this end, here we proposed a novel few-shot drug synergy prediction method (called HyperSynergy) for data-poor cell lines by designing a prior-guided Hyp...]]></description>
        </item>
        <item>
            <title><![CDATA[Fast and Robust Non-Rigid Registration Using Accelerated Majorization-Minimization]]></title>
            <link>https://ieeexplore.ieee.org/document/10049724</link>
            <guid>https://ieeexplore.ieee.org/document/10049724</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Non-rigid 3D registration, which deforms a source 3D shape in a non-rigid way to align with a target 3D shape, is a classical problem in computer vision. Such problems can be challenging because of imperfect data (noise, outliers and partial overlap) and high degrees of freedom. Existing methods typically adopt the $\ell _{p}$ type robust norm to measure the alignment error and regularize the smoo...]]></description>
        </item>
        <item>
            <title><![CDATA[Consistent 3D Hand Reconstruction in Video via Self-Supervised Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10050006</link>
            <guid>https://ieeexplore.ieee.org/document/10050006</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present a method for reconstructing accurate and consistent 3D hands from a monocular video. We observe that the detected 2D hand keypoints and the image texture provide important cues about the geometry and texture of the 3D hand, which can reduce or even eliminate the requirement on 3D hand annotation. Accordingly, in this work, we propose $\mathrm{{S}^{2}HAND}$, a self-supervised 3D hand rec...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Augment Poses for 3D Human Pose Estimation in Images and Videos]]></title>
            <link>https://ieeexplore.ieee.org/document/10050391</link>
            <guid>https://ieeexplore.ieee.org/document/10050391</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Existing 3D human pose estimation methods often suffer inferior generalization performance to new datasets, largely due to the limited diversity of 2D-3D pose pairs in the training data. To address this problem, we present PoseAug, a novel auto-augmentation framework that learns to augment the available training poses towards greater diversity and thus enhances the generalization power of the trai...]]></description>
        </item>
        <item>
            <title><![CDATA[Latent Class-Conditional Noise Model]]></title>
            <link>https://ieeexplore.ieee.org/document/10049697</link>
            <guid>https://ieeexplore.ieee.org/document/10049697</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Learning with noisy labels has become imperative in the Big Data era, which saves expensive human labors on accurate annotations. Previous noise-transition-based methods have achieved theoretically-grounded performance under the Class-Conditional Noise model (CCN). However, these approaches builds upon an ideal but impractical anchor set available to pre-estimate the noise transition. Even though ...]]></description>
        </item>
        <item>
            <title><![CDATA[Cross-Modal Retrieval with Partially Mismatched Pairs]]></title>
            <link>https://ieeexplore.ieee.org/document/10050111</link>
            <guid>https://ieeexplore.ieee.org/document/10050111</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we study a challenging but less-touched problem in cross-modal retrieval, i.e., partially mismatched pairs (PMPs). Specifically, in real-world scenarios, a huge number of multimedia data (e.g., the Conceptual Captions dataset) are collected from the Internet, and thus it is inevitable to wrongly treat some irrelevant cross-modal pairs as matched. Undoubtedly, such a PMP problem will...]]></description>
        </item>
        <item>
            <title><![CDATA[Variational Nested Dropout]]></title>
            <link>https://ieeexplore.ieee.org/document/10049079</link>
            <guid>https://ieeexplore.ieee.org/document/10049079</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Nested dropout  is a variant of dropout operation that is able to order network parameters or features based on the pre-defined importance during training. It has been explored for: I. Constructing nested nets [11], [10]: the nested nets are neural networks whose architectures can be adjusted instantly during testing time, e.g., based on computational constraints. The nested dropout implicitly ran...]]></description>
        </item>
        <item>
            <title><![CDATA[A Survey on Label-Efficient Deep Image Segmentation: Bridging the Gap Between Weak Supervision and Dense Prediction]]></title>
            <link>https://ieeexplore.ieee.org/document/10048555</link>
            <guid>https://ieeexplore.ieee.org/document/10048555</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The rapid development of deep learning has made a great progress in image segmentation, one of the fundamental tasks of computer vision. However, the current segmentation algorithms mostly rely on the availability of pixel-level annotations, which are often expensive, tedious, and laborious. To alleviate this burden, the past years have witnessed an increasing attention in building label-efficient...]]></description>
        </item>
        <item>
            <title><![CDATA[Occlusion-Aware Instance Segmentation Via BiLayer Network Architectures]]></title>
            <link>https://ieeexplore.ieee.org/document/10048550</link>
            <guid>https://ieeexplore.ieee.org/document/10048550</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Segmenting highly-overlapping image objects is challenging, because there is typically no distinction between real object contours and occlusion boundaries on images. Unlike previous instance segmentation methods, we model image formation as a composition of two overlapping layers, and propose Bilayer Convolutional Network (BCNet), where the top layer detects occluding objects (occluders) and the ...]]></description>
        </item>
        <item>
            <title><![CDATA[Handling Open-set Noise and Novel Target Recognition in Domain Adaptive Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10048580</link>
            <guid>https://ieeexplore.ieee.org/document/10048580</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper studies a practical domain adaptive (DA) semantic segmentation problem where only pseudo-labeled target data is accessible through a black-box model. Due to the domain gap and label shift between two domains, pseudo-labeled target data contains mixed closed-set and open-set label noises. In this paper, we propose a simplex noise transition matrix (SimT) to model the mixed noise distribu...]]></description>
        </item>
        <item>
            <title><![CDATA[Implicit Neural Representations with Structured Latent Codes for Human Body Modeling]]></title>
            <link>https://ieeexplore.ieee.org/document/10045794</link>
            <guid>https://ieeexplore.ieee.org/document/10045794</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper addresses the challenge of novel view synthesis for a human performer from a very sparse set of camera views. Some recent works have shown that learning implicit neural representations of 3D scenes achieves remarkable view synthesis quality given dense input views. However, the representation learning will be ill-posed if the views are highly sparse. To solve this ill-posed problem, our...]]></description>
        </item>
        <item>
            <title><![CDATA[Multifractal Characterization of Texts for Pattern Recognition: on the Complexity of Morphological Structures in Modern and Ancient Languages]]></title>
            <link>https://ieeexplore.ieee.org/document/10045797</link>
            <guid>https://ieeexplore.ieee.org/document/10045797</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The study of languages&#39; structure and their organization in a set of well-defined relation schemes is a delicate matter. In the last decades, the convergence of traditional conflicting views by linguists is supported by an interdisciplinary approach that involves not only genetics or bio-archelogy but nowadays even the science of complexity. In light of this new and useful approach, this study pro...]]></description>
        </item>
        <item>
            <title><![CDATA[Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud Analysis]]></title>
            <link>https://ieeexplore.ieee.org/document/10044160</link>
            <guid>https://ieeexplore.ieee.org/document/10044160</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Point clouds are characterized by irregularity and unstructuredness, which pose challenges in efficient data exploitation and discriminative feature extraction. In this paper, we present an unsupervised deep neural architecture called Flattening-Net to represent irregular 3D point clouds of arbitrary geometry and topology as a completely regular 2D point geometry image (PGI) structure, in which co...]]></description>
        </item>
        <item>
            <title><![CDATA[RoReg: Pairwise Point Cloud Registration with Oriented Descriptors and Local Rotations]]></title>
            <link>https://ieeexplore.ieee.org/document/10044259</link>
            <guid>https://ieeexplore.ieee.org/document/10044259</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present RoReg, a novel point cloud registration framework that fully exploits oriented descriptors and estimated local rotations in the whole registration pipeline. Previous methods mainly focus on extracting rotation-invariant descriptors for registration but unanimously neglect the orientations of descriptors. In this paper, we show that the oriented descriptors and the estimated local rotati...]]></description>
        </item>
        <item>
            <title><![CDATA[MILO: Multi-bounce Inverse Rendering for Indoor Scene with Light-emitting Objects]]></title>
            <link>https://ieeexplore.ieee.org/document/10043749</link>
            <guid>https://ieeexplore.ieee.org/document/10043749</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, many advances in inverse rendering are achieved by high-dimensional lighting representations and differentiable rendering. However, multi-bounce lighting effects can hardly be handled correctly in scene editing using high-dimensional lighting representations, and light source model deviation and ambiguities exist in differentiable rendering methods. These problems limit the applications ...]]></description>
        </item>
        <item>
            <title><![CDATA[Self-supervised Video-centralised Transformer for Video Face Clustering]]></title>
            <link>https://ieeexplore.ieee.org/document/10042051</link>
            <guid>https://ieeexplore.ieee.org/document/10042051</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper presents a novel method for face clustering in videos using a video-centralised transformer. Previous works often employed contrastive learning to learn frame-level representation and used average pooling to aggregate the features along the temporal dimension. This approach may not fully capture the complicated video dynamics. In addition, despite the recent progress in video-based cont...]]></description>
        </item>
        <item>
            <title><![CDATA[Hitchhiker's Guide to Super-Resolution: Introduction and Recent Advances]]></title>
            <link>https://ieeexplore.ieee.org/document/10041995</link>
            <guid>https://ieeexplore.ieee.org/document/10041995</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[With the advent of Deep Learning (DL), Super-Resolution (SR) has also become a thriving research area. However, despite promising results, the field still faces challenges that require further research, e.g., allowing flexible upsampling, more effective loss functions, and better evaluation metrics. We review the domain of SR in light of recent advances and examine state-of-the-art models such as ...]]></description>
        </item>
        <item>
            <title><![CDATA[From Instance to Metric Calibration: A Unified Framework for Open-World Few-Shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10041935</link>
            <guid>https://ieeexplore.ieee.org/document/10041935</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Robust few-shot learning (RFSL), which aims to address noisy labels in few-shot learning, has recently gained considerable attention. Existing RFSL methods are based on the assumption that the noise comes from known classes (in-domain), which is inconsistent with many real-world scenarios where the noise does not belong to any known classes (out-of-domain). We refer to this more complex scenario a...]]></description>
        </item>
        <item>
            <title><![CDATA[Tractable Maximum Likelihood Estimation for Latent Structure Influence Models with Applications to EEG & ECoG processing]]></title>
            <link>https://ieeexplore.ieee.org/document/10042041</link>
            <guid>https://ieeexplore.ieee.org/document/10042041</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Brain signals are nonlinear and nonstationary time series, which provide information about spatiotemporal patterns of electrical activity in the brain. CHMMs are suitable tools for modeling multi-channel time-series dependent on both time and space, but state-space parameters grow exponentially with the number of channels. To cope with this limitation, we consider the influence model as the intera...]]></description>
        </item>
        <item>
            <title><![CDATA[Video Transformers: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/10041724</link>
            <guid>https://ieeexplore.ieee.org/document/10041724</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Transformer models have shown great success handling long-range interactions, making them a promising tool for modeling video. However, they lack inductive biases and scale quadratically with input length. These limitations are further exacerbated when dealing with the high dimensionality introduced by the temporal dimension. While there are surveys analyzing the advances of Transformers for visio...]]></description>
        </item>
        <item>
            <title><![CDATA[Image-to-Character-to-Word Transformers for Accurate Scene Text Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10041804</link>
            <guid>https://ieeexplore.ieee.org/document/10041804</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Leveraging the advances of natural language processing, most recent scene text recognizers adopt an encoder-decoder architecture where text images are first converted to representative features and then a sequence of characters via ‘sequential decoding’. However, scene text images suffer from rich noises of different sources such as complex background and geometric distortions which often confuse ...]]></description>
        </item>
        <item>
            <title><![CDATA[Contextual Instance Decoupling for Instance-Level Human Analysis]]></title>
            <link>https://ieeexplore.ieee.org/document/10040902</link>
            <guid>https://ieeexplore.ieee.org/document/10040902</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[One fundamental challenge of instance-level human analysis is to decouple instances in crowded scenes, where multiple persons are overlapped with each other. This paper proposes the Contextual Instance Decoupling (CID), which presents a new pipeline of decoupling persons for multi-person instance-level analysis. Instead of relying on person bounding boxes to spatially differentiate persons, CID de...]]></description>
        </item>
        <item>
            <title><![CDATA[Neural Belief Propagation for Scene Graph Generation]]></title>
            <link>https://ieeexplore.ieee.org/document/10040751</link>
            <guid>https://ieeexplore.ieee.org/document/10040751</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Scene graph generation aims to interpret an input image by explicitly modelling the objects contained therein and their relationships. In existing methods the problem is predominantly solved by message passing neural network models. Unfortunately, in such models, the variational distributions generally ignore the structural dependencies among the output variables, and most of the scoring functions...]]></description>
        </item>
        <item>
            <title><![CDATA[Coarse-to-fine Disentangling Demoiréing Framework for Recaptured Screen Images]]></title>
            <link>https://ieeexplore.ieee.org/document/10040914</link>
            <guid>https://ieeexplore.ieee.org/document/10040914</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Removing the undesired moiré patterns from images capturing the contents displayed on screens is of increasing research interest, as the need for recording and sharing the instant information conveyed by the screens is growing. Previous demoiréing methods provide limited investigations into the formation process of moiré patterns to exploit moiré-specific priors for guiding the learning of demoiré...]]></description>
        </item>
        <item>
            <title><![CDATA[Asymmetric Loss Functions for Noise-Tolerant Learning: Theory and Applications]]></title>
            <link>https://ieeexplore.ieee.org/document/10039708</link>
            <guid>https://ieeexplore.ieee.org/document/10039708</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Supervised deep learning has achieved tremendous success in many computer vision tasks, which however is prone to overfit noisy labels. To mitigate the undesirable influence of noisy labels, robust loss functions offer a feasible approach to achieve noise-tolerant learning. In this work, we systematically study the problem of noise-tolerant learning with respect to both classification and regressi...]]></description>
        </item>
        <item>
            <title><![CDATA[SequenceMorph: A Unified Unsupervised Learning Framework for Motion Tracking on Cardiac Image Sequences]]></title>
            <link>https://ieeexplore.ieee.org/document/10039678</link>
            <guid>https://ieeexplore.ieee.org/document/10039678</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Modern medical imaging techniques, such as ultrasound (US) and cardiac magnetic resonance (MR) imaging, have enabled the evaluation of myocardial deformation directly from an image sequence. While many traditional cardiac motion tracking methods have been developed for the automated estimation of the myocardial wall deformation, they are not widely used in clinical diagnosis, due to their lack of ...]]></description>
        </item>
        <item>
            <title><![CDATA[Conformer: Local Features Coupling Global Representations for Recognition and Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10040235</link>
            <guid>https://ieeexplore.ieee.org/document/10040235</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[With convolution operations, Convolutional Neural Networks (CNNs) are good at extracting local features but experience difficulty to capture global representations. With cascaded self-attention modules, vision transformers can capture long-distance feature dependencies but unfortunately deteriorate local feature details. In this paper, we propose a hybrid network structure, termed Conformer, to ta...]]></description>
        </item>
        <item>
            <title><![CDATA[Cascaded Deep Video Deblurring Using Temporal Sharpness Prior and Non-local Spatial-Temporal Similarity]]></title>
            <link>https://ieeexplore.ieee.org/document/10039490</link>
            <guid>https://ieeexplore.ieee.org/document/10039490</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present compact and effective deep convolutional neural networks (CNNs) by exploring properties of videos for video deblurring. Motivated by the non-uniform blur property that not all the pixels of the frames are blurry, we develop a CNN to integrate a temporal sharpness prior (TSP) for removing blur in videos. The TSP exploits sharp pixels from adjacent frames to facilitate the CNN for better ...]]></description>
        </item>
        <item>
            <title><![CDATA[Salvage of Supervision in Weakly Supervised Object Detection and Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10039501</link>
            <guid>https://ieeexplore.ieee.org/document/10039501</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Weakly supervised vision tasks, including detection and segmentation, have attracted much attention in the vision community recently. However, the lack of detailed and precise annotations in the weakly supervised case leads to a large accuracy gap between weakly- and fully-supervised methods. In this paper, we propose a new framework, Salvage of Supervision (SoS), with the key idea being to effect...]]></description>
        </item>
        <item>
            <title><![CDATA[Federated Learning via Inexact ADMM]]></title>
            <link>https://ieeexplore.ieee.org/document/10040221</link>
            <guid>https://ieeexplore.ieee.org/document/10040221</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[One of the crucial issues in federated learning is how to develop efficient optimization algorithms. Most of the current ones require full device participation and/or impose strong assumptions for convergence. Different from the widely-used gradient descent-based algorithms, in this paper, we develop an inexact alternating direction method of multipliers (ADMM), which is both computation- and comm...]]></description>
        </item>
        <item>
            <title><![CDATA[Properties of Standard and Sketched Kernel Fisher Discriminant]]></title>
            <link>https://ieeexplore.ieee.org/document/10038534</link>
            <guid>https://ieeexplore.ieee.org/document/10038534</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Kernel Fisher discriminant (KFD) is a popular tool as a nonlinear extension of Fisher&#39;s linear discriminant, based on the use of the kernel trick. However, its asymptotic properties are still rarely studied. We first present an operator-theoretical formulation of KFD which elucidates the population target of the estimation problem. Convergence of the KFD solution to its population target is then e...]]></description>
        </item>
        <item>
            <title><![CDATA[Content-aware Warping for View Synthesis]]></title>
            <link>https://ieeexplore.ieee.org/document/10038566</link>
            <guid>https://ieeexplore.ieee.org/document/10038566</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Existing image-based rendering methods usually adopt depth-based image warping operation to synthesize novel views. In this paper, we reason the essential limitations of the traditional warping operation to be the limited neighborhood and only distance-based interpolation weights. To this end, we propose content-aware warping, which adaptively learns the interpolation weights for pixels of a relat...]]></description>
        </item>
        <item>
            <title><![CDATA[Hybrid High Dynamic Range Imaging fusing Neuromorphic and Conventional Images]]></title>
            <link>https://ieeexplore.ieee.org/document/10036136</link>
            <guid>https://ieeexplore.ieee.org/document/10036136</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Reconstruction of high dynamic range image from a single low dynamic range image captured by a conventional RGB camera, which suffers from over- or under-exposure, is an ill-posed problem. In contrast, recent neuromorphic cameras like event camera and spike camera can record high dynamic range scenes in the form of intensity maps, but with much lower spatial resolution and no color information. In...]]></description>
        </item>
        <item>
            <title><![CDATA[Continual Image Deraining with Hypergraph Convolutional Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10035447</link>
            <guid>https://ieeexplore.ieee.org/document/10035447</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image deraining is a challenging task since rain streaks have the characteristics of spatially long structure and complex diversity. Existing deep learning-based methods mainly construct the deraining networks by stacking vanilla convolutional layers with local relations, and can only handle a single dataset due to the catastrophic forgetting, resulting in a limited performance and insufficient ad...]]></description>
        </item>
        <item>
            <title><![CDATA[A Generalized Explanation Framework for Visualization of Deep Learning Model Predictions]]></title>
            <link>https://ieeexplore.ieee.org/document/10034989</link>
            <guid>https://ieeexplore.ieee.org/document/10034989</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Attribution-based explanations are popular in computer vision but of limited use for fine-grained classification problems typical of expert domains, where classes differ by subtle details. In these domains, users also seek understanding of “why” a class was chosen and “why not” an alternative class. A new GenerAlized expLanatiOn fRamEwork (GALORE) is proposed to satisfy all these requirements, by ...]]></description>
        </item>
        <item>
            <title><![CDATA[DeepEIT: Deep Image Prior Enabled Electrical Impedance Tomography]]></title>
            <link>https://ieeexplore.ieee.org/document/10034853</link>
            <guid>https://ieeexplore.ieee.org/document/10034853</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Neural networks (NNs) have been widely applied in tomographic imaging through data-driven training and image processing. One of the main challenges in using NNs in real medical imaging is the requirement of massive amounts of training data which are not always available in clinical practice. In this paper, we demonstrate that, on the contrary, one can directly execute image reconstruction using NN...]]></description>
        </item>
        <item>
            <title><![CDATA[Attention Spiking Neural Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10032591</link>
            <guid>https://ieeexplore.ieee.org/document/10032591</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Brain-inspired spiking neural networks (SNNs) are becoming a promising energy-efficient alternative to traditional artificial neural networks (ANNs). However, the performance gap between SNNs and ANNs has been a significant hindrance to deploying SNNs ubiquitously. To leverage the full potential of SNNs, in this paper we study the attention mechanisms, which can help human focus on important infor...]]></description>
        </item>
        <item>
            <title><![CDATA[SS-TBN: A Semi-Supervised Tri-Branch Network for COVID-19 Screening and Lesion Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10032636</link>
            <guid>https://ieeexplore.ieee.org/document/10032636</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Insufficient annotated data and minor lung lesions pose big challenges for computed tomography (CT)-aided automatic COVID-19 diagnosis at an early outbreak stage. To address this issue, we propose a Semi-Supervised Tri-Branch Network (SS-TBN). First, we develop a joint TBN model for dual-task application scenarios of image segmentation and classification such as CT-based COVID-19 diagnosis, in whi...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Super-Resolve Blurry Images With Events]]></title>
            <link>https://ieeexplore.ieee.org/document/10029887</link>
            <guid>https://ieeexplore.ieee.org/document/10029887</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Super-Resolution from a single motion Blurred image (SRB) is a severely ill-posed problem due to the joint degradation of motion blurs and low spatial resolution. In this paper, we employ events to alleviate the burden of SRB and propose an Event-enhanced SRB (E-SRB) algorithm, which can generate a sequence of sharp and clear images with High Resolution (HR) from a single blurry image with Low Res...]]></description>
        </item>
        <item>
            <title><![CDATA[Differentiable Multi-Granularity Human Parsing]]></title>
            <link>https://ieeexplore.ieee.org/document/10032235</link>
            <guid>https://ieeexplore.ieee.org/document/10032235</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this work, we study the challenging problem of instance-aware human body part parsing. We introduce a new bottom-up regime which achieves the task through learning category-level human semantic segmentation as well as multi-person pose estimation in a joint and end-to-end manner. The output is a compact, efficient and powerful framework that exploits structural information over different human ...]]></description>
        </item>
        <item>
            <title><![CDATA[Evaluating Classification Model Against Bayes Error Rate]]></title>
            <link>https://ieeexplore.ieee.org/document/10027467</link>
            <guid>https://ieeexplore.ieee.org/document/10027467</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[For a classification task, we usually select an appropriate classifier via model selection. How to evaluate whether the chosen classifier is optimal? One can answer this question via Bayes error rate (BER). Unfortunately, estimating BER is a fundamental conundrum. Most existing BER estimators focus on giving the upper and lower bounds of the BER. However, evaluating whether the selected classifier...]]></description>
        </item>
        <item>
            <title><![CDATA[TextStyleBrush: Transfer of Text Aesthetics From a Single Example]]></title>
            <link>https://ieeexplore.ieee.org/document/10027471</link>
            <guid>https://ieeexplore.ieee.org/document/10027471</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present a novel approach for disentangling the content of a text image from all aspects of its appearance. The appearance representation we derive can then be applied to new content, for one-shot transfer of the source style to new content. We learn this disentanglement in a self-supervised manner. Our method processes entire word boxes, without requiring segmentation of text from background, p...]]></description>
        </item>
        <item>
            <title><![CDATA[General Greedy De-bias Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10027464</link>
            <guid>https://ieeexplore.ieee.org/document/10027464</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Neural networks often make predictions relying on the spurious correlations from the datasets rather than the intrinsic properties of the task of interest, facing with sharp degradation on out-of-distribution (OOD) test data. Existing de-bias learning frameworks try to capture specific dataset bias by annotations but they fail to handle complicated OOD scenarios. Others implicitly identify the dat...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Good Features to Transfer Across Tasks and Domains]]></title>
            <link>https://ieeexplore.ieee.org/document/10027474</link>
            <guid>https://ieeexplore.ieee.org/document/10027474</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Availability of labelled data is the major obstacle to the deployment of deep learning algorithms for computer vision tasks in new domains. The fact that many frameworks adopted to solve different tasks share the same architecture suggests that there should be a way of reusing the knowledge learned in a specific setting to solve novel tasks with limited or no additional supervision. In this work, ...]]></description>
        </item>
        <item>
            <title><![CDATA[Image Intensity Variation Information for Interest Point Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10026417</link>
            <guid>https://ieeexplore.ieee.org/document/10026417</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Interest point detection methods are gaining more attention and are widely applied in computer vision tasks such as image retrieval and 3D reconstruction. However, there still exist two main problems to be solved: (1) from the perspective of mathematical representations, the differences among edges, corners, and blobs have not been convincingly explained and the relationships among the amplitude r...]]></description>
        </item>
        <item>
            <title><![CDATA[Knowledge-aware Global Reasoning for Situation Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10024320</link>
            <guid>https://ieeexplore.ieee.org/document/10024320</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The task of situation recognition aims to solve the visual reasoning problem with the ability to predict the activity happening (salient action) in an image and the nouns of all associated semantic roles playing in the activity. This poses severe challenges due to long-tailed data distributions and local class ambiguities. Prior works only propagate the local noun-level features on one single imag...]]></description>
        </item>
        <item>
            <title><![CDATA[Self-Adversarial Disentangling for Specific Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/10024368</link>
            <guid>https://ieeexplore.ieee.org/document/10024368</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Domain adaptation aims to bridge the domain shifts between the source and the target domain. These shifts may span different dimensions such as fog, rainfall, etc. However, recent methods typically do not consider explicit prior knowledge about the domain shifts on a specific dimension, thus leading to less desired adaptation performance. In this paper, we study a practical setting called Specific...]]></description>
        </item>
        <item>
            <title><![CDATA[Graph Diffusion Convolutional Network for Skeleton Based Semantic Recognition of Two-Person Actions]]></title>
            <link>https://ieeexplore.ieee.org/document/10023982</link>
            <guid>https://ieeexplore.ieee.org/document/10023982</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph Convolutional Networks (GCNs) have successfully boosted skeleton-based human action recognition. However, existing GCN-based methods mostly cast the problem as separated person&#39;s action recognition while ignoring the interaction between the action initiator and the action responder, especially for the fundamental two-person interactive action recognition. It is still challenging to effective...]]></description>
        </item>
        <item>
            <title><![CDATA[AGConv: Adaptive Graph Convolution on 3D Point Clouds]]></title>
            <link>https://ieeexplore.ieee.org/document/10024001</link>
            <guid>https://ieeexplore.ieee.org/document/10024001</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Convolution on 3D point clouds is widely researched yet far from perfect in geometric deep learning. The traditional wisdom of convolution characterises feature correspondences indistinguishably among 3D points, arising an intrinsic limitation of poor distinctive feature learning. In this paper, we propose Adaptive Graph Convolution (AGConv) for wide applications of point cloud analysis. AGConv ge...]]></description>
        </item>
        <item>
            <title><![CDATA[Restoring Vision in Adverse Weather Conditions With Patch-Based Denoising Diffusion Models]]></title>
            <link>https://ieeexplore.ieee.org/document/10021824</link>
            <guid>https://ieeexplore.ieee.org/document/10021824</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image restoration under adverse weather conditions has been of significant interest for various computer vision applications. Recent successful methods rely on the current progress in deep neural network architectural designs (e.g., with vision transformers). Motivated by the recent progress achieved with state-of-the-art conditional generative models, we present a novel patch-based image restorat...]]></description>
        </item>
        <item>
            <title><![CDATA[Adaptive Feature Selection With Augmented Attributes]]></title>
            <link>https://ieeexplore.ieee.org/document/10021870</link>
            <guid>https://ieeexplore.ieee.org/document/10021870</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In many dynamic environment applications, with the evolution of data collection ways, the data attributes are incremental and the samples are stored with accumulated feature spaces gradually. For instance, in the neuroimaging-based diagnosis of neuropsychiatric disorders, with emerging of diverse testing ways, we get more brain image features over time. The accumulation of different types of featu...]]></description>
        </item>
        <item>
            <title><![CDATA[Recognizing Object by Components with Human Prior Knowledge Enhances Adversarial Robustness of Deep Neural Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10019576</link>
            <guid>https://ieeexplore.ieee.org/document/10019576</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Adversarial attacks can easily fool object recognition systems based on deep neural networks (DNNs). Although many defense methods have been proposed in recent years, most of them can still be adaptively evaded. One reason for the weak adversarial robustness may be that DNNs are only supervised by category labels and do not have part-based inductive bias like the recognition process of humans. Ins...]]></description>
        </item>
        <item>
            <title><![CDATA[Large Scale Visual Food Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10019590</link>
            <guid>https://ieeexplore.ieee.org/document/10019590</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Food recognition plays an important role in food choice and intake, which is essential to the health and well-being of humans. It is thus of importance to the computer vision community, and can further support many food-oriented vision and multimodal tasks, e.g., food detection and segmentation, cross-modal recipe retrieval and generation. Unfortunately, we have witnessed remarkable advancements i...]]></description>
        </item>
        <item>
            <title><![CDATA[Capture the Moment: High-speed Imaging with Spiking Cameras through Short-term Plasticity]]></title>
            <link>https://ieeexplore.ieee.org/document/10019594</link>
            <guid>https://ieeexplore.ieee.org/document/10019594</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[High-speed imaging can help us understand some phenomena that our eyes cannot capture fast enough. Although ultra-fast frame-based cameras (e.g., Phantom) can record millions of fps at reduced resolution, are too expensive to be widely used. Recently, a retina-inspired vision sensor, spiking camera, has been developed to record external information at 40, 000 Hz. The spiking camera uses the asynch...]]></description>
        </item>
        <item>
            <title><![CDATA[Fully Convolutional Change Detection Framework with Generative Adversarial Network for Unsupervised, Weakly Supervised and Regional Supervised Change Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10019593</link>
            <guid>https://ieeexplore.ieee.org/document/10019593</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep learning for change detection is one of the current hot topics in the field of remote sensing. However, most end-to-end networks are proposed for supervised change detection, and unsupervised change detection models depend on traditional pre-detection methods. Therefore, we proposed a fully convolutional change detection framework with generative adversarial network, to unify unsupervised, we...]]></description>
        </item>
        <item>
            <title><![CDATA[Transforming Complex Problems into K-means Solutions]]></title>
            <link>https://ieeexplore.ieee.org/document/10018468</link>
            <guid>https://ieeexplore.ieee.org/document/10018468</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[K-means is a fundamental clustering algorithm widely used in both academic and industrial applications. Its popularity can be attributed to its simplicity and efficiency. Studies show the equivalence of K-means to principal component analysis, non-negative matrix factorization, and spectral clustering. However, these studies focus on standard K-means with squared Euclidean distance. In this review...]]></description>
        </item>
        <item>
            <title><![CDATA[ContextLoc++: A Unified Context Model for Temporal Action Localization]]></title>
            <link>https://ieeexplore.ieee.org/document/10018461</link>
            <guid>https://ieeexplore.ieee.org/document/10018461</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Effectively tackling the problem of temporal action localization (TAL) necessitates a visual representation that jointly pursues two confounding goals, i.e., fine-grained discrimination for temporal localization and sufficient visual invariance for action classification. We address this challenge by enriching the local, global and multi-scale contexts in the popular two-stage temporal localization...]]></description>
        </item>
        <item>
            <title><![CDATA[SePiCo: Semantic-Guided Pixel Contrast for Domain Adaptive Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10018569</link>
            <guid>https://ieeexplore.ieee.org/document/10018569</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Domain adaptive semantic segmentation attempts to make satisfactory dense predictions on an unlabeled target domain by utilizing the supervised model trained on a labeled source domain. One popular solution is self-training, which retrains the model with pseudo labels on target instances. Plenty of approaches tend to alleviate noisy pseudo labels, however, they ignore the intrinsic connection of t...]]></description>
        </item>
        <item>
            <title><![CDATA[SceneHGN: Hierarchical Graph Networks for 3D Indoor Scene Generation with Fine-Grained Geometry]]></title>
            <link>https://ieeexplore.ieee.org/document/10018465</link>
            <guid>https://ieeexplore.ieee.org/document/10018465</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[3D indoor scenes are widely used in computer graphics, with applications ranging from interior design to gaming to virtual and augmented reality. They also contain rich information, including room layout, as well as furniture type, geometry, and placement. High-quality 3D indoor scenes are highly demanded while it requires expertise and is time-consuming to design high-quality 3D indoor scenes man...]]></description>
        </item>
        <item>
            <title><![CDATA[Pixel-Perfect Structure-From-Motion With Featuremetric Refinement]]></title>
            <link>https://ieeexplore.ieee.org/document/10018409</link>
            <guid>https://ieeexplore.ieee.org/document/10018409</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Finding local features that are repeatable across multiple views is a cornerstone of sparse 3D reconstruction. The classical image matching paradigm detects keypoints per-image once and for all, which can yield poorly-localized features and propagate large errors to the final geometry. In this paper, we refine two key steps of structure-from-motion by a direct alignment of low-level image informat...]]></description>
        </item>
        <item>
            <title><![CDATA[Generalizable Black-Box Adversarial Attack With Meta Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/10017370</link>
            <guid>https://ieeexplore.ieee.org/document/10017370</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In the scenario of black-box adversarial attack, the target model&#39;s parameters are unknown, and the attacker aims to find a successful adversarial perturbation based on query feedback under a query budget. Due to the limited feedback information, existing query-based black-box attack methods often require many queries for attacking each benign example. To reduce query cost, we propose to utilize t...]]></description>
        </item>
        <item>
            <title><![CDATA[FingerGAN: A Constrained Fingerprint Generation Scheme for Latent Fingerprint Enhancement]]></title>
            <link>https://ieeexplore.ieee.org/document/10016755</link>
            <guid>https://ieeexplore.ieee.org/document/10016755</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Latent fingerprint enhancement is an essential preprocessing step for latent fingerprint identification. Most latent fingerprint enhancement methods try to restore corrupted gray ridges/valleys. In this paper, we propose a new method that formulates latent fingerprint enhancement as a constrained fingerprint generation problem within a generative adversarial network (GAN) framework. We name the pr...]]></description>
        </item>
        <item>
            <title><![CDATA[Convolution-enhanced Evolving Attention Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/10016752</link>
            <guid>https://ieeexplore.ieee.org/document/10016752</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Attention-based neural networks, such as Transformers, have become ubiquitous in numerous applications, including computer vision, natural language processing, and time-series analysis. In all kinds of attention networks, the attention maps are crucial as they encode semantic dependencies between input tokens. However, most existing attention networks perform modeling or reasoning based on represe...]]></description>
        </item>
        <item>
            <title><![CDATA[Adversarially-Regularized Mixed Effects Deep Learning (ARMED) Models Improve Interpretability, Performance, and Generalization on Clustered (non-iid) Data]]></title>
            <link>https://ieeexplore.ieee.org/document/10016237</link>
            <guid>https://ieeexplore.ieee.org/document/10016237</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Natural science datasets frequently violate assumptions of independence. Samples may be clustered (e.g. by study site, subject, or experimental batch), leading to spurious associations, poor model fitting, and confounded analyses. While largely unaddressed in deep learning, this problem has been handled in the statistics community through mixed effects models, which separate cluster-invariant fixe...]]></description>
        </item>
        <item>
            <title><![CDATA[Full-Volume 3D Fluid Flow Reconstruction With Light Field PIV]]></title>
            <link>https://ieeexplore.ieee.org/document/10015628</link>
            <guid>https://ieeexplore.ieee.org/document/10015628</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Particle Imaging Velocimetry (PIV) is a classical method that estimates fluid flow by analyzing the motion of injected particles. To reconstruct and track the swirling particles is a difficult computer vision problem, as the particles are dense in the fluid volume and have similar appearances. Further, tracking a large number of particles is particularly challenging due to heavy occlusion. Here we...]]></description>
        </item>
        <item>
            <title><![CDATA[Adaptive Subgraph Neural Network with Reinforced Critical Structure Mining]]></title>
            <link>https://ieeexplore.ieee.org/document/10013693</link>
            <guid>https://ieeexplore.ieee.org/document/10013693</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[While graph representation learning methods have shown success in various graph mining tasks, what knowledge is exploited for predictions is less discussed. This paper proposes a novel Adaptive Subgraph Neural Network named AdaSNN to find critical structures in graph data, i.e., subgraphs that are dominant to the prediction results. To detect critical subgraphs of arbitrary size and shape in the a...]]></description>
        </item>
        <item>
            <title><![CDATA[Language-Aware Spatial-Temporal Collaboration for Referring Video Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10013778</link>
            <guid>https://ieeexplore.ieee.org/document/10013778</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Given a natural language referring expression, the goal of referring video segmentation task is to predict the segmentation mask of the referred object in the video. Previous methods only adopt 3D CNNs upon the video clip as a single encoder to extract a mixed spatio-temporal feature for the target frame. Though 3D convolutions are able to recognize which object is performing the described actions...]]></description>
        </item>
        <item>
            <title><![CDATA[DAN: a Segmentation-free Document Attention Network for Handwritten Document Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/10013687</link>
            <guid>https://ieeexplore.ieee.org/document/10013687</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Unconstrained handwritten text recognition is a challenging computer vision task. It is traditionally handled by a two-step approach, combining line segmentation followed by text line recognition. For the first time, we propose an end-to-end segmentation-free architecture for the task of handwritten document recognition: the Document Attention Network. In addition to text recognition, the model is...]]></description>
        </item>
        <item>
            <title><![CDATA[SIGMA++: Improved Semantic-complete Graph Matching for Domain Adaptive Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10012542</link>
            <guid>https://ieeexplore.ieee.org/document/10012542</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Domain Adaptive Object Detection (DAOD) generalizes the object detector from an annotated domain to a label-free novel one. Recent works estimate prototypes (class centers) and minimize the corresponding distances to adapt the cross-domain class conditional distribution. However, this prototype-based paradigm 1) fails to capture the class variance with agnostic structural dependencies, and 2) igno...]]></description>
        </item>
        <item>
            <title><![CDATA[BNET: Batch Normalization With Enhanced Linear Transformation]]></title>
            <link>https://ieeexplore.ieee.org/document/10012548</link>
            <guid>https://ieeexplore.ieee.org/document/10012548</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Batch normalization (BN) is a fundamental unit in modern deep neural networks. However, BN and its variants focus on normalization statistics but neglect the recovery step that uses linear transformation to improve the capacity of fitting complex data distributions. In this paper, we demonstrate that the recovery step can be improved by aggregating the neighborhood of each neuron rather than just ...]]></description>
        </item>
        <item>
            <title><![CDATA[A Thorough Benchmark and a New Model for Light Field Saliency Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/10012539</link>
            <guid>https://ieeexplore.ieee.org/document/10012539</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Compared with current RGB or RGB-D saliency detection datasets, those for light field saliency detection often suffer from many defects, e.g., insufficient data amount and diversity, incomplete data formats, and rough annotations, thus impeding the prosperity of this field. To settle these issues, we elaborately build a large-scale light field dataset, dubbed PKU-LF, comprising 5,000 light fields ...]]></description>
        </item>
        <item>
            <title><![CDATA[Detection-Friendly Dehazing: Object Detection in Real-World Hazy Scenes]]></title>
            <link>https://ieeexplore.ieee.org/document/10012056</link>
            <guid>https://ieeexplore.ieee.org/document/10012056</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Adverse weather conditions in real-world scenarios lead to performance degradation of deep learning-based detection models. A well-known method is to use image restoration methods to enhance degraded images before object detection. However, how to build a positive correlation between these two tasks is still technically challenging. The restoration labels are also unavailable in practice. To this ...]]></description>
        </item>
        <item>
            <title><![CDATA[Convolutional Hough Matching Networks for Robust and Efficient Visual Correspondence]]></title>
            <link>https://ieeexplore.ieee.org/document/10008958</link>
            <guid>https://ieeexplore.ieee.org/document/10008958</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Despite advances in feature representation, leveraging geometric relations is crucial for establishing reliable visual correspondences under large variations of images. In this work we introduce a Hough transform perspective on convolutional matching and propose an effective geometric matching algorithm, dubbed Convolutional Hough Matching (CHM). The method distributes similarities of candidate ma...]]></description>
        </item>
        <item>
            <title><![CDATA[Co-Salient Object Detection with Co-Representation Purification]]></title>
            <link>https://ieeexplore.ieee.org/document/10008072</link>
            <guid>https://ieeexplore.ieee.org/document/10008072</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Co-salient object detection (Co-SOD) aims at discovering the common objects in a group of relevant images. Mining a co-representation is essential for locating co-salient objects. Unfortunately, the current Co-SOD method does not pay enough attention that the information not related to the co-salient object is included in the co-representation. Such irrelevant information in the co-representation ...]]></description>
        </item>
        <item>
            <title><![CDATA[GCNet: Graph Completion Network for Incomplete Multimodal Learning in Conversation]]></title>
            <link>https://ieeexplore.ieee.org/document/10008078</link>
            <guid>https://ieeexplore.ieee.org/document/10008078</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Conversations have become a critical data format on social media platforms. Understanding conversation from emotion, content and other aspects also attracts increasing attention from researchers due to its widespread application in human-computer interaction. In real-world environments, we often encounter the problem of incomplete modalities, which has become a core issue of conversation understan...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Metric Learning with Adaptively Composite Dynamic Constraints]]></title>
            <link>https://ieeexplore.ieee.org/document/10008092</link>
            <guid>https://ieeexplore.ieee.org/document/10008092</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we propose a deep metric learning with adaptively composite dynamic constraints (DML-DC) method for image retrieval and clustering. Most existing deep metric learning methods impose pre-defined constraints on the training samples, which might not be optimal at all stages of training. To address this, we propose a learnable constraint generator to adaptively produce dynamic constrain...]]></description>
        </item>
        <item>
            <title><![CDATA[Gradient Descent Ascent for Minimax Problems on Riemannian Manifolds]]></title>
            <link>https://ieeexplore.ieee.org/document/10005847</link>
            <guid>https://ieeexplore.ieee.org/document/10005847</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In the paper, we study a class of useful minimax problems on Riemanian manifolds and propose a class of effective Riemanian gradient-based methods to solve these minimax problems. Specifically, we propose an effective Riemannian gradient descent ascent (RGDA) algorithm for the deterministic minimax optimization. Moreover, we prove that our RGDA has a sample complexity of $O(\kappa ^{2}\epsilon ^{-...]]></description>
        </item>
        <item>
            <title><![CDATA[Universal Multimodal Representation for Language Understanding]]></title>
            <link>https://ieeexplore.ieee.org/document/10005816</link>
            <guid>https://ieeexplore.ieee.org/document/10005816</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Representation learning is the foundation of natural language processing (NLP). This work presents new methods to employ visual information as assistant signals to general NLP tasks. For each sentence, we first retrieve a flexible number of images either from a light topic-image lookup table extracted over the existing sentence-image pairs or a shared cross-modal embedding space that is pre-traine...]]></description>
        </item>
        <item>
            <title><![CDATA[From Keypoints to Object Landmarks via Self-Training Correspondence: A novel approach to Unsupervised Landmark Discovery]]></title>
            <link>https://ieeexplore.ieee.org/document/10005822</link>
            <guid>https://ieeexplore.ieee.org/document/10005822</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper proposes a novel paradigm for the unsupervised learning of object landmark detectors. Contrary to existing methods that build on auxiliary tasks such as image generation or equivariance, we propose a self-training approach where, departing from generic keypoints, a landmark detector and descriptor is trained to improve itself, tuning the keypoints into distinctive landmarks. To this end...]]></description>
        </item>
        <item>
            <title><![CDATA[Semi-Blindly Enhancing Extremely Noisy Videos With Recurrent Spatio-Temporal Large-Span Network]]></title>
            <link>https://ieeexplore.ieee.org/document/10005850</link>
            <guid>https://ieeexplore.ieee.org/document/10005850</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Capturing videos under the extremely dark environment is quite challenging for the extremely large and complex noise. To accurately represent the complex noise distribution, the physics-based noise modeling and learning-based blind noise modeling methods are proposed. However, these methods suffer from either the requirement of complex calibration procedure or performance degradation in practice. ...]]></description>
        </item>
        <item>
            <title><![CDATA[HOP+: History-Enhanced and Order-Aware Pre-Training for Vision-and-Language Navigation]]></title>
            <link>https://ieeexplore.ieee.org/document/10006384</link>
            <guid>https://ieeexplore.ieee.org/document/10006384</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent works attempt to employ pre-training in Vision-and-Language Navigation (VLN). However, these methods neglect the importance of historical contexts or ignore predicting future actions during pre-training, limiting the learning of visual-textual correspondence and the capability of decision-making. To address these problems, we present a history-enhanced and order-aware pre-training with the ...]]></description>
        </item>
        <item>
            <title><![CDATA[Monocular 3D Fingerprint Reconstruction and Unwarping]]></title>
            <link>https://ieeexplore.ieee.org/document/10005833</link>
            <guid>https://ieeexplore.ieee.org/document/10005833</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Compared with contact-based fingerprint acquisition techniques, contactless acquisition has the advantages of less skin distortion, more complete fingerprint area, and hygienic acquisition. However, perspective distortion is a challenge in contactless fingerprint recognition, which changes the ridge frequency and relative minutiae location, and thus degrades the recognition accuracy. We propose a ...]]></description>
        </item>
        <item>
            <title><![CDATA[A Unified Visual Information Preservation Framework for Self-supervised Pre-training in Medical Image Analysis]]></title>
            <link>https://ieeexplore.ieee.org/document/10005161</link>
            <guid>https://ieeexplore.ieee.org/document/10005161</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent advances in self-supervised learning (SSL) in computer vision are primarily comparative, whose goal is to preserve invariant and discriminative semantics in latent representations by comparing siamese image views. However, the preserved high-level semantics do not contain enough local information, which is vital in medical image analysis (e.g., image-based diagnosis and tumor segmentation)....]]></description>
        </item>
        <item>
            <title><![CDATA[Invariant Policy Learning: A Causal Perspective]]></title>
            <link>https://ieeexplore.ieee.org/document/10005169</link>
            <guid>https://ieeexplore.ieee.org/document/10005169</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Contextual bandit and reinforcement learning algorithms have been successfully used in various interactive learning systems such as online advertising, recommender systems, and dynamic pricing. However, they have yet to be widely adopted in high-stakes application domains, such as healthcare. One reason may be that existing approaches assume that the underlying mechanisms are static in the sense t...]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Unary Convolution in Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/10004645</link>
            <guid>https://ieeexplore.ieee.org/document/10004645</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[It is uncertain whether the power of transformer architectures can complement existing convolutional neural networks. A few recent attempts have combined convolution with transformer design through a range of structures in series, where the main contribution of this paper is to explore a parallel design approach. While previous transformed-based approaches need to segment the image into patch-wise...]]></description>
        </item>
        <item>
            <title><![CDATA[Hyperparameter-Free Localized Simple Multiple Kernel K-Means With Global Optimum]]></title>
            <link>https://ieeexplore.ieee.org/document/10005021</link>
            <guid>https://ieeexplore.ieee.org/document/10005021</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The newly proposed localized simple multiple kernel k-means (SimpleMKKM) provides an elegant clustering framework which sufficiently considers the potential variation among samples. Although achieving superior clustering performance in some applications, we observe that it is required to pre-specify an extra hyperparameter, which determines the size of the localization. This greatly limits its ava...]]></description>
        </item>
        <item>
            <title><![CDATA[Querying Labeled for Unlabeled: Cross-Image Semantic Consistency Guided Semi-Supervised Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/10005033</link>
            <guid>https://ieeexplore.ieee.org/document/10005033</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Semi-supervised semantic segmentation aims to learn a semantic segmentation model via limited labeled images and adequate unlabeled images. The key to this task is generating reliable pseudo labels for unlabeled images. Existing methods mainly focus on producing reliable pseudo labels based on the confidence scores of unlabeled images while largely ignoring the use of labeled images with accurate ...]]></description>
        </item>
        <item>
            <title><![CDATA[Fisher's Linear Discriminant Analysis With Space-Folding Operations]]></title>
            <link>https://ieeexplore.ieee.org/document/10005006</link>
            <guid>https://ieeexplore.ieee.org/document/10005006</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Fisher&#39;s linear discriminant analysis (LDA) is an easy-to-use supervised dimensionality reduction method. However, LDA may be ineffective against complicated class distributions. It is well-known that deep feedforward neural networks with rectified linear units as activation functions can map many input neighborhoods to similar outputs by a succession of space-folding operations. This short paper ...]]></description>
        </item>
        <item>
            <title><![CDATA[Face Forgery Detection by 3D Decomposition and Composition Search]]></title>
            <link>https://ieeexplore.ieee.org/document/10005010</link>
            <guid>https://ieeexplore.ieee.org/document/10005010</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Detecting digital face manipulation has attracted extensive attention due to fake media&#39;s potential risks to the public. However, recent advances have been able to reduce the forgery signals to a low magnitude. Decomposition, which reversibly decomposes an image into several constituent elements, is a promising way to highlight the hidden forgery details. In this paper, we investigate a novel 3D d...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Implicit Functions for Dense 3D Shape Correspondence of Generic Objects]]></title>
            <link>https://ieeexplore.ieee.org/document/10004641</link>
            <guid>https://ieeexplore.ieee.org/document/10004641</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The objective of this paper is to learn dense 3D shape correspondence for topology-varying generic objects in an unsupervised manner. Conventional implicit functions estimate the occupancy of a 3D point given a shape latent code. Instead, our novel implicit function produces a probabilistic embedding to represent each 3D point in a part embedding space. Assuming the corresponding points are simila...]]></description>
        </item>
        <item>
            <title><![CDATA[A Multi-Task Multi-Stage Transitional Training Framework for Neural Chat Translation]]></title>
            <link>https://ieeexplore.ieee.org/document/10003654</link>
            <guid>https://ieeexplore.ieee.org/document/10003654</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Neural chat translation (NCT) aims to translate a cross-lingual chat between speakers of different languages. Existing context-aware NMT models cannot achieve satisfactory performances due to the following inherent problems: 1) limited resources of annotated bilingual dialogues; 2) the neglect of modelling conversational properties; 3) training discrepancy between different stages. To address thes...]]></description>
        </item>
        <item>
            <title><![CDATA[WebUAV-3 M: A Benchmark for Unveiling the Power of Million-Scale Deep UAV Tracking]]></title>
            <link>https://ieeexplore.ieee.org/document/10004511</link>
            <guid>https://ieeexplore.ieee.org/document/10004511</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Unmanned aerial vehicle (UAV) tracking is of great significance for a wide range of applications, such as delivery and agriculture. Previous benchmarks in this area mainly focused on small-scale tracking problems while ignoring the amounts of data, types of data modalities, diversities of target categories and scenarios, and evaluation protocols involved, greatly hiding the massive power of deep U...]]></description>
        </item>
        <item>
            <title><![CDATA[HAKE: A Knowledge Engine Foundation for Human Activity Understanding]]></title>
            <link>https://ieeexplore.ieee.org/document/10002711</link>
            <guid>https://ieeexplore.ieee.org/document/10002711</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Human activity understanding is of widespread interest in artificial intelligence and spans diverse applications like health care and behavior analysis. Although there have been advances with deep learning, it remains challenging. The object recognition-like solutions usually try to map pixels to semantics directly, but activity patterns are much different from object patterns, thus hindering anot...]]></description>
        </item>
        <item>
            <title><![CDATA[Reducing Spatial Labeling Redundancy for Active Semi-Supervised Crowd Counting]]></title>
            <link>https://ieeexplore.ieee.org/document/10002302</link>
            <guid>https://ieeexplore.ieee.org/document/10002302</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Labeling is onerous for crowd counting as it should annotate each individual in crowd images. Recently, several methods have been proposed for semi-supervised crowd counting to reduce the labeling efforts. Given a limited labeling budget, they typically select a few crowd images and densely label all individuals in each of them. Despite the promising results, we argue the None-or-All labeling stra...]]></description>
        </item>
        <item>
            <title><![CDATA[IC9600: A Benchmark Dataset for Automatic Image Complexity Assessment]]></title>
            <link>https://ieeexplore.ieee.org/document/9999482</link>
            <guid>https://ieeexplore.ieee.org/document/9999482</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image complexity (IC) is an essential visual perception for human beings to understand an image. However, explicitly evaluating the IC is challenging, and has long been overlooked since, on the one hand, the evaluation of IC is relatively subjective due to its dependence on human perception, and on the other hand, the IC is semantic-dependent while real-world images are diverse. To facilitate the ...]]></description>
        </item>
        <item>
            <title><![CDATA[High-Performance Transformer Tracking]]></title>
            <link>https://ieeexplore.ieee.org/document/9999490</link>
            <guid>https://ieeexplore.ieee.org/document/9999490</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Correlation has a critical role in the tracking field, especially in recent popular Siamese-based trackers. The correlation operation is a simple fusion method that considers the similarity between the template and the search region. However, the correlation operation is a local linear matching process, losing semantic information and easily falling into a local optimum, which may be the bottlenec...]]></description>
        </item>
        <item>
            <title><![CDATA[SignNet II: A Transformer-Based Two-Way Sign Language Translation Model]]></title>
            <link>https://ieeexplore.ieee.org/document/9999492</link>
            <guid>https://ieeexplore.ieee.org/document/9999492</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The role of a sign interpreting agent is to bridge the communication gap between the hearing-only and Deaf or Hard of Hearing communities by translating both from sign language to text and from text to sign language. Until now, much of the AI work in automated sign language processing has focused primarily on sign language to text translation, which puts the advantage mainly on the side of hearing...]]></description>
        </item>
        <item>
            <title><![CDATA[Neural Radiance Fields from Sparse RGB-D Images for High-Quality View Synthesis]]></title>
            <link>https://ieeexplore.ieee.org/document/9999509</link>
            <guid>https://ieeexplore.ieee.org/document/9999509</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The recently proposed neural radiance fields (NeRF) use a continuous function formulated as a multi-layer perceptron (MLP) to model the appearance and geometry of a 3D scene. This enables realistic synthesis of novel views, even for scenes with view dependent appearance. Many follow-up works have since extended NeRFs in different ways. However, a fundamental restriction of the method remains that ...]]></description>
        </item>
        <item>
            <title><![CDATA[Polarimetric Multi-View Inverse Rendering]]></title>
            <link>https://ieeexplore.ieee.org/document/9999345</link>
            <guid>https://ieeexplore.ieee.org/document/9999345</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[A polarization camera has great potential for 3D reconstruction since the angle of polarization (AoP) and the degree of polarization (DoP) of reflected light are related to an object&#39;s surface normal. In this paper, we propose a novel 3D reconstruction method called Polarimetric Multi-View Inverse Rendering (Polarimetric MVIR) that effectively exploits geometric, photometric, and polarimetric cues...]]></description>
        </item>
        <item>
            <title><![CDATA[Simultaneously Optimizing Perturbations and Positions for Black-Box Adversarial Patch Attacks]]></title>
            <link>https://ieeexplore.ieee.org/document/9999043</link>
            <guid>https://ieeexplore.ieee.org/document/9999043</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Adversarial patch is an important form of real-world adversarial attack that brings serious risks to the robustness of deep neural networks. Previous methods generate adversarial patches by either optimizing their perturbation values while fixing the pasting position or manipulating the position while fixing the patch&#39;s content. This reveals that the positions and perturbations are both important ...]]></description>
        </item>
        <item>
            <title><![CDATA[DaisyRec 2.0: Benchmarking Recommendation for Rigorous Evaluation]]></title>
            <link>https://ieeexplore.ieee.org/document/9999032</link>
            <guid>https://ieeexplore.ieee.org/document/9999032</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, one critical issue looms large in the field of recommender systems – there are no effective benchmarks for rigorous evaluation – which consequently leads to unreproducible evaluation and unfair comparison. We, therefore, conduct studies from the perspectives of practical theory and experiments, aiming at benchmarking recommendation for rigorous evaluation. Regarding the theoretical study...]]></description>
        </item>
        <item>
            <title><![CDATA[ScoreMix: A Scalable Augmentation Strategy for Training GANs With Limited Data]]></title>
            <link>https://ieeexplore.ieee.org/document/9998118</link>
            <guid>https://ieeexplore.ieee.org/document/9998118</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Generative Adversarial Networks (GANs) typically suffer from overfitting when limited training data is available. To facilitate GAN training, current methods propose to use data-specific augmentation techniques. Despite the effectiveness, it is difficult for these methods to scale to practical applications. In this work, we present ScoreMix, a novel and scalable data augmentation approach for vari...]]></description>
        </item>
        <item>
            <title><![CDATA[Patch-based Separable Transformer for Visual Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9998115</link>
            <guid>https://ieeexplore.ieee.org/document/9998115</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The computational complexity of transformers limits it to be widely deployed onto frameworks for visual recognition. Recent work [9] significantly accelerates the network processing speed by reducing the resolution at the beginning of the network, however, it is still hard to be directly generalized onto other downstream tasks e.g. object detection and segmentation like CNN. In this paper, we pres...]]></description>
        </item>
        <item>
            <title><![CDATA[Self-supervised 3D Representation Learning of Dressed Humans from Social Media Videos]]></title>
            <link>https://ieeexplore.ieee.org/document/9996551</link>
            <guid>https://ieeexplore.ieee.org/document/9996551</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[A key challenge of learning a visual representation for the 3D high fidelity geometry of dressed humans lies in the limited availability of the ground truth data (e.g., 3D scanned models), which results in the performance degradation of 3D human reconstruction when applying to real-world imagery. We address this challenge by leveraging a new data resource: a number of social media dance videos tha...]]></description>
        </item>
        <item>
            <title><![CDATA[Non-Graph Data Clustering via $\mathcal {O}(n)$ Bipartite Graph Convolution]]></title>
            <link>https://ieeexplore.ieee.org/document/9996549</link>
            <guid>https://ieeexplore.ieee.org/document/9996549</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Since the representative capacity of graph-based clustering methods is usually limited by the graph constructed on the original features, it is attractive to find whether graph neural networks (GNNs), a strong extension of neural networks to graphs, can be applied to augment the capacity of graph-based clustering methods. The core problems mainly come from two aspects. On the one hand, the graph i...]]></description>
        </item>
        <item>
            <title><![CDATA[Task-Aware Weakly Supervised Object Localization With Transformer]]></title>
            <link>https://ieeexplore.ieee.org/document/9996553</link>
            <guid>https://ieeexplore.ieee.org/document/9996553</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Weakly supervised object localization (WSOL) aims to predict both object locations and categories with only image-level class labels. However, most existing methods rely on class-specific image regions for localization, resulting in incomplete object localization. To alleviate this problem, we propose a novel end-to-end task-aware framework with a transformer encoder-decoder architecture (TAFormer...]]></description>
        </item>
        <item>
            <title><![CDATA[What Makes for Good Tokenizers in Vision Transformer?]]></title>
            <link>https://ieeexplore.ieee.org/document/9996581</link>
            <guid>https://ieeexplore.ieee.org/document/9996581</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The architecture of transformers, which recently witness booming applications in vision tasks, has pivoted against the widespread convolutional paradigm. Relying on the tokenization process that splits inputs into multiple tokens, transformers are capable of extracting their pairwise relationships using self-attention. While being the stemming building block of transformers, what makes for a good ...]]></description>
        </item>
        <item>
            <title><![CDATA[Reference-based Image and Video Super-Resolution via $C^{2}$-Matching]]></title>
            <link>https://ieeexplore.ieee.org/document/9996154</link>
            <guid>https://ieeexplore.ieee.org/document/9996154</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising paradigm to enhance a low-resolution (LR) input image or video by introducing an additional high-resolution (HR) reference image. Existing Ref-SR methods mostly rely on implicit correspondence matching to borrow HR textures from reference images to compensate for the information loss in input images. However, performing ...]]></description>
        </item>
        <item>
            <title><![CDATA[Knowledge-enriched Attention Network with Group-wise Semantic for Visual Storytelling]]></title>
            <link>https://ieeexplore.ieee.org/document/9996128</link>
            <guid>https://ieeexplore.ieee.org/document/9996128</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[As a technically challenging topic, visual storytelling aims at generating an imaginary and coherent story with narrative multi-sentences from a group of relevant images. Existing methods often generate direct and rigid descriptions of apparent image-based contents, because they are not capable of exploring implicit information beyond images. Hence, these schemes could not capture consistent depen...]]></description>
        </item>
        <item>
            <title><![CDATA[Formulating Event-based Image Reconstruction as a Linear Inverse Problem with Deep Regularization using Optical Flow]]></title>
            <link>https://ieeexplore.ieee.org/document/9994038</link>
            <guid>https://ieeexplore.ieee.org/document/9994038</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[A Deep Framework for Hyperspectral Image Fusion between Different Satellites]]></title>
            <link>https://ieeexplore.ieee.org/document/9992028</link>
            <guid>https://ieeexplore.ieee.org/document/9992028</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, fusing a low-resolution hyperspectral image (LR-HSI) with a high-resolution multispectral image (HR-MSI) of different satellites has become an effective way to improve the resolution of an HSI. However, due to different imaging satellites, different illumination, and adjacent imaging time, the LR-HSI and HR-MSI may not satisfy the observation models established by existing works, and the...]]></description>
        </item>
        <item>
            <title><![CDATA[Quantformer: Learning Extremely Low-precision Vision Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/9992209</link>
            <guid>https://ieeexplore.ieee.org/document/9992209</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we propose extremely low-precision vision transformers called Quantformer for efficient inference. Conventional network quantization methods directly quantize weights and activations of fully-connected layers without considering properties of transformer architectures. Quantization sizably deviates the self-attention compared with full-precision counterparts, and the shared quantiza...]]></description>
        </item>
        <item>
            <title><![CDATA[Global Learnable Attention for Single Image Super-Resolution]]></title>
            <link>https://ieeexplore.ieee.org/document/9992208</link>
            <guid>https://ieeexplore.ieee.org/document/9992208</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Self-similarity is valuable to the exploration of non-local textures in single image super-resolution (SISR). Researchers usually assume that the importance of non-local textures is positively related to their similarity scores. In this paper, we surprisingly found that when repairing severely damaged query textures, some non-local textures with low-similarity which are closer to the target can pr...]]></description>
        </item>
        <item>
            <title><![CDATA[Multi-Label Classification via Adaptive Resonance Theory-Based Clustering]]></title>
            <link>https://ieeexplore.ieee.org/document/9992110</link>
            <guid>https://ieeexplore.ieee.org/document/9992110</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper proposes a multi-label classification algorithm capable of continual learning by applying an Adaptive Resonance Theory (ART)-based clustering algorithm and the Bayesian approach for label probability computation. The ART-based clustering algorithm adaptively and continually generates prototype nodes corresponding to given data, and the generated nodes are used as classifiers. The label ...]]></description>
        </item>
        <item>
            <title><![CDATA[Adaptive Siamese Tracking with a Compact Latent Network]]></title>
            <link>https://ieeexplore.ieee.org/document/9991898</link>
            <guid>https://ieeexplore.ieee.org/document/9991898</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we provide an intuitive viewing to simplify the Siamese-based trackers by converting the tracking task to a classification. Under this viewing, we perform an in-depth analysis for them through visual simulations and real tracking examples, and find that the failure cases in some challenging situations can be regarded as the issue of missing decisive samples in offline training. Sinc...]]></description>
        </item>
        <item>
            <title><![CDATA[Semantic and Relation Modulation for Audio-Visual Event Localization]]></title>
            <link>https://ieeexplore.ieee.org/document/9990903</link>
            <guid>https://ieeexplore.ieee.org/document/9990903</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We study the problem of localizing audio-visual events that are both audible and visible in a video. Existing works focus on encoding and aligning audio and visual features at the segment level while neglecting informative correlation between segments of the two modalities and between multi-scale event proposals. We propose a novel Semantic and Relation Modulation Network (SRMN) to learn the above...]]></description>
        </item>
        <item>
            <title><![CDATA[TransZero++: Cross Attribute-Guided Transformer for Zero-Shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9987664</link>
            <guid>https://ieeexplore.ieee.org/document/9987664</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Zero-shot learning (ZSL) tackles the novel class recognition problem by transferring semantic knowledge from seen classes to unseen ones. Semantic knowledge is typically represented by attribute descriptions shared between different classes, which act as strong priors for localizing object attributes that represent discriminative region features, enabling significant and sufficient visual-semantic...]]></description>
        </item>
        <item>
            <title><![CDATA[Revealing the Distributional Vulnerability of Discriminators by Implicit Generators]]></title>
            <link>https://ieeexplore.ieee.org/document/9987694</link>
            <guid>https://ieeexplore.ieee.org/document/9987694</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In deep neural learning, a discriminator trained on in-distribution (ID) samples may make high-confidence predictions on out-of-distribution (OOD) samples. This triggers a significant matter for robust, trustworthy and safe deep learning. The issue is primarily caused by the limited ID samples observable in training the discriminator when OOD samples are unavailable. We propose a general approach ...]]></description>
        </item>
        <item>
            <title><![CDATA[Survey: Leakage and Privacy at Inference Time]]></title>
            <link>https://ieeexplore.ieee.org/document/9987657</link>
            <guid>https://ieeexplore.ieee.org/document/9987657</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Leakage of data from publicly available Machine Learning (ML) models is an area of growing significance since commercial and government applications of ML can draw on multiple sources of data, potentially including users&#39; and clients&#39; sensitive data. We provide a comprehensive survey of contemporary advances on several fronts, covering involuntary data leakage which is natural to ML models, potent...]]></description>
        </item>
        <item>
            <title><![CDATA[I2F: A Unified Image-to-Feature Approach for Domain Adaptive Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9984933</link>
            <guid>https://ieeexplore.ieee.org/document/9984933</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Unsupervised domain adaptation (UDA) for semantic segmentation is a promising task freeing people from heavy annotation work. However, domain discrepancies in low-level image statistics and high-level contexts compromise the segmentation performance over the target domain. A key idea to tackle this problem is to perform both image-level and feature-level adaptation jointly. Unfortunately, there is...]]></description>
        </item>
        <item>
            <title><![CDATA[Split-GCN: Effective Interactive Annotation for Segmentation of Disconnected Instance]]></title>
            <link>https://ieeexplore.ieee.org/document/9984937</link>
            <guid>https://ieeexplore.ieee.org/document/9984937</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Annotating object boundaries by humans demands high costs. Recently, polygon-based annotation methods with human interaction have shown successful performance. However, given the connected vertex topology, these methods exhibit difficulty predicting the disconnected components in an object. This paper introduces Split-GCN, a novel architecture based on the polygon approach and self-attention mecha...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Depth Completion from Extremely Sparse Data: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9984942</link>
            <guid>https://ieeexplore.ieee.org/document/9984942</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Depth completion aims at predicting dense pixel-wise depth from an extremely sparse map captured from a depth sensor, e.g., LiDARs. It plays an essential role in various applications such as autonomous driving, 3D reconstruction, augmented reality, and robot navigation. Recent successes on the task have been demonstrated and dominated by deep learning based solutions. In this article, for the firs...]]></description>
        </item>
        <item>
            <title><![CDATA[Orthogonal SVD Covariance Conditioning and Latent Disentanglement]]></title>
            <link>https://ieeexplore.ieee.org/document/9983471</link>
            <guid>https://ieeexplore.ieee.org/document/9983471</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Inserting an SVD meta-layer into neural networks is prone to make the covariance ill-conditioned, which could harm the model in the training stability and generalization abilities. In this paper, we systematically study how to improve the covariance conditioning by enforcing orthogonality to the Pre-SVD layer. Existing orthogonal treatments on the weights are first investigated. However, these tec...]]></description>
        </item>
        <item>
            <title><![CDATA[A Unifying Probabilistic Framework for Partially Labeled Data Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9983986</link>
            <guid>https://ieeexplore.ieee.org/document/9983986</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Partially labeled data learning (PLDL), including partial label learning (PLL) and partial multi-label learning (PML), has been widely used in nowadays data science. Researchers attempt to construct different specific models to deal with the different classification tasks for PLL and PML scenarios respectively. The main challenge in training classifiers for PLL and PML is how to deal with ambiguit...]]></description>
        </item>
        <item>
            <title><![CDATA[E2E-FS: An End-to-End Feature Selection Method for Neural Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9983480</link>
            <guid>https://ieeexplore.ieee.org/document/9983480</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Classic embedded feature selection algorithms are often divided in two large groups: tree-based algorithms and LASSO variants. Both approaches are focused in different aspects: while the tree-based algorithms provide a clear explanation about which variables are being used to trigger a certain output, LASSO-like approaches sacrifice a detailed explanation in favor of increasing its accuracy. In th...]]></description>
        </item>
        <item>
            <title><![CDATA[Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms]]></title>
            <link>https://ieeexplore.ieee.org/document/9983478</link>
            <guid>https://ieeexplore.ieee.org/document/9983478</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper focuses on conditional generative modeling (CGM) for image data with continuous, scalar conditions (termed regression labels). We propose the first model for this task which is called continuous conditional generative adversarial network (CcGAN). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels). Conditioning on regression labels is ma...]]></description>
        </item>
        <item>
            <title><![CDATA[EPNet++: Cascade Bi-Directional Fusion for Multi-Modal 3D Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/9983516</link>
            <guid>https://ieeexplore.ieee.org/document/9983516</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, fusing the LiDAR point cloud and camera image to improve the performance and robustness of 3D object detection has received more and more attention, as these two modalities naturally possess strong complementarity. In this paper, we propose EPNet++ for multi-modal 3D object detection by introducing a novel Cascade Bi-directional Fusion (CB-Fusion) module and a Multi-Modal Consistency (MC...]]></description>
        </item>
        <item>
            <title><![CDATA[Partial Domain Adaptation without Domain Alignment]]></title>
            <link>https://ieeexplore.ieee.org/document/9983498</link>
            <guid>https://ieeexplore.ieee.org/document/9983498</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Unsupervised domain adaptation (UDA) aims to transfer knowledge from a well-labeled source domain to a related and unlabeled target domain with identical label space. The main workhorse in UDA is domain alignment and has proven successful. However, it is practically difficult to find an appropriate source domain with identical label space. A more practical scenario is partial domain adaptation (PD...]]></description>
        </item>
        <item>
            <title><![CDATA[Differentially Private Graph Neural Networks for Whole-Graph Classification]]></title>
            <link>https://ieeexplore.ieee.org/document/9980390</link>
            <guid>https://ieeexplore.ieee.org/document/9980390</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph Neural Networks (GNNs) have established themselves as state-of-the-art for many machine learning applications such as the analysis of social and medical networks. Several among these datasets contain privacy-sensitive data. Machine learning with differential privacy is a promising technique to allow deriving insight from sensitive data while offering formal guarantees of privacy protection. ...]]></description>
        </item>
        <item>
            <title><![CDATA[PoseBERT: A Generic Transformer Module for Temporal 3D Human Modeling]]></title>
            <link>https://ieeexplore.ieee.org/document/9982410</link>
            <guid>https://ieeexplore.ieee.org/document/9982410</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Training state-of-the-art models for human pose estimation in videos requires datasets with annotations that are really hard and expensive to obtain. Although transformers have been recently utilized for body pose sequence modeling, related methods rely on pseudo-ground truth to augment the currently limited training data available for learning such models. In this paper, we introduce PoseBERT, a ...]]></description>
        </item>
        <item>
            <title><![CDATA[A Generic Graph-Based Neural Architecture Encoding Scheme With Multifaceted Information]]></title>
            <link>https://ieeexplore.ieee.org/document/9982412</link>
            <guid>https://ieeexplore.ieee.org/document/9982412</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Neural architecture search (NAS) can automatically discover well-performing architectures in a large search space and has been shown to bring improvements to various applications. However, the computational burden of NAS is huge, since exploring a large search space can need evaluating more than thousands of architecture samples. To improve the sample efficiency of search space exploration, predic...]]></description>
        </item>
        <item>
            <title><![CDATA[Orientational Distribution Learning with Hierarchical Spatial Attention for Open Set Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9978641</link>
            <guid>https://ieeexplore.ieee.org/document/9978641</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Open set recognition (OSR) aims to correctly recognize the known classes and reject the unknown classes for increasing the reliability of the recognition system. The distance-based loss is often employed in deep neural networks-based OSR methods to constrain the latent representation of known classes. However, the optimization is usually conducted using the nondirectional Euclidean distance in a s...]]></description>
        </item>
        <item>
            <title><![CDATA[Open World Entity Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9976289</link>
            <guid>https://ieeexplore.ieee.org/document/9976289</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We introduce a new image segmentation task, called Entity Segmentation (ES), which aims to segment all visual entities (objects and stuffs) in an image without predicting their semantic labels. By removing the need of class label prediction, the models trained for such task can focus more on improving segmentation quality. It has many practical applications such as image manipulation and editing w...]]></description>
        </item>
        <item>
            <title><![CDATA[How Trustworthy are Performance Evaluations for Basic Vision Tasks?]]></title>
            <link>https://ieeexplore.ieee.org/document/9976259</link>
            <guid>https://ieeexplore.ieee.org/document/9976259</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper examines performance evaluation criteria for basic vision tasks involving sets of objects namely, object detection, instance-level segmentation and multi-object tracking. The rankings of algorithms by an existing criterion can fluctuate with different choices of parameters, e.g. Intersection over Union (IoU) threshold, making their evaluations unreliable. More importantly, there is no m...]]></description>
        </item>
        <item>
            <title><![CDATA[BoostTree and BoostForest for Ensemble Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9973329</link>
            <guid>https://ieeexplore.ieee.org/document/9973329</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Bootstrap aggregating (Bagging) and boosting are two popular ensemble learning approaches, which combine multiple base learners to generate a composite model for more accurate and more reliable performance. They have been widely used in biology, engineering, healthcare, etc. This paper proposes BoostForest, which is an ensemble learning approach using BoostTree as base learners and can be used for...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to See Through with Events]]></title>
            <link>https://ieeexplore.ieee.org/document/9973388</link>
            <guid>https://ieeexplore.ieee.org/document/9973388</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Although synthetic aperture imaging (SAI) can achieve the seeing-through effect by blurring out off-focus foreground occlusions while recovering in-focus occluded scenes from multi-view images, its performance is often deteriorated by dense occlusions and extreme lighting conditions. To address the problem, this paper presents an Event-based SAI (E-SAI) method by relying on the asynchronous events...]]></description>
        </item>
        <item>
            <title><![CDATA[Interactive Object Segmentation with Inside-Outside Guidance]]></title>
            <link>https://ieeexplore.ieee.org/document/9971769</link>
            <guid>https://ieeexplore.ieee.org/document/9971769</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This work explores how to harvest precise object segmentation masks while minimizing the human interaction cost. To achieve this, we propose a simple yet effective interaction scheme, named Inside-Outside Guidance (IOG). Concretely, we leverage an inside point that is clicked near the object center and two outside points at the symmetrical corner locations (top-left and bottom-right or top-right a...]]></description>
        </item>
        <item>
            <title><![CDATA[Towards Lightweight Pixel-Wise Hallucination for Heterogeneous Face Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9971748</link>
            <guid>https://ieeexplore.ieee.org/document/9971748</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Cross-spectral face hallucination is an intuitive way to mitigate the modality discrepancy in Heterogeneous Face Recognition (HFR). However, due to imaging differences, the hallucination inevitably suffers from a shape misalignment between paired heterogeneous images. Rather than building complicated architectures to circumvent the problem like previous works, we propose a simple yet effective met...]]></description>
        </item>
        <item>
            <title><![CDATA[Searching for Network Width With Bilaterally Coupled Network]]></title>
            <link>https://ieeexplore.ieee.org/document/9970301</link>
            <guid>https://ieeexplore.ieee.org/document/9970301</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Searching for a more compact network width recently serves as an effective way of channel pruning for the deployment of convolutional neural networks (CNNs) under hardware constraints. To fulfil the searching, a one-shot supernet is usually leveraged to efficiently evaluate the performance w.r.t. different network widths. However, current methods mainly follow a unilaterally augmented (UA) princip...]]></description>
        </item>
        <item>
            <title><![CDATA[A New Outlier Removal Strategy Based on Reliability of Correspondence Graph for Fast Point Cloud Registration]]></title>
            <link>https://ieeexplore.ieee.org/document/9969937</link>
            <guid>https://ieeexplore.ieee.org/document/9969937</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Registration is a basic yet crucial task in point cloud processing. In correspondence-based point cloud registration, matching correspondences by point feature techniques may lead to an extremely high outlier (false correspondence) ratio. Current outlier removal methods still suffer from low efficiency, accuracy, and recall rate. We use an intuitive method to describe the 6-DOF (degree of freedom)...]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Time Warping based Adversarial Framework for Time-Series Domain]]></title>
            <link>https://ieeexplore.ieee.org/document/9970291</link>
            <guid>https://ieeexplore.ieee.org/document/9970291</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Despite the rapid progress on research in adversarial robustness of deep neural networks (DNNs), there is little principled work for the time-series domain. Since time-series data arises in diverse applications including mobile health, finance, and smart grid, it is important to verify and improve the robustness of DNNs for the time-series domain. In this paper, we propose a novel framework for th...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Invariance from Generated Variance for Unsupervised Person Re-identification]]></title>
            <link>https://ieeexplore.ieee.org/document/9970293</link>
            <guid>https://ieeexplore.ieee.org/document/9970293</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This work focuses on unsupervised representation learning in person re-identification (ReID). Recent self-supervised contrastive learning methods learn invariance by maximizing the representation similarity between two augmented views of a same image. However, traditional data augmentation may bring to the fore undesirable distortions on identity features, which is not always favorable in id-sensi...]]></description>
        </item>
        <item>
            <title><![CDATA[Rank-One Prior: Real-Time Scene Recovery]]></title>
            <link>https://ieeexplore.ieee.org/document/9969127</link>
            <guid>https://ieeexplore.ieee.org/document/9969127</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Scene recovery is a fundamental imaging task with several practical applications, including video surveillance and autonomous vehicles, etc. In this paper, we provide a new real-time scene recovery framework to restore degraded images under different weather/imaging conditions, such as underwater, sand dust and haze. A degraded image can actually be seen as a superimposition of a clear image with ...]]></description>
        </item>
        <item>
            <title><![CDATA[Trifocal Relative Pose From Lines at Points]]></title>
            <link>https://ieeexplore.ieee.org/document/9969132</link>
            <guid>https://ieeexplore.ieee.org/document/9969132</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present a method for solving two minimal problems for relative camera pose estimation from three views, which are based on three view correspondences of (i) three points and one line and the novel case of (ii) three points and two lines through two of the points. These problems are too difficult to be efficiently solved by the state of the art Gröbner basis methods. Our method is based on a new...]]></description>
        </item>
        <item>
            <title><![CDATA[Optimising for Interpretability: Convolutional Dynamic Alignment Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9968133</link>
            <guid>https://ieeexplore.ieee.org/document/9968133</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We introduce a new family of neural network models called Convolutional Dynamic Alignment Networks (CoDA Nets), which are performant classifiers with a high degree of inherent interpretability. Their core building blocks are Dynamic Alignment Units (DAUs), which are optimised to transform their inputs with dynamically computed weight vectors that align with task-relevant patterns. As a result, CoD...]]></description>
        </item>
        <item>
            <title><![CDATA[Sparse Tensor-Based Multiscale Representation for Point Cloud Geometry Compression]]></title>
            <link>https://ieeexplore.ieee.org/document/9968173</link>
            <guid>https://ieeexplore.ieee.org/document/9968173</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This study develops a unified Point Cloud Geometry (PCG) compression method through the processing of multiscale sparse tensor-based voxelized PCG. We call this compression method SparsePCGC. The proposed SparsePCGC is a low complexity solution because it only performs the convolutions on sparsely-distributed Most-Probable Positively-Occupied Voxels (MP-POV). The multiscale representation also all...]]></description>
        </item>
        <item>
            <title><![CDATA[GH-Feat: Learning Versatile Generative Hierarchical Features From GANs]]></title>
            <link>https://ieeexplore.ieee.org/document/9968154</link>
            <guid>https://ieeexplore.ieee.org/document/9968154</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent years witness the tremendous success of generative adversarial networks (GANs) in synthesizing photo-realistic images. GAN generator learns to compose realistic images and reproduce the real data distribution. Through that, a hierarchical visual feature with multi-level semantics spontaneously emerges. In this work we investigate that such a generative feature learned from image synthesis e...]]></description>
        </item>
        <item>
            <title><![CDATA[A Survey on Deep Learning Technique for Video Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9966836</link>
            <guid>https://ieeexplore.ieee.org/document/9966836</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Video segmentation—partitioning video frames into multiple segments or objects—plays a critical role in a broad range of practical applications, from enhancing visual effects in movie, to understanding scenes in autonomous driving, to creating virtual background in video conferencing. Recently, with the renaissance of connectionism in computer vision, there has been an influx of deep learning base...]]></description>
        </item>
        <item>
            <title><![CDATA[Robust Point Cloud Segmentation with Noisy Annotations]]></title>
            <link>https://ieeexplore.ieee.org/document/9966842</link>
            <guid>https://ieeexplore.ieee.org/document/9966842</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Point cloud segmentation is a fundamental task in 3D. Despite recent progress on point cloud segmentation with the power of deep networks, current learning methods based on the clean label assumptions may fail with noisy labels. Yet, class labels are often mislabeled at both instance-level and boundary-level in real-world datasets. In this work, we take the lead in solving the instance-level label...]]></description>
        </item>
        <item>
            <title><![CDATA[Structure Evolution on Manifold for Graph Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9966846</link>
            <guid>https://ieeexplore.ieee.org/document/9966846</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph has been widely used in various applications, while how to optimize the graph is still an open question. In this paper, we propose a framework to optimize the graph structure via structure evolution on graph manifold. We first define the graph manifold and search the best graph structure on this manifold. Concretely, associated with the data features and the prediction results of a given tas...]]></description>
        </item>
        <item>
            <title><![CDATA[Rectification-based Knowledge Retention for Task Incremental Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9966835</link>
            <guid>https://ieeexplore.ieee.org/document/9966835</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In the task incremental learning problem, deep learning models suffer from catastrophic forgetting of previously seen classes/tasks as they are trained on new classes/tasks. This problem becomes even harder when some of the test classes do not belong to the training class set, i.e., the task incremental generalized zero-shot learning problem. We propose a novel approach to address the task increme...]]></description>
        </item>
        <item>
            <title><![CDATA[$\mathcal {X}$-Metric: An N-Dimensional Information-Theoretic Framework for Groupwise Registration and Deep Combined Computing]]></title>
            <link>https://ieeexplore.ieee.org/document/9965747</link>
            <guid>https://ieeexplore.ieee.org/document/9965747</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper presents a generic probabilistic framework for estimating the statistical dependency and finding the anatomical correspondences among an arbitrary number of medical images. The method builds on a novel formulation of the $N$-dimensional joint intensity distribution by representing the common anatomy as latent variables and estimating the appearance model with nonparametric estimators. T...]]></description>
        </item>
        <item>
            <title><![CDATA[Spatial-Temporal Transformer for Video Snapshot Compressive Imaging]]></title>
            <link>https://ieeexplore.ieee.org/document/9965744</link>
            <guid>https://ieeexplore.ieee.org/document/9965744</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Video snapshot compressive imaging (SCI) captures multiple sequential video frames by a single measurement using the idea of computational imaging. The underlying principle is to modulate high-speed frames through different masks and these modulated frames are summed to a single measurement captured by a low-speed 2D sensor (dubbed optical encoder); following this, algorithms are employed to recon...]]></description>
        </item>
        <item>
            <title><![CDATA[Micro-supervised Disturbance Learning: A Perspective of Representation Probability Distribution]]></title>
            <link>https://ieeexplore.ieee.org/document/9965741</link>
            <guid>https://ieeexplore.ieee.org/document/9965741</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The instability is shown in the existing methods of representation learning based on Euclidean distance under a broad set of conditions. Furthermore, the scarcity and high cost of labels prompt us to explore more expressive representation learning methods which depends on as few labels as possible. To address above issues, the small-perturbation ideology is firstly introduced on the representation...]]></description>
        </item>
        <item>
            <title><![CDATA[Supervised Anomaly Detection via Conditional Generative Adversarial Network and Ensemble Active Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9965739</link>
            <guid>https://ieeexplore.ieee.org/document/9965739</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Anomaly detection has wide applications in machine intelligence but is still a difficult unsolved problem. Major challenges include the rarity of labeled anomalies and it is a class highly imbalanced problem. Traditional unsupervised anomaly detectors are suboptimal while supervised models can easily make biased predictions towards normal data. In this paper, we present a new supervised anomaly de...]]></description>
        </item>
        <item>
            <title><![CDATA[State-Regularized Recurrent Neural Networks to Extract Automata and Explain Predictions]]></title>
            <link>https://ieeexplore.ieee.org/document/9965745</link>
            <guid>https://ieeexplore.ieee.org/document/9965745</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recurrent neural networks are a widely used class of neural architectures. They have, however, two shortcomings. First, they are often treated as black-box models and as such it is difficult to understand what exactly they learn as well as how they arrive at a particular prediction. Second, they tend to work poorly on sequences requiring long-term memorization, despite having this capacity in prin...]]></description>
        </item>
        <item>
            <title><![CDATA[One-Hot Graph Encoder Embedding]]></title>
            <link>https://ieeexplore.ieee.org/document/9964227</link>
            <guid>https://ieeexplore.ieee.org/document/9964227</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper we propose a lightning fast graph embedding method called one-hot graph encoder embedding. It has a linear computational complexity and the capacity to process billions of edges within minutes on standard PC — making it an ideal candidate for huge graph processing. It is applicable to either adjacency matrix or graph Laplacian, and can be viewed as a transformation of the spectral em...]]></description>
        </item>
        <item>
            <title><![CDATA[Geodesic Models with Convexity Shape Prior]]></title>
            <link>https://ieeexplore.ieee.org/document/9964444</link>
            <guid>https://ieeexplore.ieee.org/document/9964444</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The minimal geodesic models established upon the eikonal equation framework are capable of finding suitable solutions in various image segmentation scenarios. Existing geodesic-based segmentation approaches usually exploit image features in conjunction with geometric regularization terms, such as Euclidean curve length or curvature-penalized length, for computing geodesic curves. In this paper, we...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning by Seeing More Classes]]></title>
            <link>https://ieeexplore.ieee.org/document/9964413</link>
            <guid>https://ieeexplore.ieee.org/document/9964413</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Traditional pattern recognition models usually assume a fixed and identical number of classes during both training and inference stages. In this paper, we study an interesting but ignored question: can increasing the number of classes during training improve the generalization and reliability performance? For a $k$-class problem, instead of training with only these $k$ classes, we propose to learn...]]></description>
        </item>
        <item>
            <title><![CDATA[TransCenter: Transformers With Dense Representations for Multiple-Object Tracking]]></title>
            <link>https://ieeexplore.ieee.org/document/9964258</link>
            <guid>https://ieeexplore.ieee.org/document/9964258</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Transformers have proven superior performance for a wide variety of tasks since they were introduced. In recent years, they have drawn attention from the vision community in tasks such as image classification and object detection. Despite this wave, an accurate and efficient multiple-object tracking (MOT) method based on transformers is yet to be designed. We argue that the direct application of a...]]></description>
        </item>
        <item>
            <title><![CDATA[A Differentiable Perspective for Multi-View Spectral Clustering With Flexible Extension]]></title>
            <link>https://ieeexplore.ieee.org/document/9964300</link>
            <guid>https://ieeexplore.ieee.org/document/9964300</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multi-view clustering aims to discover common patterns from multi-source data, whose generality is remarkable. Compared with traditional methods, deep learning methods are data-driven and have a larger search space for solutions, which may find a better solution to the problem. In addition, more considerations can be introduced by loss functions, so deep models are highly reusable. However, compar...]]></description>
        </item>
        <item>
            <title><![CDATA[Interpretable by Design: Learning Predictors by Composing Interpretable Queries]]></title>
            <link>https://ieeexplore.ieee.org/document/9964439</link>
            <guid>https://ieeexplore.ieee.org/document/9964439</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[There is a growing concern about typically opaque decision-making with high-performance machine learning algorithms. Providing an explanation of the reasoning process in domain-specific terms can be crucial for adoption in risk-sensitive domains such as healthcare. We argue that machine learning algorithms should be interpretable by design and that the language in which these interpretations are e...]]></description>
        </item>
        <item>
            <title><![CDATA[TransVOD: End-to-End Video Object Detection With Spatial-Temporal Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/9960850</link>
            <guid>https://ieeexplore.ieee.org/document/9960850</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Detection Transformer (DETR) and Deformable DETR have been proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance as previous complex hand-crafted detectors. However, their performance on Video Object Detection (VOD) has not been well explored. In this paper, we present TransVOD, the first end-to-end video object detection system b...]]></description>
        </item>
        <item>
            <title><![CDATA[Curriculum-Based Asymmetric Multi-Task Reinforcement Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9960813</link>
            <guid>https://ieeexplore.ieee.org/document/9960813</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We introduce CAMRL, the first curriculum-based asymmetric multi-task learning (AMTL) algorithm for dealing with multiple reinforcement learning (RL) tasks altogether. To mitigate the negative influence of customizing the one-off training order in curriculum-based AMTL, CAMRL switches its training mode between parallel single-task RL and asymmetric multi-task RL (MTRL), according to an indicator re...]]></description>
        </item>
        <item>
            <title><![CDATA[Cell Multi-Bernoulli (Cell-MB) Sensor Control for Multi-Object Search-While-Tracking (SWT)]]></title>
            <link>https://ieeexplore.ieee.org/document/9960819</link>
            <guid>https://ieeexplore.ieee.org/document/9960819</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Information-driven control can be used to develop intelligent sensors that can optimize their measurement value based on environmental feedback. In object tracking applications, sensor actions are chosen based on the expected reduction in uncertainty also known as information gain. Random finite set (RFS) theory provides a formalism for quantifying and estimating information gain in multi-object t...]]></description>
        </item>
        <item>
            <title><![CDATA[ABINet++: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Spotting]]></title>
            <link>https://ieeexplore.ieee.org/document/9960802</link>
            <guid>https://ieeexplore.ieee.org/document/9960802</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Scene text spotting is of great importance to the computer vision community due to its wide variety of applications. Recent methods attempt to introduce linguistic knowledge for challenging recognition rather than pure visual classification. However, how to effectively model the linguistic rules in end-to-end deep networks remains a research challenge. In this paper, we argue that the limited capa...]]></description>
        </item>
        <item>
            <title><![CDATA[Intrinsic Image Transfer for Illumination Manipulation]]></title>
            <link>https://ieeexplore.ieee.org/document/9961945</link>
            <guid>https://ieeexplore.ieee.org/document/9961945</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper presents a novel intrinsic image transfer (IIT) algorithm for image illumination manipulation, which creates a local image translation between two illumination surfaces. This model is built on an optimization-based framework composed of illumination, reflectance and content photo-realistic losses, respectively. Each loss is firstly defined on the corresponding sub-layers factorized by a...]]></description>
        </item>
        <item>
            <title><![CDATA[SuperFast: 200$\boldsymbol{\times }$ Video Frame Interpolation via Event Camera]]></title>
            <link>https://ieeexplore.ieee.org/document/9962797</link>
            <guid>https://ieeexplore.ieee.org/document/9962797</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Traditional frame-based video frame interpolation (VFI) methods rely on the linear motion assumption and brightness invariance assumption, which may lead to fatal errors confronting the scenarios with high-speed motions. To tackle the above challenge, inspired by the advantages of event cameras on asynchronously recording brightness changes at each pixel, we propose a Fast-Slow joint synthesis fra...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised Global and Local Homography Estimation with Motion Basis Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9956874</link>
            <guid>https://ieeexplore.ieee.org/document/9956874</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we introduce a new framework for unsupervised deep homography estimation. Our contributions are 3 folds. First, unlike previous methods that regress 4 offsets for a homography, we propose a homography flow representation, which can be estimated by a weighted sum of 8 pre-defined homography flow bases. Second, considering a homography contains 8 Degree-of-Freedoms (DOFs) that is much...]]></description>
        </item>
        <item>
            <title><![CDATA[PatchMix Augmentation to Identify Causal Features in Few-shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9956886</link>
            <guid>https://ieeexplore.ieee.org/document/9956886</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The task of Few-shot learning (FSL) aims to transfer the knowledge learned from base categories with sufficient labelled data to novel categories with scarce known information. It is currently an important research question and has great practical values in the real-world applications. Despite extensive previous efforts are made on few-shot learning tasks, we emphasize that most existing methods d...]]></description>
        </item>
        <item>
            <title><![CDATA[Semi-Dense Feature Matching with Transformers and its Applications in Multiple-View Geometry]]></title>
            <link>https://ieeexplore.ieee.org/document/9956767</link>
            <guid>https://ieeexplore.ieee.org/document/9956767</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present a novel method for local image feature matching. Instead of performing image feature detection, description, and matching sequentially, we propose to first establish pixel-wise dense matches at a coarse level and later refine the good matches at a fine level. In contrast to dense methods that use a cost volume to search correspondences, we use self and cross attention layers in Transfor...]]></description>
        </item>
        <item>
            <title><![CDATA[Reward-Adaptive Reinforcement Learning: Dynamic Policy Gradient Optimization for Bipedal Locomotion]]></title>
            <link>https://ieeexplore.ieee.org/document/9956746</link>
            <guid>https://ieeexplore.ieee.org/document/9956746</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Controlling a non-statically bipedal robot is challenging due to the complex dynamics and multi-criterion optimization involved. Recent works have demonstrated the effectiveness of deep reinforcement learning (DRL) for simulation and physical robots. In these methods, the rewards from different criteria are normally summed to learn a scalar function. However, a scalar is less informative and may b...]]></description>
        </item>
        <item>
            <title><![CDATA[Contrastive Positive Sample Propagation along the Audio-Visual Event Line]]></title>
            <link>https://ieeexplore.ieee.org/document/9956870</link>
            <guid>https://ieeexplore.ieee.org/document/9956870</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Visual and audio signals often coexist in natural environments, forming audio-visual events (AVEs). Given a video, we aim to localize video segments containing an AVE and identify its category. It is pivotal to learn the discriminative features for each video segment. Unlike existing work focusing on audio-visual feature fusion, in this paper, we propose a new contrastive positive sample propagati...]]></description>
        </item>
        <item>
            <title><![CDATA[AlphaPose: Whole-Body Regional Multi-Person Pose Estimation and Tracking in Real-Time]]></title>
            <link>https://ieeexplore.ieee.org/document/9954214</link>
            <guid>https://ieeexplore.ieee.org/document/9954214</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Accurate whole-body multi-person pose estimation and tracking is an important yet challenging topic in computer vision. To capture the subtle actions of humans for complex behavior analysis, whole-body pose estimation including the face, body, hand and foot is essential over conventional body-only pose estimation. In this paper, we present AlphaPose, a system that can perform accurate whole-body p...]]></description>
        </item>
        <item>
            <title><![CDATA[Multi-Granularity Anchor-Contrastive Representation Learning for Semi-Supervised Skeleton-Based Action Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9954217</link>
            <guid>https://ieeexplore.ieee.org/document/9954217</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In the semi-supervised skeleton-based action recognition task, obtaining more discriminative information from both labeled and unlabeled data is a challenging problem. As the current mainstream approach, contrastive learning can learn more representations of augmented data, which can be considered as the pretext task of action recognition. However, such a method still confronts three main limitati...]]></description>
        </item>
        <item>
            <title><![CDATA[Differentiable Hierarchical Optimal Transport for Robust Multi-View Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9953569</link>
            <guid>https://ieeexplore.ieee.org/document/9953569</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Traditional multi-view learning methods often rely on two assumptions: ($i$) the samples in different views are well-aligned, and ($ii$) their representations obey the same distribution in a latent space. Unfortunately, these two assumptions may be questionable in practice, which limits the application of multi-view learning. In this work, we propose a differentiable hierarchical optimal transport...]]></description>
        </item>
        <item>
            <title><![CDATA[Mutual-Assistance Learning for Standalone Mono-Modality Survival Analysis of Human Cancers]]></title>
            <link>https://ieeexplore.ieee.org/document/9953577</link>
            <guid>https://ieeexplore.ieee.org/document/9953577</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Current survival analysis of cancer confronts two key issues. While comprehensive perspectives provided by data from multiple modalities often promote the performance of survival models, data with inadequate modalities at testing phase are more ubiquitous in clinical scenarios, which makes multi-modality approaches not applicable. Additionally, incomplete observations (i.e., censored instances) br...]]></description>
        </item>
        <item>
            <title><![CDATA[Geometry Regularized Autoencoders]]></title>
            <link>https://ieeexplore.ieee.org/document/9950332</link>
            <guid>https://ieeexplore.ieee.org/document/9950332</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[A fundamental task in data exploration is to extract low dimensional representations that capture intrinsic geometry in data, especially for faithfully visualizing data in two or three dimensions. Common approaches use kernel methods for manifold learning. However, these methods typically only provide an embedding of the input data and cannot extend naturally to new data points. Autoencoders have ...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning View-Based Graph Convolutional Network for Multi-View 3D Shape Analysis]]></title>
            <link>https://ieeexplore.ieee.org/document/9947327</link>
            <guid>https://ieeexplore.ieee.org/document/9947327</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[View-based approach that recognizes 3D shape through its projected 2D images has achieved state-of-the-art results for 3D shape recognition. The major challenges are how to aggregate multi-view features and deal with 3D shapes in arbitrary poses. We propose two versions of a novel view-based Graph Convolutional Network, dubbed view-GCN and view-GCN++, to recognize 3D shape based on graph represent...]]></description>
        </item>
        <item>
            <title><![CDATA[Referring Segmentation Via Encoder-Fused Cross-Modal Attention Network]]></title>
            <link>https://ieeexplore.ieee.org/document/9946403</link>
            <guid>https://ieeexplore.ieee.org/document/9946403</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper focuses on referring segmentation, which aims to selectively segment the corresponding visual region in an image (or video) according to the referring expression. However, the existing methods usually consider the interaction between multi-modal features at the decoding end of the network. Specifically, they interact the visual features of each scale with language respectively, thus ign...]]></description>
        </item>
        <item>
            <title><![CDATA[Contrastive Bayesian Analysis for Deep Metric Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9946419</link>
            <guid>https://ieeexplore.ieee.org/document/9946419</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent methods for deep metric learning have been focusing on designing different contrastive loss functions between positive and negative pairs of samples so that the learned feature embedding is able to pull positive samples of the same class closer and push negative samples from different classes away from each other. In this work, we recognize that there is a significant semantic gap between f...]]></description>
        </item>
        <item>
            <title><![CDATA[Conditional Wasserstein Generator]]></title>
            <link>https://ieeexplore.ieee.org/document/9944913</link>
            <guid>https://ieeexplore.ieee.org/document/9944913</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The statistical distance of conditional distributions is an essential element of generating target data given some data as in video prediction. We establish how the statistical distances between two joint distributions are related to those between two conditional distributions for three popular statistical distances: f-divergence, Wasserstein distance, and integral probability metrics. Such charac...]]></description>
        </item>
        <item>
            <title><![CDATA[DMRNet++: Learning Discriminative Features with Decoupled Networks and Enriched Pairs for One-Step Person Search]]></title>
            <link>https://ieeexplore.ieee.org/document/9944858</link>
            <guid>https://ieeexplore.ieee.org/document/9944858</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Person search aims at localizing and recognizing query persons from raw video frames, which is a combination of two sub-tasks, i.e., pedestrian detection and person re-identification. The dominant fashion is termed as the one-step person search that jointly optimizes detection and identification in a unified network, exhibiting higher efficiency. However, there remain major challenges: (i) conflic...]]></description>
        </item>
        <item>
            <title><![CDATA[The Shape of Learning Curves: A Review]]></title>
            <link>https://ieeexplore.ieee.org/document/9944190</link>
            <guid>https://ieeexplore.ieee.org/document/9944190</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Learning curves provide insight into the dependence of a learner&#39;s generalization performance on the training set size. This important tool can be used for model selection, to predict the effect of more training data, and to reduce the computational complexity of model training and hyperparameter tuning. This review recounts the origins of the term, provides a formal definition of the learning cur...]]></description>
        </item>
        <item>
            <title><![CDATA[Rethinking Label Flipping Attack: From Sample Masking to Sample Thresholding]]></title>
            <link>https://ieeexplore.ieee.org/document/9944159</link>
            <guid>https://ieeexplore.ieee.org/document/9944159</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Nowadays, machine learning (ML) and deep learning (DL) methods have become fundamental building blocks for a wide range of AI applications. The popularity of these methods also makes them widely exposed to malicious attacks, which may cause severe security concerns. To understand the security properties of the ML/DL methods, researchers have recently started to turn their focus to adversarial atta...]]></description>
        </item>
        <item>
            <title><![CDATA[Adaptive Transfer Kernel Learning for Transfer Gaussian Process Regression]]></title>
            <link>https://ieeexplore.ieee.org/document/9937157</link>
            <guid>https://ieeexplore.ieee.org/document/9937157</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Transfer regression is a practical and challenging problem with important applications in various domains, such as engineering design and localization. Capturing the relatedness of different domains is the key of adaptive knowledge transfer. In this paper, we investigate an effective way of explicitly modelling domain relatedness through transfer kernel, a transfer-specified kernel that considers ...]]></description>
        </item>
        <item>
            <title><![CDATA[Dual Instance-Consistent Network for Cross-Domain Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/9935311</link>
            <guid>https://ieeexplore.ieee.org/document/9935311</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Cross-domain object detection aims to transfer knowledge from a labeled dataset to an unlabeled dataset. Most existing methods apply a unified embedding model to generate the tightly coupled source and target descriptions for domain alignment, leading to the destroyed feature distribution of the target domain because the embedding model is mainly controlled by the source domain. To reduce the repr...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Learning for Instance Retrieval: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9933854</link>
            <guid>https://ieeexplore.ieee.org/document/9933854</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In recent years a vast amount of visual content has been generated and shared from many fields, such as social media platforms, medical imaging, and robotics. This abundance of content creation and sharing has introduced new challenges, particularly that of searching databases for similar content — Content Based Image Retrieval (CBIR) — a long-established research area in which improved efficiency...]]></description>
        </item>
        <item>
            <title><![CDATA[Human Collective Intelligence Inspired Multi-View Representation Learning — Enabling View Communication by Simulating Human Communication Mechanism]]></title>
            <link>https://ieeexplore.ieee.org/document/9933914</link>
            <guid>https://ieeexplore.ieee.org/document/9933914</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In real-world applications, we often encounter multi-view learning tasks where we need to learn from multiple sources of data or use multiple sources of data to make decisions. Multi-view representation learning, which can learn a unified representation from multiple data sources, is a key pre-task of multi-view learning and plays a significant role in real-world applications. Accordingly, how to ...]]></description>
        </item>
        <item>
            <title><![CDATA[Transferring Knowledge from Text to Video: Zero-Shot Anticipation for Procedural Actions]]></title>
            <link>https://ieeexplore.ieee.org/document/9933901</link>
            <guid>https://ieeexplore.ieee.org/document/9933901</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Can we teach a robot to recognize and make predictions for activities that it has never seen before? We tackle this problem by learning models for video from text. This paper presents a hierarchical model that generalizes instructional knowledge from large-scale text corpora and transfers the knowledge to video. Given a portion of an instructional video, our model recognizes and predicts coherent ...]]></description>
        </item>
        <item>
            <title><![CDATA[CATs++: Boosting Cost Aggregation with Convolutions and Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/9933865</link>
            <guid>https://ieeexplore.ieee.org/document/9933865</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Cost aggregation is a process in image matching tasks that aims to disambiguate the noisy matching scores. Existing methods generally tackle this by hand-crafted or CNN-based methods, which either lack robustness to severe deformations or inherit the limitation of CNNs that fail to discriminate incorrect matches due to limited receptive fields and inadaptability. In this paper, we introduce Cost A...]]></description>
        </item>
        <item>
            <title><![CDATA[Large-scale Unsupervised Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9933726</link>
            <guid>https://ieeexplore.ieee.org/document/9933726</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Empowered by large datasets, e.g., ImageNet and MS COCO, unsupervised learning on large-scale data has enabled significant advances for classification tasks. However, whether the large-scale unsupervised semantic segmentation can be achieved remains unknown. There are two major challenges: i) we need a large-scale benchmark for assessing algorithms; ii) we need to develop methods to simultaneously...]]></description>
        </item>
        <item>
            <title><![CDATA[When Age-Invariant Face Recognition Meets Face Age Synthesis: A Multi-Task Learning Framework and A New Benchmark]]></title>
            <link>https://ieeexplore.ieee.org/document/9931965</link>
            <guid>https://ieeexplore.ieee.org/document/9931965</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[To minimize the impact of age variation on face recognition, age-invariant face recognition (AIFR) extracts identity-related discriminative features by minimizing the correlation between identity- and age-related features while face age synthesis (FAS) eliminates age variation by converting the faces in different age groups to the same group. However, AIFR lacks visual results for model interpreta...]]></description>
        </item>
        <item>
            <title><![CDATA[NeX360: Real-time All-around View Synthesis with Neural Basis Expansion]]></title>
            <link>https://ieeexplore.ieee.org/document/9931981</link>
            <guid>https://ieeexplore.ieee.org/document/9931981</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present NeX, a new approach to novel view synthesis based on enhancements of multiplane images (MPI) that can reproduce view-dependent effects in real time. Unlike traditional MPI, our technique parameterizes each pixel as a linear combination of spherical basis functions learned from a neural network to model view-dependent effects and uses a hybrid implicit-explicit modeling strategy to impro...]]></description>
        </item>
        <item>
            <title><![CDATA[Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9931970</link>
            <guid>https://ieeexplore.ieee.org/document/9931970</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose self-adaptive training—a unified training algorithm that dynamically calibrates and enhances training processes by model predictions without incurring an extra computational cost—to advance both supervised and self-supervised learning of deep neural networks. We analyze the training dynamics of deep networks on training data that are corrupted by, e.g., random noise and adversarial exam...]]></description>
        </item>
        <item>
            <title><![CDATA[VLT: Vision-Language Transformer and Query Generation for Referring Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9932025</link>
            <guid>https://ieeexplore.ieee.org/document/9932025</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose a Vision-Language Transformer (VLT) framework for referring segmentation to facilitate deep interactions among multi-modal information and enhance the holistic understanding to vision-language features. There are different ways to understand the dynamic emphasis of a language expression, especially when interacting with the image. However, the learned queries in existing transformer wor...]]></description>
        </item>
        <item>
            <title><![CDATA[Neural Architecture Search via Proxy Validation]]></title>
            <link>https://ieeexplore.ieee.org/document/9931480</link>
            <guid>https://ieeexplore.ieee.org/document/9931480</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper searches for the optimal neural architecture by minimizing a proxy of validation loss. Existing neural architecture search (NAS) methods used to discover the optimal neural architecture that best fits the validation examples given the up-to-date network weights. These intermediate validation results are invaluable but have not been fully explored. We propose to approximate the validatio...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised Pre-Training for Detection Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/9926201</link>
            <guid>https://ieeexplore.ieee.org/document/9926201</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[DEtection TRansformer (DETR) for object detection reaches competitive performance compared with Faster R-CNN via a transformer encoder-decoder architecture. However, trained with scratch transformers, DETR needs large-scale training data and an extreme long training schedule even on COCO dataset. Inspired by the great success of pre-training transformers in natural language processing, we propose ...]]></description>
        </item>
        <item>
            <title><![CDATA[Fast Differentiable Matrix Square Root and Inverse Square Root]]></title>
            <link>https://ieeexplore.ieee.org/document/9926140</link>
            <guid>https://ieeexplore.ieee.org/document/9926140</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Computing the matrix square root and its inverse in a differentiable manner is important in a variety of computer vision tasks. Previous methods either adopt the Singular Value Decomposition (SVD) to explicitly factorize the matrix or use the Newton-Schulz iteration (NS iteration) to derive the approximate solution. However, both methods are not computationally efficient enough in either the forwa...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Representation for Clustering Via Prototype Scattering and Positive Sampling]]></title>
            <link>https://ieeexplore.ieee.org/document/9926200</link>
            <guid>https://ieeexplore.ieee.org/document/9926200</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Existing deep clustering methods rely on either contrastive or non-contrastive representation learning for downstream clustering task. Contrastive-based methods thanks to negative pairs learn uniform representations for clustering, in which negative pairs, however, may inevitably lead to the class collision issue and consequently compromise the clustering performance. Non-contrastive-based methods...]]></description>
        </item>
        <item>
            <title><![CDATA[Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/9914676</link>
            <guid>https://ieeexplore.ieee.org/document/9914676</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Tracking a time-varying indefinite number of objects in a video sequence over time remains a challenge despite recent advances in the field. Most existing approaches are not able to properly handle multi-object tracking challenges such as occlusion, in part because they ignore long-term temporal information. To address these shortcomings, we present MO3TR: a truly end-to-end Transformer-based onli...]]></description>
        </item>
        <item>
            <title><![CDATA[Interpretable Compositional Representations for Robust Few-Shot Generalization]]></title>
            <link>https://ieeexplore.ieee.org/document/9913725</link>
            <guid>https://ieeexplore.ieee.org/document/9913725</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose Recognition as Part Composition (RPC), an image encoding approach inspired by human cognition. It is based on the cognitive theory that humans recognize complex objects by components, and that they build a small compact vocabulary of concepts to represent each instance with. RPC encodes images by first decomposing them into salient parts, and then encoding each part as a mixture of a sm...]]></description>
        </item>
        <item>
            <title><![CDATA[Revisiting Viewing Graph Solvability: an Effective Approach Based on Cycle Consistency]]></title>
            <link>https://ieeexplore.ieee.org/document/9913729</link>
            <guid>https://ieeexplore.ieee.org/document/9913729</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In the structure from motion, the viewing graph is a graph where the vertices correspond to cameras (or images) and the edges represent the fundamental matrices. We provide a new formulation and an algorithm for determining whether a viewing graph is solvable, i.e., uniquely determines a set of projective cameras. The known theoretical conditions either do not fully characterize the solvability of...]]></description>
        </item>
        <item>
            <title><![CDATA[Towards JPEG-Resistant Image Forgery Detection and Localization Via Self-Supervised Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/9904872</link>
            <guid>https://ieeexplore.ieee.org/document/9904872</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[With wide applications of image editing tools, forged images (splicing, copy-move, removal and etc.) have been becoming great public concerns. Although existing image forgery localization methods could achieve fairly good results on several public datasets, most of them perform poorly when the forged images are JPEG compressed as they are usually done in social networks. To tackle this issue, in t...]]></description>
        </item>
        <item>
            <title><![CDATA[Token Selection is a Simple Booster for Vision Transformers]]></title>
            <link>https://ieeexplore.ieee.org/document/9903081</link>
            <guid>https://ieeexplore.ieee.org/document/9903081</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Vision transformers have recently attained state-of-the-art results in visual recognition tasks. Their success is largely attributed to the self-attention component, which models the global dependencies among the image patches (tokens) and aggregates them into higher-level features. However, self-attention brings significant training difficulties to ViTs. Many recent works thus develop various new...]]></description>
        </item>
        <item>
            <title><![CDATA[MCTS with Refinement for Proposals Selection Games in Scene Understanding]]></title>
            <link>https://ieeexplore.ieee.org/document/9903516</link>
            <guid>https://ieeexplore.ieee.org/document/9903516</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose a novel method applicable in many scene understanding problems that adapts the Monte Carlo Tree Search (MCTS) algorithm, originally designed to learn to play games of high-state complexity. From a generated pool of proposals, our method jointly selects and optimizes proposals that minimize the objective term. In our first application for floor plan reconstruction from point clouds, our ...]]></description>
        </item>
        <item>
            <title><![CDATA[Transformer for Image Harmonization and Beyond]]></title>
            <link>https://ieeexplore.ieee.org/document/9893399</link>
            <guid>https://ieeexplore.ieee.org/document/9893399</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image harmonization, aiming to make composite images look more realistic, is an important and challenging task. The composite, synthesized by combining foreground from one image with background from another image, inevitably suffers from the issue of inharmonious appearance caused by distinct imaging conditions, i.e., lights. Current solutions mainly adopt an encoder-decoder architecture with conv...]]></description>
        </item>
        <item>
            <title><![CDATA[BimodalPS: Causes and Corrections for Bimodal Multi-path in Phase-Shifting Structured Light Scanners]]></title>
            <link>https://ieeexplore.ieee.org/document/9889210</link>
            <guid>https://ieeexplore.ieee.org/document/9889210</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Structured light illumination is an active 3D scanning technique based on projecting and capturing a set of striped patterns and measuring the warping of the patterns as they reflect off a target object&#39;s surface. As designed, each pixel in the camera sees exactly one pixel from the projector; however, there are multi-path situations where a camera pixel sees light from multiple projector position...]]></description>
        </item>
        <item>
            <title><![CDATA[MPS-NeRF: Generalizable 3D Human Rendering From Multiview Images]]></title>
            <link>https://ieeexplore.ieee.org/document/9888037</link>
            <guid>https://ieeexplore.ieee.org/document/9888037</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[There has been rapid progress recently on 3D human rendering, including novel view synthesis and pose animation, based on the advances of neural radiance fields (NeRF). However, most existing methods focus on person-specific training and their training typically requires multi-view videos. This paper deals with a new challenging task – rendering novel views and novel poses for a person unseen in t...]]></description>
        </item>
        <item>
            <title><![CDATA[StARformer: Transformer with State-Action-Reward Representations for Robot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9878209</link>
            <guid>https://ieeexplore.ieee.org/document/9878209</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Reinforcement Learning (RL) can be considered as a sequence modeling task, where an agent employs a sequence of past state-action-reward experiences to predict a sequence of future actions. In this work, we propose State-Action-Reward Transformer (StARformer), a Transformer architecture for robot learning with image inputs, which explicitly models short-term state-action-reward representations (St...]]></description>
        </item>
        <item>
            <title><![CDATA[Wide-Baseline Light Fields using Ellipsoidal Mirrors]]></title>
            <link>https://ieeexplore.ieee.org/document/9878227</link>
            <guid>https://ieeexplore.ieee.org/document/9878227</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Traditional hand-held light field cameras only observe a small fraction of the cone of light emitted by a scene point. As a consequence, the study of interesting angular effects like iridescence are beyond the scope of such cameras. This paper envisions a new design for sensing light fields with wide baselines, so as to sense a significantly larger fraction of the cone of light emitted by scene po...]]></description>
        </item>
        <item>
            <title><![CDATA[Bayesian Embeddings for Few-Shot Open World Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9875990</link>
            <guid>https://ieeexplore.ieee.org/document/9875990</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[As autonomous decision-making agents move from narrow operating environments to unstructured worlds, learning systems must move from a closed-world formulation to an open-world and few-shot setting in which agents continuously learn new classes from small amounts of information. This stands in stark contrast to modern machine learning systems that are typically designed with a known set of classes...]]></description>
        </item>
        <item>
            <title><![CDATA[Physics to the Rescue: Deep Non-Line-of-Sight Reconstruction for High-Speed Imaging]]></title>
            <link>https://ieeexplore.ieee.org/document/9874257</link>
            <guid>https://ieeexplore.ieee.org/document/9874257</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Computational approach to imaging around the corner, or non-line-of-sight (NLOS) imaging, is becoming a reality thanks to major advances in imaging hardware and reconstruction algorithms. A recent development towards practical NLOS imaging, Nam et al. [1] demonstrated a high-speed non-confocal imaging system that operates at 5 Hz, 100x faster than the prior art. This enormous gain in acquisition r...]]></description>
        </item>
        <item>
            <title><![CDATA[Towards Mixed-State Coded Diffraction Imaging]]></title>
            <link>https://ieeexplore.ieee.org/document/9872132</link>
            <guid>https://ieeexplore.ieee.org/document/9872132</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Coherent diffraction imaging (CDI) is a computational technique for reconstructing a complex-valued optical field from an intensity measurement. The approach is to illuminate an object with a coherent beam of light to form a diffraction pattern, and use a phase retrieval algorithm to reconstruct the object&#39;s complex transmittance from the measurement. However, as the name implies, conventional CDI...]]></description>
        </item>
        <item>
            <title><![CDATA[P2T: Pyramid Pooling Transformer for Scene Understanding]]></title>
            <link>https://ieeexplore.ieee.org/document/9870559</link>
            <guid>https://ieeexplore.ieee.org/document/9870559</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, the vision transformer has achieved great success by pushing the state-of-the-art of various vision tasks. One of the most challenging problems in the vision transformer is that the large sequence length of image tokens leads to high computational cost (quadratic complexity). A popular solution to this problem is to use a single pooling operation to reduce the sequence length. This paper...]]></description>
        </item>
        <item>
            <title><![CDATA[PS $^{2}$ F: Polarized Spiral Point Spread Function for Single-Shot 3D Sensing]]></title>
            <link>https://ieeexplore.ieee.org/document/9869297</link>
            <guid>https://ieeexplore.ieee.org/document/9869297</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose a compact snapshot monocular depth estimation technique that relies on an engineered point spread function (PSF). Traditional approaches used in microscopic super-resolution imaging such as the Double-Helix PSF (DHPSF) are ill-suited for scenes that are more complex than a sparse set of point light sources. We show, using the Cramér-Rao lower bound, that separating the two lobes of the ...]]></description>
        </item>
        <item>
            <title><![CDATA[Semi-Supervised and Unsupervised Deep Visual Learning: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9866825</link>
            <guid>https://ieeexplore.ieee.org/document/9866825</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[State-of-the-art deep learning models are often trained with a large amount of costly labeled training data. However, requiring exhaustive manual annotations may degrade the model&#39;s generalizability in the limited-label regime.Semi-supervised learning and unsupervised learning offer promising paradigms to learn from an abundance of unlabeled visual data. Recent progress in these paradigms has indi...]]></description>
        </item>
        <item>
            <title><![CDATA[Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks]]></title>
            <link>https://ieeexplore.ieee.org/document/9864267</link>
            <guid>https://ieeexplore.ieee.org/document/9864267</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[New classes arise frequently in our ever-changing world, e.g., emerging topics in social media and new types of products in e-commerce. A model should recognize new classes and meanwhile maintain discriminability over old classes. Under severe circumstances, only limited novel instances are available to incrementally update the model. The task of recognizing few-shot new classes with...]]></description>
        </item>
        <item>
            <title><![CDATA[Open Long-Tailed Recognition In A Dynamic World]]></title>
            <link>https://ieeexplore.ieee.org/document/9863702</link>
            <guid>https://ieeexplore.ieee.org/document/9863702</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Real world data often exhibits a long-tailed and open-ended (i.e., with unseen classes) distribution. A practical recognition system must balance between majority (head) and minority (tail) classes, generalize across the distribution, and acknowledge novelty upon the instances of unseen classes (open classes). We define Open Long-Tailed Recognition++ (OLTR++) as learning from such naturally...]]></description>
        </item>
        <item>
            <title><![CDATA[TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving]]></title>
            <link>https://ieeexplore.ieee.org/document/9863660</link>
            <guid>https://ieeexplore.ieee.org/document/9863660</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[How should we integrate representations from complementary sensors for autonomous driving? Geometry-based fusion has shown promise for perception (e.g. object detection, motion forecasting). However, in the context of end-to-end driving, we find that imitation learning based on existing sensor fusion methods underperforms in complex driving scenarios with a high density of dynamic agents. Therefor...]]></description>
        </item>
        <item>
            <title><![CDATA[Few-shot Font Generation with Weakly Supervised Localized Representations]]></title>
            <link>https://ieeexplore.ieee.org/document/9854803</link>
            <guid>https://ieeexplore.ieee.org/document/9854803</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Automatic few-shot font generation aims to solve a well-defined, real-world problem because manual font designs are expensive and sensitive to the expertise of designers. Existing methods learn to disentangle style and content elements by developing a universal style representation for each font style. However, this approach limits the model in representing diverse local styles because it is unsui...]]></description>
        </item>
        <item>
            <title><![CDATA[Variable Imaging Projection Cloud Scattering Tomography]]></title>
            <link>https://ieeexplore.ieee.org/document/9847357</link>
            <guid>https://ieeexplore.ieee.org/document/9847357</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is a nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale is particularly important when the objects constitute large cloud fields, where volumetric recovery is ...]]></description>
        </item>
        <item>
            <title><![CDATA[Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation Exploitation]]></title>
            <link>https://ieeexplore.ieee.org/document/9847356</link>
            <guid>https://ieeexplore.ieee.org/document/9847356</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Few-shot object detection has been extensively investigated by incorporating meta-learning into region-based detection frameworks. Despite its success, the said paradigm is still constrained by several factors, such as (i) low-quality region proposals for novel classes and (ii) negligence of the inter-class correlation among different classes. Such limitations hinder the generalizati...]]></description>
        </item>
        <item>
            <title><![CDATA[Voxel-Mesh Network for Geodesic-Aware 3D Semantic Segmentation of Indoor Scenes]]></title>
            <link>https://ieeexplore.ieee.org/document/9844250</link>
            <guid>https://ieeexplore.ieee.org/document/9844250</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In recent years, sparse voxel-based methods have become the state-of-the-arts for 3D semantic segmentation of indoor scenes, thanks to the powerful 3D CNNs. Nevertheless, being oblivious to the underlying geometry, voxel-based methods suffer from ambiguous features on spatially close objects and struggle with handling complex and irregular geometries due to the lack of geodesic information. In vie...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Remove Rain in Video With Self-Supervision]]></title>
            <link>https://ieeexplore.ieee.org/document/9815121</link>
            <guid>https://ieeexplore.ieee.org/document/9815121</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In heavy rain video, rain streak and rain accumulation are the most common causes of degradation. They occlude background information and can significantly impair the visibility. Most existing methods rely heavily on the synthetic training data, and thus raise the domain gap problem that prevents the trained models from performing adequately in real testing cases. Unlike these methods, we introduc...]]></description>
        </item>
        <item>
            <title><![CDATA[RAgE: Robust Age Estimation Through Subject Anchoring with Consistency Regularisation]]></title>
            <link>https://ieeexplore.ieee.org/document/9810519</link>
            <guid>https://ieeexplore.ieee.org/document/9810519</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Modern facial age estimation systems can achieve high accuracy when training and test datasets are identically distributed and captured under similar conditions. However, domain shifts in data, encountered in practice, lead to a sharp drop in accuracy of most existing age estimation algorithms. In this work, we propose a novel method, namely RAgE, to improve the robustness and reduce the uncertain...]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing Two-way Partial AUC with an End-to-end Framework]]></title>
            <link>https://ieeexplore.ieee.org/document/9804230</link>
            <guid>https://ieeexplore.ieee.org/document/9804230</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The Area Under the ROC Curve (AUC) is a crucial metric for machine learning, which evaluates the average performance over all possible True Positive Rates (TPRs) and False Positive Rates (FPRs). Based on the knowledge that a skillful classifier should simultaneously embrace a high TPR and a low FPR, we turn to study a more general variant called Two-way Partial AUC (TPAUC), where only the region w...]]></description>
        </item>
        <item>
            <title><![CDATA[Out-of-Domain Generalization From a Single Source: An Uncertainty Quantification Approach]]></title>
            <link>https://ieeexplore.ieee.org/document/9801711</link>
            <guid>https://ieeexplore.ieee.org/document/9801711</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We are concerned with a worst-case scenario in model generalization, in the sense that a model aims to perform well on many unseen domains while there is only one single domain available for training. We propose Meta-Learning based Adversarial Domain Augmentation to solve this Out-of-Domain generalization problem. The key idea is to leverage adversarial training to create &#x201C;fictitious&#x201D...]]></description>
        </item>
        <item>
            <title><![CDATA[<italic>OpenGAN</italic>: Open-Set Recognition Via Open Data Generation]]></title>
            <link>https://ieeexplore.ieee.org/document/9799769</link>
            <guid>https://ieeexplore.ieee.org/document/9799769</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Real-world machine learning systems need to analyze test data that may differ from training data. In K-way classification, this is crisply formulated as open-set recognition, core to which is the ability to discriminate open-set data outside the K closed-set classes. Two conceptually elegant ideas for open-set discrimination are: 1) discriminatively learning an open-vs-closed binary discriminator ...]]></description>
        </item>
        <item>
            <title><![CDATA[Image De-raining Transformer]]></title>
            <link>https://ieeexplore.ieee.org/document/9798773</link>
            <guid>https://ieeexplore.ieee.org/document/9798773</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Existing deep learning based de-raining approaches have resorted to the convolutional architectures. However, the intrinsic limitations of convolution, including local receptive fields and independence of input content, hinder the model&#x2019;s ability to capture long-range and complicated rainy artifacts. To overcome these limitations, we propose an effective and efficient transformer-based arch...]]></description>
        </item>
        <item>
            <title><![CDATA[Ordinal Unsupervised Domain Adaptation With Recursively Conditional Gaussian Imposed Variational Disentanglement]]></title>
            <link>https://ieeexplore.ieee.org/document/9796559</link>
            <guid>https://ieeexplore.ieee.org/document/9796559</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[There has been a growing interest in unsupervised domain adaptation (UDA) to alleviate the data scalability issue, while the existing works usually focus on classifying independently discrete labels. However, in many tasks (e.g., medical diagnosis), the labels are discrete and successively distributed. The UDA for ordinal classification requires inducing non-trivial ordinal distribution prior to t...]]></description>
        </item>
        <item>
            <title><![CDATA[Ultra Fast Deep Lane Detection With Hybrid Anchor Driven Ordinal Classification]]></title>
            <link>https://ieeexplore.ieee.org/document/9795098</link>
            <guid>https://ieeexplore.ieee.org/document/9795098</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Modern methods mainly regard lane detection as a problem of pixel-wise segmentation, which is struggling to address the problems of efficiency and challenging scenarios like severe occlusions and extreme lighting conditions. Inspired by human perception, the recognition of lanes under severe occlusions and extreme lighting conditions is mainly based on contextual and global information. Motivated ...]]></description>
        </item>
        <item>
            <title><![CDATA[Fourier-based and Rational Graph Filters for Spectral Processing]]></title>
            <link>https://ieeexplore.ieee.org/document/9780026</link>
            <guid>https://ieeexplore.ieee.org/document/9780026</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Data are represented as graphs in a wide range of applications, such as Computer Vision (e.g., images) and Graphics (e.g., 3D meshes), network analysis (e.g., social networks), and bio-informatics (e.g., molecules). In this context, our overall goal is the definition of novel Fourier-based and graph filters induced by rational polynomials for graph processing, which generalise polynomial filters a...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Answer Visual Questions from Web Videos]]></title>
            <link>https://ieeexplore.ieee.org/document/9770842</link>
            <guid>https://ieeexplore.ieee.org/document/9770842</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent methods for visual question answering rely on large-scale annotated datasets. Manual annotation of questions and answers for videos, however, is tedious, expensive and prevents scalability. In this work, we propose to avoid manual annotation and generate a large-scale training dataset for video question answering making use of automatic cross-modal supervision. We leverage a question genera...]]></description>
        </item>
        <item>
            <title><![CDATA[Graphical Modeling for Multi-Source Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/9767755</link>
            <guid>https://ieeexplore.ieee.org/document/9767755</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multi-Source Domain Adaptation (MSDA) focuses on transferring the knowledge from multiple source domains to the target domain, which is a more practical and challenging problem compared to the conventional single-source domain adaptation. In this problem, it is essential to model multiple source domains and target domain jointly, and an effective domain combination scheme is also highly required. ...]]></description>
        </item>
        <item>
            <title><![CDATA[Looking Beyond Single Images for Weakly Supervised Semantic Segmentation Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9760057</link>
            <guid>https://ieeexplore.ieee.org/document/9760057</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This article studies the problem of learning weakly supervised semantic segmentation (WSSS) from image-level supervision only. Rather than previous efforts that primarily focus on intra-image information, we address the value of cross-image semantic relations for comprehensive object pattern mining. To achieve this, two neural co-attentions are incorporated into the classifier to complimentarily c...]]></description>
        </item>
        <item>
            <title><![CDATA[Reinforcing Generated Images via Meta-learning for One-Shot Fine-Grained Visual Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9756906</link>
            <guid>https://ieeexplore.ieee.org/document/9756906</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[One-shot fine-grained visual recognition often suffers from the problem of training data scarcity for new fine-grained classes. To alleviate this problem, off-the-shelf image generation techniques based on Generative Adversarial Networks (GANs) can potentially create additional training images. However, these GAN-generated images are often not helpful for actually improving the accuracy of one-sho...]]></description>
        </item>
        <item>
            <title><![CDATA[Anti-Adversarially Manipulated Attributions for Weakly Supervised Semantic Segmentation and Object Localization]]></title>
            <link>https://ieeexplore.ieee.org/document/9756329</link>
            <guid>https://ieeexplore.ieee.org/document/9756329</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Obtaining accurate pixel-level localization from class labels is a crucial process in weakly supervised semantic segmentation and object localization. Attribution maps from a trained classifier are widely used to provide pixel-level localization, but their focus tends to be restricted to a small discriminative region of the target object. AdvCAM is an attribution map of an image that is manipulate...]]></description>
        </item>
        <item>
            <title><![CDATA[Multiple Adverse Weather Conditions Adaptation for Object Detection via Causal Intervention]]></title>
            <link>https://ieeexplore.ieee.org/document/9756301</link>
            <guid>https://ieeexplore.ieee.org/document/9756301</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Most state-of-the-art object detection methods have achieved impressive perfomrace on several public benchmarks, which are trained with high definition images. However, existing detectors are often sensitive to the visual variations and out-of-distribution data due to the domain gap caused by various confounders, e.g. the adverse weathre conditions. To bridge the gap, previous methods have been ma...]]></description>
        </item>
        <item>
            <title><![CDATA[Deeply Unsupervised Patch Re-Identification for Pre-training Object Detectors]]></title>
            <link>https://ieeexplore.ieee.org/document/9749837</link>
            <guid>https://ieeexplore.ieee.org/document/9749837</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Unsupervised pre-training aims at learning transferable features that are beneficial for downstream tasks. However, most state-of-the-art unsupervised methods concentrate on learning global representations for image-level classification tasks instead of discriminative local region representations, which limits their transferability to region-level downstream tasks, such as object detection. To imp...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Graph Embeddings for Open World Compositional Zero-Shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9745371</link>
            <guid>https://ieeexplore.ieee.org/document/9745371</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Compositional Zero-Shot learning (CZSL) aims to recognize unseen compositions of state and object visual primitives seen during training. A problem with standard CZSL is the assumption of knowing which unseen compositions will be available at test time. In this work, we overcome this assumption operating on the open world setting, where no limit is imposed on the compositional space at test time, ...]]></description>
        </item>
        <item>
            <title><![CDATA[Intra-Inter Domain Similarity for Unsupervised Person Re-Identification]]></title>
            <link>https://ieeexplore.ieee.org/document/9745321</link>
            <guid>https://ieeexplore.ieee.org/document/9745321</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Most of unsupervised person Re-Identification (Re-ID) works produce pseudo-labels by measuring the feature similarity without considering the domain discrepancy among cameras, leading to degraded accuracy in pseudo label computation. This paper targets to address this challenge by decomposing the similarity computation into two stage, i.e., the intra-domain and inter-domain computations, respectiv...]]></description>
        </item>
        <item>
            <title><![CDATA[NPT-Loss: Demystifying face recognition losses with Nearest Proxies Triplet]]></title>
            <link>https://ieeexplore.ieee.org/document/9743810</link>
            <guid>https://ieeexplore.ieee.org/document/9743810</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Face recognition (FR) using deep convolutional neural networks (DCNNs) has seen remarkable success in recent years. One key ingredient of DCNN-based FR is the design of a loss function that ensures discrimination between various identities. The state-of-the-art (SOTA) solutions utilise normalised Softmax loss with additive and/or multiplicative margins. Despite being popular and effective, these l...]]></description>
        </item>
        <item>
            <title><![CDATA[Self-supervised Latent Space Optimization with Nebula Variational Coding]]></title>
            <link>https://ieeexplore.ieee.org/document/9740011</link>
            <guid>https://ieeexplore.ieee.org/document/9740011</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep learning approaches process data in a layer-by-layer way with intermediate (or latent) features. We aim at designing a general solution to optimize the latent manifolds to improve the performance on classification, segmentation, completion and/or reconstruction through probabilistic models. This paper proposes a variational inference model which leads to a clustered embedding. We introduce ad...]]></description>
        </item>
        <item>
            <title><![CDATA[Few-Shot Learning with a Strong Teacher]]></title>
            <link>https://ieeexplore.ieee.org/document/9737396</link>
            <guid>https://ieeexplore.ieee.org/document/9737396</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Few-shot learning (FSL) aims to generate a classifier using limited labeled examples. Many existing works take the meta-learning approach, constructing a few-shot learner (a meta-model) that can learn from few-shot examples to generate a classifier. The performance is measured by how well the resulting classifiers classify the test (\ie, query) examples of those tasks. In this paper, we point out ...]]></description>
        </item>
        <item>
            <title><![CDATA[Feature Re-Representation and Reliable Pseudo Label Retraining for Cross-Domain Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9733271</link>
            <guid>https://ieeexplore.ieee.org/document/9733271</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This paper presents a novel unsupervised domain adaptation method for semantic segmentation. We argue that a good representation of the target-domain data should keep both the knowledge from the source domain and the target-domain-specific information. To obtain the knowledge from the source domain, we first learn a set of bases to characterize the feature distribution of the source domain, then f...]]></description>
        </item>
        <item>
            <title><![CDATA[Unsupervised and Semi-supervised Robust Spherical Space Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/9733209</link>
            <guid>https://ieeexplore.ieee.org/document/9733209</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Adversarial domain adaptation has been an effective approach for learning domain-invariant features by adversarial training. In this paper, we propose a novel adversarial domain adaptation approach defined in the spherical feature space, in which we define spherical classifier for label prediction and spherical domain discriminator for discriminating domain labels. In the spherical feature space, ...]]></description>
        </item>
        <item>
            <title><![CDATA[Recursive Least-Squares Estimator-Aided Online Learning for Visual Tracking]]></title>
            <link>https://ieeexplore.ieee.org/document/9729522</link>
            <guid>https://ieeexplore.ieee.org/document/9729522</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Tracking visual objects from a single initial exemplar in the testing phase has been broadly cast as a one-/few-shot problem, i.e., one-shot learning for initial adaptation and few-shot learning for online adaptation. The recent few-shot online adaptation methods incorporate the prior knowledge from large amounts of annotated training data via complex meta-learning optimization in the offline phas...]]></description>
        </item>
        <item>
            <title><![CDATA[MetaKernel: Learning Variational Random Features with Limited Labels]]></title>
            <link>https://ieeexplore.ieee.org/document/9722994</link>
            <guid>https://ieeexplore.ieee.org/document/9722994</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Few-shot learning deals with the fundamental and challenging problem of learning from a few annotated samples, while being able to generalize well on new tasks. The crux of few-shot learning is to extract prior knowledge from related tasks to enable fast adaptation to a new task with a limited amount of data. In this paper, we propose meta-learning kernels with random Fourier features for few-shot...]]></description>
        </item>
        <item>
            <title><![CDATA[FINC: An Efficient and Effective Optimization Method for Normalized Cut]]></title>
            <link>https://ieeexplore.ieee.org/document/9706351</link>
            <guid>https://ieeexplore.ieee.org/document/9706351</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The optimization methods for solving the normalized cut model usually involve three steps, i.e., problem relaxation, problem solving and post-processing. However, these methods are problematic in both performance since they do not directly solve the original problem, and efficiency since they usually depend on the time-consuming eigendecomposition and k-means (or spectral rotation) for post-proces...]]></description>
        </item>
        <item>
            <title><![CDATA[Semantics-Guided Contrastive Network for Zero-Shot Object detection]]></title>
            <link>https://ieeexplore.ieee.org/document/9669022</link>
            <guid>https://ieeexplore.ieee.org/document/9669022</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Zero-shot object detection (ZSD), the task that extends conventional detection models to detecting objects from unseen categories, has emerged as a new challenge in computer vision. Most existing approaches on ZSD are based on a strict mapping-transfer strategy that learns a mapping function from visual to semantic space over seen categories, then directly generalizes the learned mapping function ...]]></description>
        </item>
        <item>
            <title><![CDATA[Depth and Video Segmentation Based Visual Attention for Embodied Question Answering]]></title>
            <link>https://ieeexplore.ieee.org/document/9669060</link>
            <guid>https://ieeexplore.ieee.org/document/9669060</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Embodied Question Answering (EQA) is a newly defined research area where an agent is required to answer the users questions by exploring the real-world environment. It has attracted increasing research interests due to its broad applications in personal assistants and in-home robots. Most of the existing methods perform poorly in terms of answering and navigation accuracy due to the absence of fin...]]></description>
        </item>
        <item>
            <title><![CDATA[Improving Semantic Segmentation via Efficient Self-Training]]></title>
            <link>https://ieeexplore.ieee.org/document/9663011</link>
            <guid>https://ieeexplore.ieee.org/document/9663011</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Starting from the seminal work of Fully Convolutional Networks (FCN), there has been significant progress on semantic segmentation. However, deep learning models often require large amounts of pixelwise annotations to train accurate and robust models. Given the prohibitively expensive annotation cost of segmentation masks, we introduce a self-training framework in this paper to leverage pseudo lab...]]></description>
        </item>
        <item>
            <title><![CDATA[Are Labels Always Necessary for Classifier Accuracy Evaluation]]></title>
            <link>https://ieeexplore.ieee.org/document/9655472</link>
            <guid>https://ieeexplore.ieee.org/document/9655472</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Understanding model decision under novel test scenarios is central to the community. A common practice is evaluating models on labeled test sets. However, many real-world scenarios see unlabeled test data, rendering the common supervised evaluation protocols infeasible. In this paper, we investigate such an important but under-explored problem, named Automatic model Evaluation (AutoEval). Specific...]]></description>
        </item>
        <item>
            <title><![CDATA[Occlusion-Aware Self-Supervised Monocular 6D Object Pose Estimation]]></title>
            <link>https://ieeexplore.ieee.org/document/9655492</link>
            <guid>https://ieeexplore.ieee.org/document/9655492</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[6D object pose estimation is a fundamental yet challenging problem in computer vision. Convolutional Neural Networks (CNNs) have recently proven to be capable of predicting reliable 6D pose estimates even under monocular settings. Nonetheless, CNNs are identified as being extremely data-driven, and acquiring adequate annotations is oftentimes very time-consuming and labor intensive. To overcome th...]]></description>
        </item>
        <item>
            <title><![CDATA[MgSvF: Multi-Grained Slow vs. Fast Framework for Few-Shot Class-Incremental Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9645290</link>
            <guid>https://ieeexplore.ieee.org/document/9645290</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[As a challenging problem, few-shot class-incremental learning (FSCIL) continually learns a sequence of tasks, confronting the dilemma between slow forgetting of old knowledge and fast adaptation to new knowledge. In this paper, we concentrate on this ‘`slow vs. fast’&#39; (SvF) dilemma to determine which knowledge components to be updated in a slow fashion or a fast fashion, and thereby balance old-kn...]]></description>
        </item>
        <item>
            <title><![CDATA[Where and How to Transfer: Knowledge Aggregation-Induced Transferability Perception for Unsupervised Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/9616392</link>
            <guid>https://ieeexplore.ieee.org/document/9616392</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Unsupervised domain adaptation without accessing expensive annotation processes of target data has achieved remarkable successes in semantic segmentation. However, most existing state-of-the-art methods cannot explore whether semantic representations across domains are transferable or not, which may result in the negative transfer brought by irrelevant knowledge. To tackle this challenge, in this ...]]></description>
        </item>
        <item>
            <title><![CDATA[Graph Neural Network and Spatiotemporal Transformer Attention for 3D Video Object Detection from Point Clouds]]></title>
            <link>https://ieeexplore.ieee.org/document/9609569</link>
            <guid>https://ieeexplore.ieee.org/document/9609569</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Previous works for LiDAR-based 3D object detection mainly focus on the single-frame paradigm. In this paper, we propose to detect 3D objects by exploiting temporal information in multiple frames, i.e., the point cloud videos. We empirically categorize the temporal information into short-term and long-term patterns. To encode the short-term data, we present a Grid Message Passing Network (GMPNet), ...]]></description>
        </item>
        <item>
            <title><![CDATA[Few-shot domain-adaptive anomaly detection for cross-site brain images]]></title>
            <link>https://ieeexplore.ieee.org/document/9606561</link>
            <guid>https://ieeexplore.ieee.org/document/9606561</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Early screening is essential for effective intervention and treatment of individuals with mental disorders. Functional magnetic resonance imaging (fMRI) is a noninvasive tool for depicting neural activity and has demonstrated strong potential as a technique for identifying mental disorders. Due to the difficulty in data collection and diagnosis, imaging data from patients are rare at a single site...]]></description>
        </item>
        <item>
            <title><![CDATA[Leveraging Hand-Object Interactions in Assistive Egocentric Vision]]></title>
            <link>https://ieeexplore.ieee.org/document/9591443</link>
            <guid>https://ieeexplore.ieee.org/document/9591443</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Egocentric vision holds great promise for increasing access to visual information and improving the quality of life for blind people. While we strive to improve recognition performance, it remains difficult to identify which object is of interest to the user; the object may not even be included in the frame due to challenges in camera aiming without visual feedback. Also, gaze information, commonl...]]></description>
        </item>
        <item>
            <title><![CDATA[Deconfounded Image Captioning: A Causal Retrospect]]></title>
            <link>https://ieeexplore.ieee.org/document/9583890</link>
            <guid>https://ieeexplore.ieee.org/document/9583890</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Dataset bias in vision-language tasks is becoming one of the main problems which hinders the progress of our community. Existing solutions lack a principled analysis about why modern image captioners easily collapse into dataset bias. In this paper, we present a novel perspective: Deconfounded Image Captioning (DIC), to find out the answer of this question, then retrospect modern neural image capt...]]></description>
        </item>
        <item>
            <title><![CDATA[LogicENN: A Neural Based Knowledge Graphs Embedding Model with Logical Rules]]></title>
            <link>https://ieeexplore.ieee.org/document/9582776</link>
            <guid>https://ieeexplore.ieee.org/document/9582776</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Knowledge graph embedding models have gained significant attention in AI research. The aim of knowledge graph embedding is to embed the graphs into a vector space in which the structure of the graph is preserved. Recent works have shown that the inclusion of background knowledge, such as logical rules, can improve the performance of embeddings in downstream machine learning tasks. However, so far,...]]></description>
        </item>
        <item>
            <title><![CDATA[Generating Personalized Summaries of Day Long Egocentric Videos]]></title>
            <link>https://ieeexplore.ieee.org/document/9562265</link>
            <guid>https://ieeexplore.ieee.org/document/9562265</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The popularity of egocentric cameras and their always-on nature has lead to the abundance of day long first-person videos. The highly redundant nature of these videos and extreme camera-shakes make them difficult to watch from beginning to end. These videos require efficient summarization tools for consumption. However, traditional summarization techniques developed for static surveillance videos ...]]></description>
        </item>
        <item>
            <title><![CDATA[Incomplete Multiple Kernel Alignment Maximization for Clustering]]></title>
            <link>https://ieeexplore.ieee.org/document/9556554</link>
            <guid>https://ieeexplore.ieee.org/document/9556554</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multiple kernel alignment (MKA) maximization criterion has been widely applied into multiple kernel clustering (MKC) and many variants have been recently developed. Though demonstrating superior clustering performance in various applications, it is observed that none of them can effectively handle incomplete MKC, where parts or all of the pre-specified base kernel matrices are incomplete. To addre...]]></description>
        </item>
        <item>
            <title><![CDATA[A Holistically-Guided Decoder for Deep Representation Learning with Applications to Semantic Segmentation and Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/9551977</link>
            <guid>https://ieeexplore.ieee.org/document/9551977</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Both high-level and high-resolution feature representations are of great importance in various visual understanding tasks. In this paper, we propose one novel holistically-guided decoder which is introduced to obtain the high-resolution semantic-rich feature maps via the multi-scale features from the encoder. The decoding is achieved via novel holistic codeword generation and codeword assembly ope...]]></description>
        </item>
        <item>
            <title><![CDATA[Recognizing Predictive Substructures with Subgraph Information Bottleneck]]></title>
            <link>https://ieeexplore.ieee.org/document/9537601</link>
            <guid>https://ieeexplore.ieee.org/document/9537601</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The emergence of Graph Convolutional Network (GCN) has greatly boosted the progress of graph learning. However, two disturbing factors, noise and redundancy in graph data, and lack of interpretation for prediction results, impede further development of GCN. One solution is to recognize a predictive yet compressed subgraph to get rid of the noise and redundancy and obtain the interpretable part of ...]]></description>
        </item>
        <item>
            <title><![CDATA[A Large-scale Virtual Dataset and Egocentric Localization for Disaster Responses]]></title>
            <link>https://ieeexplore.ieee.org/document/9476992</link>
            <guid>https://ieeexplore.ieee.org/document/9476992</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[With the increasing social demands of disaster response, methods of visual observation for rescue and safety have become increasingly important. However, because of the shortage of datasets for disaster scenarios, there has been little progress in computer vision and robotics in this field. With this in mind, we present the first large-scale synthetic dataset of egocentric viewpoints for disaster ...]]></description>
        </item>
        <item>
            <title><![CDATA[Revisiting 2D Convolutional Neural Networks for Graph-based Applications]]></title>
            <link>https://ieeexplore.ieee.org/document/9440667</link>
            <guid>https://ieeexplore.ieee.org/document/9440667</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph convolutional networks are widely used in graph-based applications such as graph classification and segmentation. However, current GCNs have limitations on implementation such as network architectures due to their irregular inputs. In contrast, convolutional neural networks are capable to extract rich features from large-scale input data, but they do not support general graph inputs. To brid...]]></description>
        </item>
        <item>
            <title><![CDATA[DeepGCNs: Making GCNs Go as Deep as CNNs]]></title>
            <link>https://ieeexplore.ieee.org/document/9408381</link>
            <guid>https://ieeexplore.ieee.org/document/9408381</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Convolutional Neural Networks have been very successful at solving a variety of computer vision tasks such as object classification and detection, semantic segmentation, activity understanding, to name just a few. One key enabling factor for their great performance has been the ability to train very deep networks. Despite their huge success in many tasks, CNNs do not work well with non-Euclidean d...]]></description>
        </item>
        <item>
            <title><![CDATA[JRDB: A Dataset and Benchmark of Egocentric Robot Visual Perception of Humans in Built Environments]]></title>
            <link>https://ieeexplore.ieee.org/document/9394786</link>
            <guid>https://ieeexplore.ieee.org/document/9394786</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present JRDB, a novel egocentric dataset collected from our social mobile manipulator JackRabbot. The dataset includes 64 minutes of annotated multimodal sensor data including stereo cylindrical 360 RGB video at 15 fps, 3D point clouds from two Velodyne 16 Lidars, line 3D point clouds from two Sick Lidars, audio signal, RGB-D video at 30 fps, 360 spherical image from a fisheye camera and encode...]]></description>
        </item>
        <item>
            <title><![CDATA[Geodesic Multi-Class SVM with Stiefel Manifold Embedding]]></title>
            <link>https://ieeexplore.ieee.org/document/9390382</link>
            <guid>https://ieeexplore.ieee.org/document/9390382</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Manifold of geodesic plays an essential role in characterizing the intrinsic data geometry. However, the existing SVM methods have largely neglected the manifold structure. As such, functional degeneration may occur due to the potential polluted training. Even worse, the entire SVM model might collapse in the presence of excessive training contamination. To address these issues, this paper devises...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Graph Convolutional Networks for Multi-Label Recognition and Applications]]></title>
            <link>https://ieeexplore.ieee.org/document/9369105</link>
            <guid>https://ieeexplore.ieee.org/document/9369105</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The task of multi-label image recognition is to predict a set of object labels that present in an image. As objects normally co-occur in an image, it is desirable to model label dependencies to improve recognition performance. To capture and explore such important information, we propose Graph Convolutional Networks based models for multi-label recognition, where directed graphs are constructed ov...]]></description>
        </item>
        <item>
            <title><![CDATA[Multi-Dataset, Multitask Learning of Egocentric Vision Tasks]]></title>
            <link>https://ieeexplore.ieee.org/document/9361177</link>
            <guid>https://ieeexplore.ieee.org/document/9361177</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[For egocentric vision tasks such as action recognition, there is a relative scarcity of labeled data. This increases the risk of overfitting during training. In this paper, we address this issue by introducing a multitask learning scheme that employs related tasks as well as related datasets in the training process. Related tasks are indicative of the performed action, such as the presence of obje...]]></description>
        </item>
        <item>
            <title><![CDATA[Self-Regulated Learning for Egocentric Video Activity Anticipation]]></title>
            <link>https://ieeexplore.ieee.org/document/9356220</link>
            <guid>https://ieeexplore.ieee.org/document/9356220</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Future activity anticipation is a challenging problem in egocentric vision. As a standard future activity anticipation paradigm, recursive sequence prediction suffers from the accumulation of errors. To address this problem, we propose a simple and effective Self-Regulated Learning framework, which aims to regulate the intermediate representation consecutively to produce representation that (a) em...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Recognize Actions on Objects in Egocentric Video with Attention Dictionaries]]></title>
            <link>https://ieeexplore.ieee.org/document/9353268</link>
            <guid>https://ieeexplore.ieee.org/document/9353268</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present EgoACO, a deep neural architecture for video action recognition that learns to pool action-context-object descriptors from frame level features by leveraging the verb-noun structure of action labels in egocentric video datasets. The core component of EgoACO is class activation pooling (CAP), a differentiable pooling operation that combines ideas from bilinear pooling for fine-grained re...]]></description>
        </item>
        <item>
            <title><![CDATA[Domain-Specific Priors and Meta Learning for Few-Shot First-Person Action Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9352536</link>
            <guid>https://ieeexplore.ieee.org/document/9352536</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The lack of large-scale real datasets with annotations makes transfer learning a necessity for video activity understanding. We aim to develop an effective method for few-shot transfer learning for first-person action classification. We leverage independently trained local visual cues to learn representations that can be transferred from a source domain, which provides primitive action labels, to ...]]></description>
        </item>
        <item>
            <title><![CDATA[Forecasting Action through Contact Representations from First Person Video]]></title>
            <link>https://ieeexplore.ieee.org/document/9340014</link>
            <guid>https://ieeexplore.ieee.org/document/9340014</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Human visual understanding of action is reliant on anticipation of contact as is demonstrated by pioneering work in cognitive science. Taking inspiration from this, we introduce representations and models centered on contact, which we then use in action prediction and anticipation. We annotate a subset of the EPIC Kitchens dataset to include time-to-contact between hands and objects, as well as se...]]></description>
        </item>
        <item>
            <title><![CDATA[In the Eye of the Beholder: Gaze and Actions in First Person Video]]></title>
            <link>https://ieeexplore.ieee.org/document/9325929</link>
            <guid>https://ieeexplore.ieee.org/document/9325929</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We address the task of jointly determining what a person is doing and where they are looking based on the analysis of video captured by a headworn camera. To facilitate our research, we first introduce the EGTEA Gaze+ dataset. Our dataset comes with videos, gaze tracking data, hand masks and action annotations, thereby providing the most comprehensive benchmark for First Person Vision (FPV). Movin...]]></description>
        </item>
        <item>
            <title><![CDATA[Global Context Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9307278</link>
            <guid>https://ieeexplore.ieee.org/document/9307278</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The Non-Local Network (NLNet) presents a pioneering approach for capturing long-range dependencies within an image, via aggregating query-specific global context to each query position. However, through a rigorous empirical analysis, we have found that the global contexts modeled by the non-local network are almost the same for different query positions. In this paper, we take advantage of this fi...]]></description>
        </item>
        <item>
            <title><![CDATA[HiGCIN: Hierarchical Graph-based Cross Inference Network for Group Activity Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9241410</link>
            <guid>https://ieeexplore.ieee.org/document/9241410</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Group activity recognition (GAR) is a challenging task aimed at recognizing the behavior of a group of people. It is a complex inference process in which visual cues collected from individuals are integrated into the final prediction, being aware of the interaction between them. This paper goes one step further beyond the existing approaches by designing a Hierarchical Graph-based Cross Inference ...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Multi-View Interactional Skeleton Graph for Action Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9234715</link>
            <guid>https://ieeexplore.ieee.org/document/9234715</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Capturing the interactions of human articulations lies in the center of skeleton-based action recognition. Recent graph-based methods are inherently limited in the weak spatial context modeling capability due to fixed interaction pattern and inflexible shared weights of GCN. To address above problems, we propose the Multi-View Interactional Graph Network (MV-IGNet) which can construct, learn and i...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Multi-Attention Context Graph for Group-Based Re-Identification]]></title>
            <link>https://ieeexplore.ieee.org/document/9233968</link>
            <guid>https://ieeexplore.ieee.org/document/9233968</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Learning to re-identify a group of people across camera systems has important applications in video surveillance. However, most existing methods focus on person re-identification (re-id), ignoring the fact that people often walk in groups. In this work, we consider employing context information for group re-id. On the one hand, group re-id is more challenging than single person re-id, since it req...]]></description>
        </item>
        <item>
            <title><![CDATA[Co-embedding of Nodes and Edges with Graph Neural Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9224195</link>
            <guid>https://ieeexplore.ieee.org/document/9224195</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph is ubiquitous in many real world applications ranging from social network analysis to biology. How to correctly and effectively learn and extract information from graph is essential for a large number of machine learning tasks. Graph embedding is a way to transform and encode data structure in high dimensional and Non-Euclidean feature space to a low dimensional and structural space. We have...]]></description>
        </item>
        <item>
            <title><![CDATA[First- And Third-person Video Co-analysis By Learning Spatial-temporal Joint Attention]]></title>
            <link>https://ieeexplore.ieee.org/document/9220850</link>
            <guid>https://ieeexplore.ieee.org/document/9220850</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recent years have witnessed a tremendous increasing of first-person videos captured by wearable devices. Such videos record information from different perspectives than the traditional third-person view, and thus show a wide range of potential usages. However, techniques for analyzing videos from different views can be fundamentally different, not to mention co-analyzing on both views to explore t...]]></description>
        </item>
        <item>
            <title><![CDATA[SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera]]></title>
            <link>https://ieeexplore.ieee.org/document/9217955</link>
            <guid>https://ieeexplore.ieee.org/document/9217955</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present a solution to egocentric 3D body pose estimation from monocular images captured from downward looking fish-eye cameras installed on the rim of a head mounted VR device. This unusual viewpoint leads to images with unique visual appearance, with severe self-occlusions and perspective distortions that result in drastic differences in resolution between lower and upper body. We propose an e...]]></description>
        </item>
        <item>
            <title><![CDATA[EgoCom: A Multi-person Multi-modal Egocentric Communications Dataset]]></title>
            <link>https://ieeexplore.ieee.org/document/9200754</link>
            <guid>https://ieeexplore.ieee.org/document/9200754</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multi-modal datasets in artificial intelligence (AI) often capture a third-person perspective, but our embodied human intelligence evolved with sensory input from the egocentric, first-person perspective. Towards embodied AI, we introduce the Egocentric Communications (EgoCom) dataset to advance the state-of-the-art in conversational AI, natural language, audio speech analysis, computer vision, an...]]></description>
        </item>
        <item>
            <title><![CDATA[Fashion Retrieval via Graph Reasoning Networks on a Similarity Pyramid]]></title>
            <link>https://ieeexplore.ieee.org/document/9200778</link>
            <guid>https://ieeexplore.ieee.org/document/9200778</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Matching clothing images from customers and online shopping stores has rich applications in E-commerce. Existing algorithms mostly encode an image as a global feature vector and perform retrieval via global representation matching. However, discriminative local information on clothes is submerged in this global representation, resulting in sub-optimal performance. To address this issue, we propose...]]></description>
        </item>
        <item>
            <title><![CDATA[MS-TCN++: Multi-Stage Temporal Convolutional Network for Action Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9186840</link>
            <guid>https://ieeexplore.ieee.org/document/9186840</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[With the success of deep learning in classifying short trimmed videos, more attention has been focused on temporally segmenting and classifying activities in long untrimmed videos. State-of-the-art approaches for action segmentation utilize several layers of temporal convolution and temporal pooling. Despite the capabilities of these approaches in capturing temporal dependencies, their predictions...]]></description>
        </item>
        <item>
            <title><![CDATA[Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment]]></title>
            <link>https://ieeexplore.ieee.org/document/9165005</link>
            <guid>https://ieeexplore.ieee.org/document/9165005</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we propose to tackle egocentric action recognition by suppressing background distractors and enhancing action-relevant interactions. The existing approaches usually utilize two independent branches to recognize egocentric actions, i.e., a verb branch and a noun branch. However, the mechanism to suppress distracting objects and exploit local human-object correlations is missing. To t...]]></description>
        </item>
        <item>
            <title><![CDATA[FakeCatcher: Detection of Synthetic Portrait Videos using Biological Signals]]></title>
            <link>https://ieeexplore.ieee.org/document/9141516</link>
            <guid>https://ieeexplore.ieee.org/document/9141516</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The recent proliferation of fake portrait videos poses direct threats on society, law, and privacy [1]. Believing the fake video of a politician, distributing fake pornographic content of celebrities, fabricating impersonated fake videos as evidence in courts are just a few real world consequences of deep fakes. We present a novel approach to detect synthetic content in portrait videos, as a preve...]]></description>
        </item>
        <item>
            <title><![CDATA[Multiple Trajectory Prediction of Moving Agents with Memory Augmented Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9138768</link>
            <guid>https://ieeexplore.ieee.org/document/9138768</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Pedestrians and drivers are expected to safely navigate complex urban environments along with several non cooperating agents. Autonomous vehicles will soon replicate this capability. Each agent acquires a representation of the world from an egocentric perspective and must make decisions ensuring safety for itself and others. This requires to predict motion patterns of observed agents for a far eno...]]></description>
        </item>
        <item>
            <title><![CDATA[CCNet: Criss-Cross Attention for Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9133304</link>
            <guid>https://ieeexplore.ieee.org/document/9133304</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Contextual information is vital in visual understanding problems, such as semantic segmentation and object detection. We propose a Criss-Cross Network (CCNet) for obtaining full-image contextual information in a very effective and efficient way. Concretely, for each pixel, a novel criss-cross attention module harvests the contextual information of all the pixels on its criss-cross path. By taking ...]]></description>
        </item>
        <item>
            <title><![CDATA[Combinatorial Learning of Robust Deep Graph Matching: an Embedding based Approach]]></title>
            <link>https://ieeexplore.ieee.org/document/9128045</link>
            <guid>https://ieeexplore.ieee.org/document/9128045</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph matching aims to establish node correspondence between two graphs, which has been a fundamental problem for its NP-complete nature. One practical consideration is the effective modeling of the affinity function in the presence of noise, such that the mathematically optimal matching result is also physically meaningful. This paper resorts to deep neural networks to learn the node and edge fea...]]></description>
        </item>
        <item>
            <title><![CDATA[Structured Knowledge Distillation for Dense Prediction]]></title>
            <link>https://ieeexplore.ieee.org/document/9115859</link>
            <guid>https://ieeexplore.ieee.org/document/9115859</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this work, we consider transferring the structure information from large networks to compact ones for dense prediction tasks in computer vision. Previous knowledge distillation strategies used for dense prediction tasks often directly borrow the distillation scheme for image classification and perform knowledge distillation for each pixel separately, leading to sub-optimal performance. Here we ...]]></description>
        </item>
        <item>
            <title><![CDATA[Second-Order Pooling for Graph Neural Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9104936</link>
            <guid>https://ieeexplore.ieee.org/document/9104936</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graph neural networks have achieved great success in learning node representations for graph tasks such as node classification and link prediction. Graph representation learning requires graph pooling to obtain graph representations from node representations. It is challenging to develop graph pooling methods due to the variable sizes and isomorphic structures of graphs. In this work, we propose t...]]></description>
        </item>
        <item>
            <title><![CDATA[Analysis of the hands in egocentric vision: A survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9064606</link>
            <guid>https://ieeexplore.ieee.org/document/9064606</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Egocentric vision (a.k.a. first-person vision - FPV) applications have thrived over the past few years, thanks to the availability of affordable wearable cameras and large annotated datasets. The position of the wearable camera (usually mounted on the head) allows recording exactly what the camera wearers have in front of them, in particular hands and manipulated objects. This intrinsic advantage ...]]></description>
        </item>
        <item>
            <title><![CDATA[Contextualized Trajectory Parsing with Spatio-Temporal Graph]]></title>
            <link>https://ieeexplore.ieee.org/document/6517196</link>
            <guid>https://ieeexplore.ieee.org/document/6517196</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This work investigates how to automatically parse object trajectories in surveillance videos, that aims to jointly solve three subproblems: i) spatial segmentation, ii) temporal tracking, and iii) object categorization. We present a novel representation spatio-temporal graph (ST-Graph), in which: i) graph nodes express the motion primitives, each representing a short sequence of small-size patches...]]></description>
        </item>
        <item>
            <title><![CDATA[A CNN-based face detector with a simple feature map and a coarse-to-fine classifier - Withdrawn]]></title>
            <link>https://ieeexplore.ieee.org/document/4378386</link>
            <guid>https://ieeexplore.ieee.org/document/4378386</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Withdrawn.]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Self-Supervised Teacher-Student Network Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9944861</link>
            <guid>https://ieeexplore.ieee.org/document/9944861</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Lifelong learning (LLL) represents the ability of an artificial intelligence system to learn successively a sequence of different databases. In this paper we introduce the Dynamic Self-Supervised Teacher-Student Network (D-TS), representing a more general LLL framework, where the Teacher is implemented as a dynamically expanding mixture model which automatically increases its capacity to deal with...]]></description>
        </item>
        <item>
            <title><![CDATA[Drinking From a Firehose: Continual Learning With Web-Scale Natural Language]]></title>
            <link>https://ieeexplore.ieee.org/document/9933017</link>
            <guid>https://ieeexplore.ieee.org/document/9933017</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Continual learning systems will interact with humans, with each other, and with the physical world through time – and continue to learn and adapt as they do. An important open problem for continual learning is a large-scale benchmark which enables realistic evaluation of algorithms. In this paper, we study a natural setting for continual learning on a massive scale. We introduce the problem of per...]]></description>
        </item>
        <item>
            <title><![CDATA[Cycle Registration in Persistent Homology With Applications in Topological Bootstrap]]></title>
            <link>https://ieeexplore.ieee.org/document/9931659</link>
            <guid>https://ieeexplore.ieee.org/document/9931659</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose a novel approach for comparing the persistent homology representations of two spaces (or filtrations). Commonly used methods are based on numerical summaries such as persistence diagrams and persistence landscapes, along with suitable metrics (e.g., Wasserstein). These summaries are useful for computational purposes, but they are merely a marginal of the actual topological information t...]]></description>
        </item>
        <item>
            <title><![CDATA[DeepEMD: Differentiable Earth Mover's Distance for Few-Shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9930675</link>
            <guid>https://ieeexplore.ieee.org/document/9930675</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this work, we develop methods for few-shot image classification from a new perspective of optimal matching between image regions. We employ the Earth Mover&#39;s Distance (EMD) as a metric to compute a structural distance between dense image representations to determine image relevance. The EMD generates the optimal matching flows between structural elements that have the minimum matching cost, whi...]]></description>
        </item>
        <item>
            <title><![CDATA[Implicit Annealing in Kernel Spaces: A Strongly Consistent Clustering Approach]]></title>
            <link>https://ieeexplore.ieee.org/document/9928792</link>
            <guid>https://ieeexplore.ieee.org/document/9928792</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Kernel $k$k-means clustering is a powerful tool for unsupervised learning of non-linearly separable data. Its merits are thoroughly validated on a suite of simulated datasets and real data benchmarks that feature nonlinear and multi-view separation. Since the earliest attempts, researchers have noted that such algorithms often become trapped by local minima arising from the non-convexity of the un...]]></description>
        </item>
        <item>
            <title><![CDATA[Snowflake Point Deconvolution for Point Cloud Completion and Generation With Skip-Transformer]]></title>
            <link>https://ieeexplore.ieee.org/document/9928787</link>
            <guid>https://ieeexplore.ieee.org/document/9928787</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Most existing point cloud completion methods suffer from the discrete nature of point clouds and the unstructured prediction of points in local regions, which makes it difficult to reveal fine local geometric details. To resolve this issue, we propose SnowflakeNet with snowflake point deconvolution (SPD) to generate complete point clouds. SPD models the generation of point clouds as the snowflake-...]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Convolution for 3D Point Cloud Instance Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9928362</link>
            <guid>https://ieeexplore.ieee.org/document/9928362</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we come up with a simple yet effective approach for instance segmentation on 3D point cloud with strong robustness. Previous top-performing methods for this task adopt a bottom-up strategy, which often involves various inefficient operations or complex pipelines, such as grouping over-segmented components, introducing heuristic post-processing steps, and designing complex loss funct...]]></description>
        </item>
        <item>
            <title><![CDATA[ST3D++: Denoised Self-Training for Unsupervised Domain Adaptation on 3D Object Detection]]></title>
            <link>https://ieeexplore.ieee.org/document/9927350</link>
            <guid>https://ieeexplore.ieee.org/document/9927350</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this paper, we present a self-training method, named ST3D++, with a holistic pseudo label denoising pipeline for unsupervised domain adaptation on 3D object detection. ST3D++ aims at reducing noise in pseudo label generation as well as alleviating the negative impacts of noisy pseudo labels on model training. First, ST3D++ pre-trains the 3D object detector on the labeled source domain with rand...]]></description>
        </item>
        <item>
            <title><![CDATA[Rolling Shutter Inversion: Bring Rolling Shutter Images to High Framerate Global Shutter Video]]></title>
            <link>https://ieeexplore.ieee.org/document/9926197</link>
            <guid>https://ieeexplore.ieee.org/document/9926197</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[A single rolling-shutter (RS) image may be viewed as a row-wise combination of a sequence of global-shutter (GS) images captured by a (virtual) moving GS camera within the exposure duration. Although rolling-shutter cameras are widely used, the RS effect causes obvious image distortion especially in the presence of fast camera motion, hindering downstream computer vision tasks. In this paper, we p...]]></description>
        </item>
        <item>
            <title><![CDATA[Gaussian RBF Centered Kernel Alignment (CKA) in the Large-Bandwidth Limit]]></title>
            <link>https://ieeexplore.ieee.org/document/9926163</link>
            <guid>https://ieeexplore.ieee.org/document/9926163</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Centered kernel alignment (CKA), also known as centered kernel-target alignment, is useful as a similarity measure between kernels and as a kernel-based similarity measure between feature representations. We prove that CKA based on a Gaussian RBF kernel converges to linear CKA in the large-bandwidth limit. The result relies on mean-centering of the feature maps and on a Hilbert-Schmidt Independenc...]]></description>
        </item>
        <item>
            <title><![CDATA[Spherical Image Generation From a Few Normal-Field-of-View Images by Considering Scene Symmetry]]></title>
            <link>https://ieeexplore.ieee.org/document/9925617</link>
            <guid>https://ieeexplore.ieee.org/document/9925617</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Spherical images taken in all directions (360 degrees by 180 degrees) can represent an entire space including the subject, providing free direction viewing and an immersive experience to viewers. It is convenient and expands the usage scenarios to generate a spherical image from a few normal-field-of-view (NFOV) images, which are partial observations. The primary challenge is generating a plausibl...]]></description>
        </item>
        <item>
            <title><![CDATA[Analytical Tensor Voting in ND Space and its Properties]]></title>
            <link>https://ieeexplore.ieee.org/document/9925111</link>
            <guid>https://ieeexplore.ieee.org/document/9925111</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This article aims to propose a novel Analytical Tensor Voting (ATV) mechanism, which enables robust perceptual grouping and salient information extraction for noisy $N-$N-dimensional (ND) data. Firstly, the approximation of the decaying function is investigated and adopted based on the idea of penalizing the $1-$1-tensor votes by distance and curvature, respectively, followed by the derivation of ...]]></description>
        </item>
        <item>
            <title><![CDATA[Continuous-Time Fitted Value Iteration for Robust Policies]]></title>
            <link>https://ieeexplore.ieee.org/document/9925102</link>
            <guid>https://ieeexplore.ieee.org/document/9925102</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Solving the Hamilton-Jacobi-Bellman equation is important in many domains including control, robotics and economics. Especially for continuous control, solving this differential equation and its extension the Hamilton-Jacobi-Isaacs equation, is important as it yields the optimal policy that achieves the maximum reward on a give task. In the case of the Hamilton-Jacobi-Isaacs equation, which includ...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Learning for Face Anti-Spoofing: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9925105</link>
            <guid>https://ieeexplore.ieee.org/document/9925105</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Face anti-spoofing (FAS) has lately attracted increasing attention due to its vital role in securing face recognition systems from presentation attacks (PAs). As more and more realistic PAs with novel types spring up, early-stage FAS methods based on handcrafted features become unreliable due to their limited representation capacity. With the emergence of large-scale academic datasets in the recen...]]></description>
        </item>
        <item>
            <title><![CDATA[Learn From Unpaired Data for Image Restoration: A Variational Bayes Approach]]></title>
            <link>https://ieeexplore.ieee.org/document/9924527</link>
            <guid>https://ieeexplore.ieee.org/document/9924527</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Collecting paired training data is difficult in practice, but the unpaired samples broadly exist. Current approaches aim at generating synthesized training data from unpaired samples by exploring the relationship between the corrupted and clean data. This work proposes LUD-VAE, a deep generative method to learn the joint probability density function from data sampled from marginal distributions. O...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Optimize on Riemannian Manifolds]]></title>
            <link>https://ieeexplore.ieee.org/document/9925104</link>
            <guid>https://ieeexplore.ieee.org/document/9925104</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Many learning tasks are modeled as optimization problems with nonlinear constraints, such as principal component analysis and fitting a Gaussian mixture model. A popular way to solve such problems is resorting to Riemannian optimization algorithms, which yet heavily rely on both human involvement and expert knowledge about Riemannian manifolds. In this paper, we propose a Riemannian meta-optimizat...]]></description>
        </item>
        <item>
            <title><![CDATA[RobustFusion: Robust Volumetric Performance Reconstruction Under Human-Object Interactions From Monocular RGBD Stream]]></title>
            <link>https://ieeexplore.ieee.org/document/9925090</link>
            <guid>https://ieeexplore.ieee.org/document/9925090</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[High-quality 4D reconstruction of human performance with complex interactions to various objects is essential in real-world scenarios, which enables numerous immersive VR/AR applications. However, recent advances still fail to provide reliable performance reconstruction, suffering from challenging interaction patterns and severe occlusions, especially for the monocular setting. To fill this gap, i...]]></description>
        </item>
        <item>
            <title><![CDATA[The Proxy Step-Size Technique for Regularized Optimization on the Sphere Manifold]]></title>
            <link>https://ieeexplore.ieee.org/document/9925098</link>
            <guid>https://ieeexplore.ieee.org/document/9925098</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We give an effective solution to the regularized optimization problem $g (\boldsymbol{x}) + h (\boldsymbol{x})$g(x)+h(x), where $\boldsymbol{x}$x is constrained on the unit sphere $\Vert \boldsymbol{x} \Vert _{2} = 1$∥x∥2=1. Here $g (\cdot)$g(·) is a smooth cost with Lipschitz continuous gradient within the unit ball $\lbrace \boldsymbol{x} : \Vert \boldsymbol{x} \Vert _{2} \leq 1 \rbrace${x:∥x∥2≤...]]></description>
        </item>
        <item>
            <title><![CDATA[A Systematic Survey on Deep Generative Models for Graph Generation]]></title>
            <link>https://ieeexplore.ieee.org/document/9920219</link>
            <guid>https://ieeexplore.ieee.org/document/9920219</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Graphs are important data representations for describing objects and their relationships, which appear in a wide diversity of real-world scenarios. As one of a critical problem in this area, graph generation considers learning the distributions of given graphs and generating more novel graphs. Owing to their wide range of applications, generative models for graphs, which have a rich history, howev...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning Dual Memory Dictionaries for Blind Face Restoration]]></title>
            <link>https://ieeexplore.ieee.org/document/9921338</link>
            <guid>https://ieeexplore.ieee.org/document/9921338</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Blind face restoration is a challenging task due to the unknown, unsynthesizable and complex degradation, yet is valuable in many practical applications. To improve the performance of blind face restoration, recent works mainly treat the two aspects, i.e., generic and specific restoration, separately. In particular, generic restoration attempts to restore the results through general facial structu...]]></description>
        </item>
        <item>
            <title><![CDATA[Minimizing Estimated Risks on Unlabeled Data: A New Formulation for Semi-Supervised Medical Image Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9921323</link>
            <guid>https://ieeexplore.ieee.org/document/9921323</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Supervised segmentation can be costly, particularly in applications of biomedical image analysis where large scale manual annotations from experts are generally too expensive to be available. Semi-supervised segmentation, able to learn from both the labeled and unlabeled images, could be an efficient and effective alternative for such scenarios. In this work, we propose a new formulation based on ...]]></description>
        </item>
        <item>
            <title><![CDATA[Temporal Representation Learning on Monocular Videos for 3D Human Pose Estimation]]></title>
            <link>https://ieeexplore.ieee.org/document/9921314</link>
            <guid>https://ieeexplore.ieee.org/document/9921314</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this article we propose an unsupervised feature extraction method to capture temporal information on monocular videos, where we detect and encode subject of interest in each frame and leverage contrastive self-supervised (CSS) learning to extract rich latent vectors. Instead of simply treating the latent features of nearby frames as positive pairs and those of temporally-distant ones as negativ...]]></description>
        </item>
        <item>
            <title><![CDATA[Towards Accurate and Robust Domain Adaptation Under Multiple Noisy Environments]]></title>
            <link>https://ieeexplore.ieee.org/document/9921307</link>
            <guid>https://ieeexplore.ieee.org/document/9921307</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In many non-stationary environments, machine learning algorithms usually confront the distribution shift scenarios. Previous domain adaptation methods have achieved great success. However, they would lose algorithm robustness in multiple noisy environments where the examples of source domain become corrupted by label noise, feature noise, or open-set noise. In this paper, we report our attempt tow...]]></description>
        </item>
        <item>
            <title><![CDATA[ASH: A Modern Framework for Parallel Spatial Hashing in 3D Perception]]></title>
            <link>https://ieeexplore.ieee.org/document/9918017</link>
            <guid>https://ieeexplore.ieee.org/document/9918017</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We present ASH, a modern and high-performance framework for parallel spatial hashing on GPU. Compared to existing GPU hash map implementations, ASH achieves higher performance, supports richer functionality, and requires fewer lines of code (LoC) when used for implementing spatially varying operations from volumetric geometry reconstruction to differentiable appearance reconstruction. Unlike exist...]]></description>
        </item>
        <item>
            <title><![CDATA[Geodesic-Based Bayesian Coherent Point Drift]]></title>
            <link>https://ieeexplore.ieee.org/document/9918058</link>
            <guid>https://ieeexplore.ieee.org/document/9918058</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Coherent point drift is a well-known algorithm for non-rigid registration, i.e., a procedure for deforming a shape to match another shape. Despite its prevalence, the algorithm has a major drawback that remains unsolved: It unnaturally deforms the different parts of a shape, e.g., human legs, when they are neighboring each other. The inappropriate deformations originate from a proximity-based defo...]]></description>
        </item>
        <item>
            <title><![CDATA[Robust Losses for Learning Value Functions]]></title>
            <link>https://ieeexplore.ieee.org/document/9918637</link>
            <guid>https://ieeexplore.ieee.org/document/9918637</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Most value function learning algorithms in reinforcement learning are based on the mean squared (projected) Bellman error. However, squared errors are known to be sensitive to outliers, both skewing the solution of the objective and resulting in high-magnitude and high-variance gradients. To control these high-magnitude updates, typical strategies in RL involve clipping gradients, clipping rewards...]]></description>
        </item>
        <item>
            <title><![CDATA[MPED: Quantifying Point Cloud Distortion Based on Multiscale Potential Energy Discrepancy]]></title>
            <link>https://ieeexplore.ieee.org/document/9917335</link>
            <guid>https://ieeexplore.ieee.org/document/9917335</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this article, we propose a new distortion quantification method for point clouds, the multiscale potential energy discrepancy (MPED). Currently, there is a lack of effective distortion quantification for a variety of point cloud perception tasks. Specifically, in human vision tasks, a distortion quantification method is used to predict human subjective scores and optimize the selection of human...]]></description>
        </item>
        <item>
            <title><![CDATA[An Efficient Fisher Matrix Approximation Method for Large-Scale Neural Network Optimization]]></title>
            <link>https://ieeexplore.ieee.org/document/9916144</link>
            <guid>https://ieeexplore.ieee.org/document/9916144</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Although the shapes of the parameters are not crucial for designing first-order optimization methods in large scale empirical risk minimization problems, they have important impact on the size of the matrix to be inverted when developing second-order type methods. In this article, we propose an efficient and novel second-order method based on the parameters in the real matrix space $\mathbb {R}^{m...]]></description>
        </item>
        <item>
            <title><![CDATA[Defensive Few-Shot Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9916072</link>
            <guid>https://ieeexplore.ieee.org/document/9916072</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This article investigates a new challenging problem called defensive few-shot learning in order to learn a robust few-shot model against adversarial attacks. Simply applying the existing adversarial defense methods to few-shot learning cannot effectively solve this problem. This is because the commonly assumed sample-level distribution consistency between the training and test sets can no longer b...]]></description>
        </item>
        <item>
            <title><![CDATA[SMMP: A Stable-Membership-Based Auto-Tuning Multi-Peak Clustering Algorithm]]></title>
            <link>https://ieeexplore.ieee.org/document/9916156</link>
            <guid>https://ieeexplore.ieee.org/document/9916156</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Since most existing single-prototype clustering algorithms are unsuitable for complex-shaped clusters, many multi-prototype clustering algorithms have been proposed. Nevertheless, the automatic estimation of the number of clusters and the detection of complex shapes are still challenging, and to solve such problems usually relies on user-specified parameters and may be prohibitively time-consuming...]]></description>
        </item>
        <item>
            <title><![CDATA[Structured Sparsity Optimization With Non-Convex Surrogates of $\ell _{2,0}$ℓ2,0-Norm: A Unified Algorithmic Framework]]></title>
            <link>https://ieeexplore.ieee.org/document/9916142</link>
            <guid>https://ieeexplore.ieee.org/document/9916142</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this article, we present a general optimization framework that leverages structured sparsity to achieve superior recovery results. The traditional method for solving the structured sparse objectives based on $\ell _{2,0}$ℓ2,0-norm is to use the $\ell _{2,1}$ℓ2,1-norm as a convex surrogate. However, such an approximation often yields a large performance gap. To tackle this issue, we first provid...]]></description>
        </item>
        <item>
            <title><![CDATA[Class-Incremental Learning: Survey and Performance Evaluation on Image Classification]]></title>
            <link>https://ieeexplore.ieee.org/document/9915459</link>
            <guid>https://ieeexplore.ieee.org/document/9915459</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[For future learning systems, incremental learning is desirable because it allows for: efficient resource usage by eliminating the need to retrain from scratch at the arrival of new data; reduced memory usage by preventing or limiting the amount of data required to be stored – also important when privacy limitations are imposed; and learning that more closely resembles human learning. The main chal...]]></description>
        </item>
        <item>
            <title><![CDATA[HydraMarker: Efficient, Flexible, and Multifold Marker Field Generation]]></title>
            <link>https://ieeexplore.ieee.org/document/9913723</link>
            <guid>https://ieeexplore.ieee.org/document/9913723</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[An n-order marker field is a special binary matrix whose n×n subregions are all distinct from each other in four orientations. It is commonly used to guide the composing process of position-sensing markers, which can be detected and identified in a camera image with very limited scope or severe visibility problems. Despite the advantages, position-sensing markers are rare and overlooked because ge...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning With Nested Scene Modeling and Cooperative Architecture Search for Low-Light Vision]]></title>
            <link>https://ieeexplore.ieee.org/document/9914672</link>
            <guid>https://ieeexplore.ieee.org/document/9914672</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Images captured from low-light scenes often suffer from severe degradations, including low visibility, color casts, intensive noises, etc. These factors not only degrade image qualities, but also affect the performance of downstream Low-Light Vision (LLV) applications. A variety of deep networks have been proposed to enhance the visual quality of low-light images. However, they mostly rely on sign...]]></description>
        </item>
        <item>
            <title><![CDATA[Multi-Channel Attention Selection GANs for Guided Image-to-Image Translation]]></title>
            <link>https://ieeexplore.ieee.org/document/9913676</link>
            <guid>https://ieeexplore.ieee.org/document/9913676</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[We propose a novel model named Multi-Channel Attention Selection Generative Adversarial Network (SelectionGAN) for guided image-to-image translation, where we translate an input image into another while respecting an external semantic guidance. The proposed SelectionGAN explicitly utilizes the semantic guidance information and consists of two stages. In the first stage, the input image and the con...]]></description>
        </item>
        <item>
            <title><![CDATA[SiMaN: Sign-to-Magnitude Network Binarization]]></title>
            <link>https://ieeexplore.ieee.org/document/9913704</link>
            <guid>https://ieeexplore.ieee.org/document/9913704</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Binary neural networks (BNNs) have attracted broad research interest due to their efficient storage and computational ability. Nevertheless, a significant challenge of BNNs lies in handling discrete constraints while ensuring bit entropy maximization, which typically makes their weight optimization very difficult. Existing methods relax the learning using the sign function, which simply encodes po...]]></description>
        </item>
        <item>
            <title><![CDATA[Theoretical Analysis of Null Foley-Sammon Transform and its Implications]]></title>
            <link>https://ieeexplore.ieee.org/document/9914807</link>
            <guid>https://ieeexplore.ieee.org/document/9914807</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Null Foley-Sammon Transform (NFST) has received increasing attention in the machine learning and pattern recognition literature. NFST finds a discriminative nullspace where all samples of the same class get mapped into a single point. It has a closed form solution and is free of parameters to tune. NFST has been leveraged in many areas including novelty detection, person or vehicle re-identificati...]]></description>
        </item>
        <item>
            <title><![CDATA[Visual Object Tracking With Discriminative Filters and Siamese Networks: A Survey and Outlook]]></title>
            <link>https://ieeexplore.ieee.org/document/9913708</link>
            <guid>https://ieeexplore.ieee.org/document/9913708</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Accurate and robust visual object tracking is one of the most challenging and fundamental computer vision problems. It entails estimating the trajectory of the target in an image sequence, given only its initial location, and segmentation, or its rough approximation in the form of a bounding box. Discriminative Correlation Filters (DCFs) and deep Siamese Networks (SNs) have emerged as dominating t...]]></description>
        </item>
        <item>
            <title><![CDATA[Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks]]></title>
            <link>https://ieeexplore.ieee.org/document/9912362</link>
            <guid>https://ieeexplore.ieee.org/document/9912362</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Attention mechanisms, especially self-attention, have played an increasingly important role in deep feature representation for visual tasks. Self-attention updates the feature at each position by computing a weighted sum of features using pair-wise affinities across all positions to capture the long-range dependency within a single sample. However, self-attention has quadratic complexity and ignor...]]></description>
        </item>
        <item>
            <title><![CDATA[Towards Accurate Reconstruction of 3D Scene Shape From A Single Monocular Image]]></title>
            <link>https://ieeexplore.ieee.org/document/9912367</link>
            <guid>https://ieeexplore.ieee.org/document/9912367</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Despite significant progress made in the past few years, challenges remain for depth estimation using a single monocular image. First, it is nontrivial to train a metric-depth prediction model that can generalize well to diverse scenes mainly due to limited training data. Thus, researchers have built large-scale relative depth datasets that are much easier to collect. However, existing relative de...]]></description>
        </item>
        <item>
            <title><![CDATA[Improving Video Instance Segmentation via Temporal Pyramid Routing]]></title>
            <link>https://ieeexplore.ieee.org/document/9910001</link>
            <guid>https://ieeexplore.ieee.org/document/9910001</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Video Instance Segmentation (VIS) is a new and inherently multi-task problem, which aims to detect, segment, and track each instance in a video sequence. Existing approaches are mainly based on single-frame features or single-scale features of multiple frames, where either temporal information or multi-scale information is ignored. To incorporate both temporal and scale information, we propose a T...]]></description>
        </item>
        <item>
            <title><![CDATA[Channel Exchanging Networks for Multimodal and Multitask Dense Image Prediction]]></title>
            <link>https://ieeexplore.ieee.org/document/9906429</link>
            <guid>https://ieeexplore.ieee.org/document/9906429</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multimodal fusion and multitask learning are two vital topics in machine learning. Despite the fruitful progress, existing methods for both problems are still brittle to the same challenge—it remains dilemmatic to integrate the common information across modalities (resp. tasks) meanwhile preserving the specific patterns of each modality (resp. task). Besides, while they are actually closely relate...]]></description>
        </item>
        <item>
            <title><![CDATA[Small-Object Sensitive Segmentation Using Across Feature Map Attention]]></title>
            <link>https://ieeexplore.ieee.org/document/9906428</link>
            <guid>https://ieeexplore.ieee.org/document/9906428</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Semantic segmentation is an important step in understanding the scene for many practical applications such as autonomous driving. Although Deep Convolutional Neural Networks-based methods have significantly improved segmentation accuracy, small/thin objects remain challenging to segment due to convolutional and pooling operations that result in information loss, especially for small objects. This ...]]></description>
        </item>
        <item>
            <title><![CDATA[CRIC: A VQA Dataset for Compositional Reasoning on Vision and Commonsense]]></title>
            <link>https://ieeexplore.ieee.org/document/9905976</link>
            <guid>https://ieeexplore.ieee.org/document/9905976</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Alternatively inferring on the visual facts and commonsense is fundamental for an advanced visual question answering (VQA) system. This ability requires models to go beyond the literal understanding of commonsense. The system should not just treat objects as the entrance to query background knowledge, but fully ground commonsense to the visual world and imagine the possible relationships between o...]]></description>
        </item>
        <item>
            <title><![CDATA[Semantic Probability Distribution Modeling for Diverse Semantic Image Synthesis]]></title>
            <link>https://ieeexplore.ieee.org/document/9904454</link>
            <guid>https://ieeexplore.ieee.org/document/9904454</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Semantic image synthesis, translating semantic layouts to photo-realistic images, is a one-to-many mapping problem. Though impressive progress has been recently made, diverse semantic synthesis that can efficiently produce semantic-level or even instance-level multimodal results, still remains a challenge. In this article, we propose a novel diverse semantic image synthesis framework from the pers...]]></description>
        </item>
        <item>
            <title><![CDATA[Depth Restoration in Under-Display Time-of-Flight Imaging]]></title>
            <link>https://ieeexplore.ieee.org/document/9903562</link>
            <guid>https://ieeexplore.ieee.org/document/9903562</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Under-display imaging has recently received considerable attention in both academia and industry. As a variation of this technique, under-display ToF (UD-ToF) cameras enable depth sensing for full-screen devices. However, it also brings problems of image blurring, signal-to-noise ratio and ranging accuracy reduction. To address these issues, we propose a cascaded deep network to improve the qualit...]]></description>
        </item>
        <item>
            <title><![CDATA[Generating Hypergraph-Based High-Order Representations of Whole-Slide Histopathological Images for Survival Prediction]]></title>
            <link>https://ieeexplore.ieee.org/document/9903546</link>
            <guid>https://ieeexplore.ieee.org/document/9903546</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Patient survival prediction based on gigapixel whole-slide histopathological images (WSIs) has become increasingly prevalent in recent years. A key challenge of this task is achieving an informative survival-specific global representation from those WSIs with highly complicated data correlation. This article proposes a multi-hypergraph based learning framework, called “HGSurvNet,” to tackle this c...]]></description>
        </item>
        <item>
            <title><![CDATA[Graph Neural Networks in Network Neuroscience]]></title>
            <link>https://ieeexplore.ieee.org/document/9903566</link>
            <guid>https://ieeexplore.ieee.org/document/9903566</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Noninvasive medical neuroimaging has yielded many discoveries about the brain connectivity. Several substantial techniques mapping morphological, structural and functional brain connectivities were developed to create a comprehensive road map of neuronal activities in the human brain –namely brain graph. Relying on its non-euclidean data type, graph neural network (GNN) provides a clever way of le...]]></description>
        </item>
        <item>
            <title><![CDATA[Partial Convolution for Padding, Inpainting, and Image Synthesis]]></title>
            <link>https://ieeexplore.ieee.org/document/9903574</link>
            <guid>https://ieeexplore.ieee.org/document/9903574</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Partial convolution weights convolutions with binary masks and renormalizes on valid pixels. It was originally proposed for image inpainting task because a corrupted image processed by a standard convolutional often leads to artifacts. Therefore, binary masks are constructed that define the valid and corrupted pixels, so that partial convolution results are only calculated based on valid pixels. I...]]></description>
        </item>
        <item>
            <title><![CDATA[MaxMatch: Semi-Supervised Learning With Worst-Case Consistency]]></title>
            <link>https://ieeexplore.ieee.org/document/9897005</link>
            <guid>https://ieeexplore.ieee.org/document/9897005</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In recent years, great progress has been made to incorporate unlabeled data to overcome the inefficiently supervised problem via semi-supervised learning (SSL). Most state-of-the-art models are based on the idea of pursuing consistent model predictions over unlabeled data toward the input noise, which is called consistency regularization. Nonetheless, there is a lack of theoretical insights into t...]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic Graph Message Passing Networks]]></title>
            <link>https://ieeexplore.ieee.org/document/9895141</link>
            <guid>https://ieeexplore.ieee.org/document/9895141</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Modelling long-range dependencies is critical for scene understanding tasks in computer vision. Although convolution neural networks (CNNs) have excelled in many vision tasks, they are still limited in capturing long-range structured relationships as they typically consist of layers of local kernels. A fully-connected graph, such as the self-attention operation in Transformers, is beneficial for s...]]></description>
        </item>
        <item>
            <title><![CDATA[Stylized Adversarial Defense]]></title>
            <link>https://ieeexplore.ieee.org/document/9895320</link>
            <guid>https://ieeexplore.ieee.org/document/9895320</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep Convolution Neural Networks (CNNs) can easily be fooled by subtle, imperceptible changes to the input images. To address this vulnerability, adversarial training creates perturbation patterns and includes them in the training set to robustify the model. In contrast to existing adversarial training methods that only use class-boundary information (e.g., using a cross-entropy loss), we propose ...]]></description>
        </item>
        <item>
            <title><![CDATA[Stereo Confidence Estimation via Locally Adaptive Fusion and Knowledge Distillation]]></title>
            <link>https://ieeexplore.ieee.org/document/9894086</link>
            <guid>https://ieeexplore.ieee.org/document/9894086</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Stereo confidence estimation aims to estimate the reliability of the estimated disparity by stereo matching. Different from the previous methods that exploit the limited input modality, we present a novel method that estimates confidence map of an initial disparity by making full use of tri-modal input, including matching cost, disparity, and color image through deep networks. The proposed network...]]></description>
        </item>
        <item>
            <title><![CDATA[Efficient 3D Deep LiDAR Odometry]]></title>
            <link>https://ieeexplore.ieee.org/document/9893384</link>
            <guid>https://ieeexplore.ieee.org/document/9893384</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[An efficient 3D point cloud learning architecture, named EfficientLO-Net, for LiDAR odometry is first proposed in this article. In this architecture, the projection-aware representation of the 3D point cloud is proposed to organize the raw 3D point cloud into an ordered data form to achieve efficiency. The Pyramid, Warping, and Cost volume (PWC) structure for the LiDAR odometry task is built to es...]]></description>
        </item>
        <item>
            <title><![CDATA[PrintsGAN: Synthetic Fingerprint Generator]]></title>
            <link>https://ieeexplore.ieee.org/document/9893541</link>
            <guid>https://ieeexplore.ieee.org/document/9893541</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[A major impediment to researchers working in the area of fingerprint recognition is the lack of publicly available, large-scale, fingerprint datasets. The publicly available datasets that do exist contain very few identities and impressions per finger. This limits research on a number of topics, including e.g., using deep networks to learn fixed length fingerprint embeddings. Therefore, we propose...]]></description>
        </item>
        <item>
            <title><![CDATA[Transitional Learning: Exploring the Transition States of Degradation for Blind Super-resolution]]></title>
            <link>https://ieeexplore.ieee.org/document/9893392</link>
            <guid>https://ieeexplore.ieee.org/document/9893392</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Being extremely dependent on iterative estimation of the degradation prior or optimization of the model from scratch, the existing blind super-resolution (SR) methods are generally time-consuming and less effective, as the estimation of degradation proceeds from a blind initialization and lacks interpretable representation of degradations. To address it, this article proposes a transitional learni...]]></description>
        </item>
        <item>
            <title><![CDATA[A Progressive Hierarchical Alternating Least Squares Method for Symmetric Nonnegative Matrix Factorization]]></title>
            <link>https://ieeexplore.ieee.org/document/9891776</link>
            <guid>https://ieeexplore.ieee.org/document/9891776</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In this article, we study the symmetric nonnegative matrix factorization (SNMF) which is a powerful tool in data mining for dimension reduction and clustering. The main contributions of the present work include: (i) a new descent direction for the rank-one SNMF is derived and a strategy for choosing the step size along this descent direction is established; (ii) a progressive hierarchical alternat...]]></description>
        </item>
        <item>
            <title><![CDATA[Class-Incremental Continual Learning Into the eXtended DER-Verse]]></title>
            <link>https://ieeexplore.ieee.org/document/9891836</link>
            <guid>https://ieeexplore.ieee.org/document/9891836</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The staple of human intelligence is the capability of acquiring knowledge in a continuous fashion. In stark contrast, Deep Networks forget catastrophically and, for this reason, the sub-field of Class-Incremental Continual Learning fosters methods that learn a sequence of tasks incrementally, blending sequentially-gained knowledge into a comprehensive prediction. This work aims at assessing and ov...]]></description>
        </item>
        <item>
            <title><![CDATA[Deep Discriminative Feature Models (DDFMs) for Set Based Face Recognition and Distance Metric Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9888005</link>
            <guid>https://ieeexplore.ieee.org/document/9888005</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[This article introduces two methods that find compact deep feature models for approximating images in set based face recognition problems. The proposed method treats each image set as a nonlinear face manifold that is composed of linear components. To find linear components of the face manifold, we first split image sets into subsets containing face images which share similar appearances. Then, ou...]]></description>
        </item>
        <item>
            <title><![CDATA[MCIBI++: Soft Mining Contextual Information Beyond Image for Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9888041</link>
            <guid>https://ieeexplore.ieee.org/document/9888041</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Co-occurrent visual pattern makes context aggregation become an essential paradigm for semantic segmentation. The existing studies focus on modeling the contexts within image while neglecting the valuable semantics of the corresponding category beyond image. To this end, we propose a novel soft mining contextual information beyond image paradigm named MCIBI++ to further boost the pixel-level repre...]]></description>
        </item>
        <item>
            <title><![CDATA[Searching a High Performance Feature Extractor for Text Recognition Network]]></title>
            <link>https://ieeexplore.ieee.org/document/9887897</link>
            <guid>https://ieeexplore.ieee.org/document/9887897</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Feature extractor plays a critical role in text recognition (TR), but customizing its architecture is relatively less explored due to expensive manual tweaking. In this article, inspired by the success of neural architecture search (NAS), we propose to search for suitable feature extractors. We design a domain-specific search space by exploring principles for having good feature extractors. The sp...]]></description>
        </item>
        <item>
            <title><![CDATA[VOLO: Vision Outlooker for Visual Recognition]]></title>
            <link>https://ieeexplore.ieee.org/document/9888055</link>
            <guid>https://ieeexplore.ieee.org/document/9888055</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Recently, Vision Transformers (ViTs) have been broadly explored in visual recognition. With low efficiency in encoding fine-level features, the performance of ViTs is still inferior to the state-of-the-art CNNs when trained from scratch on a midsize dataset like ImageNet. Through experimental analysis, we find it is because of two reasons: 1) the simple tokenization of input images fails to model ...]]></description>
        </item>
        <item>
            <title><![CDATA[A Principled Design of Image Representation: Towards Forensic Tasks]]></title>
            <link>https://ieeexplore.ieee.org/document/9881995</link>
            <guid>https://ieeexplore.ieee.org/document/9881995</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Image forensics is a rising topic as the trustworthy multimedia content is critical for modern society. Like other vision-related applications, forensic analysis relies heavily on the proper image representation. Despite the importance, current theoretical understanding for such representation remains limited, with varying degrees of neglect for its key role. For this gap, we attempt to investigat...]]></description>
        </item>
        <item>
            <title><![CDATA[Regularized Multi-Output Gaussian Convolution Process With Domain Adaptation]]></title>
            <link>https://ieeexplore.ieee.org/document/9881867</link>
            <guid>https://ieeexplore.ieee.org/document/9881867</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multi-output Gaussian process (MGP) has been attracting increasing attention as a transfer learning method to model multiple outputs. Despite its high flexibility and generality, MGP still faces two critical challenges when applied to transfer learning. The first one is negative transfer, which occurs when there exists no shared information among the outputs. The second challenge is the input doma...]]></description>
        </item>
        <item>
            <title><![CDATA[Learning to Discriminate Information for Online Action Detection: Analysis and Application]]></title>
            <link>https://ieeexplore.ieee.org/document/9881239</link>
            <guid>https://ieeexplore.ieee.org/document/9881239</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Online action detection, which aims to identify an ongoing action from a streaming video, is an important subject in real-world applications. For this task, previous methods use recurrent neural networks for modeling temporal relations in an input sequence. However, these methods overlook the fact that the input image sequence includes not only the action of interest but background and irrelevant ...]]></description>
        </item>
        <item>
            <title><![CDATA[On the Convergence of Tsetlin Machines for the XOR Operator]]></title>
            <link>https://ieeexplore.ieee.org/document/9881240</link>
            <guid>https://ieeexplore.ieee.org/document/9881240</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[The Tsetlin Machine (TM) is a novel machine learning algorithm with several distinct properties, including transparent inference and learning using hardware-near building blocks. Although numerous papers explore the TM empirically, many of its properties have not yet been analyzed mathematically. In this article, we analyze the convergence of the TM when input is non-linearly related to output by ...]]></description>
        </item>
        <item>
            <title><![CDATA[Robust Point Cloud Registration Framework Based on Deep Graph Matching]]></title>
            <link>https://ieeexplore.ieee.org/document/9878213</link>
            <guid>https://ieeexplore.ieee.org/document/9878213</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[3D point cloud registration is a fundamental problem in computer vision and robotics. Recently, learning-based point cloud registration methods have made great progress. However, these methods are sensitive to outliers, which lead to more incorrect correspondences. In this paper, we propose a novel deep graph matching-based framework for point cloud registration. Specifically, we first transform p...]]></description>
        </item>
        <item>
            <title><![CDATA[Exact Decomposition of Joint Low Rankness and Local Smoothness Plus Sparse Matrices]]></title>
            <link>https://ieeexplore.ieee.org/document/9875963</link>
            <guid>https://ieeexplore.ieee.org/document/9875963</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[It is known that the decomposition in low-rank and sparse matrices (L+S for short) can be achieved by several Robust PCA techniques. Besides the low rankness, the local smoothness (LSS) is a vitally essential prior for many real-world matrix data such as hyperspectral images and surveillance videos, which makes such matrices have low-rankness and local smoothness property at the same time. This po...]]></description>
        </item>
        <item>
            <title><![CDATA[Explainability in Graph Neural Networks: A Taxonomic Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9875989</link>
            <guid>https://ieeexplore.ieee.org/document/9875989</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Deep learning methods are achieving ever-increasing performance on many artificial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved si...]]></description>
        </item>
        <item>
            <title><![CDATA[Untrained Neural Network Priors for Inverse Imaging Problems: A Survey]]></title>
            <link>https://ieeexplore.ieee.org/document/9878048</link>
            <guid>https://ieeexplore.ieee.org/document/9878048</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In recent years, advancements in machine learning (ML) techniques, in particular, deep learning (DL) methods have gained a lot of momentum in solving inverse imaging problems, often surpassing the performance provided by hand-crafted approaches. Traditionally, analytical methods have been used to solve inverse imaging problems such as image restoration, inpainting, and superresolution. Unlike anal...]]></description>
        </item>
        <item>
            <title><![CDATA[Semi-Supervised Hierarchical Graph Classification]]></title>
            <link>https://ieeexplore.ieee.org/document/9875050</link>
            <guid>https://ieeexplore.ieee.org/document/9875050</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Node classification and graph classification are two graph learning problems that predict the class label of a node and the class label of a graph respectively. A node of a graph usually represents a real-world entity, e.g., a user in a social network, or a document in a document citation network. In this work, we consider a more challenging but practically useful setting, in which a node itself i...]]></description>
        </item>
        <item>
            <title><![CDATA[Variational Label Enhancement]]></title>
            <link>https://ieeexplore.ieee.org/document/9875104</link>
            <guid>https://ieeexplore.ieee.org/document/9875104</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Multi-label learning focuses on the ambiguity at the label side, i.e., one instance is associated with multiple class labels, where the logical labels are always adopted to partition class labels into relevant labels and irrelevant labels rigidly. However, the relevance or irrelevance of each label corresponding to one instance is essentially relative in real-world tasks and the label distribution...]]></description>
        </item>
        <item>
            <title><![CDATA[BiFuse++: Self-Supervised and Efficient Bi-Projection Fusion for 360° Depth Estimation]]></title>
            <link>https://ieeexplore.ieee.org/document/9874253</link>
            <guid>https://ieeexplore.ieee.org/document/9874253</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Due to the rise of spherical cameras, monocular 360$^\circ$∘ depth estimation becomes an important technique for many applications (e.g., autonomous systems). Thus, state-of-the-art frameworks for monocular 360$^\circ$∘ depth estimation such as bi-projection fusion in BiFuse are proposed. To train such a framework, a large number of panoramas along with the corresponding depth ground truths captur...]]></description>
        </item>
        <item>
            <title><![CDATA[Memory-Based Cross-Image Contexts for Weakly Supervised Semantic Segmentation]]></title>
            <link>https://ieeexplore.ieee.org/document/9873854</link>
            <guid>https://ieeexplore.ieee.org/document/9873854</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Weakly supervised semantic segmentation (WSSS) trains segmentation models by only weak labels, aiming to save the burden of expensive pixel-level annotations. This paper tackles the WSSS problem of utilizing image-level labels as the weak supervision. Previous approaches address this problem by focusing on generating better pseudo-masks from weak labels to train the segmentation model. However, th...]]></description>
        </item>
        <item>
            <title><![CDATA[Contrastive Learning With Stronger Augmentations]]></title>
            <link>https://ieeexplore.ieee.org/document/9873966</link>
            <guid>https://ieeexplore.ieee.org/document/9873966</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Representation learning has significantly been developed with the advance of contrastive learning methods. Most of those methods are benefited from various data augmentations that are carefully designated to maintain their identities so that the images transformed from the same instance can still be retrieved. However, those carefully designed transformations limited us to further explore the nove...]]></description>
        </item>
        <item>
            <title><![CDATA[Parameterized Hamiltonian Learning With Quantum Circuit]]></title>
            <link>https://ieeexplore.ieee.org/document/9872139</link>
            <guid>https://ieeexplore.ieee.org/document/9872139</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Hamiltonian learning, as an important quantum machine learning technique, provides a significant approach for determining an accurate quantum system. This paper establishes parameterized Hamiltonian learning (PHL) and explores its application and implementation on quantum computers. A parameterized quantum circuit for Hamiltonian learning is first created by decomposing unitary operators to excite...]]></description>
        </item>
        <item>
            <title><![CDATA[Blind Image Super-Resolution: A Survey and Beyond]]></title>
            <link>https://ieeexplore.ieee.org/document/9870558</link>
            <guid>https://ieeexplore.ieee.org/document/9870558</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Blind image super-resolution (SR), aiming to super-resolve low-resolution images with unknown degradation, has attracted increasing attention due to its significance in promoting real-world applications. Many novel and effective solutions have been proposed recently, especially with powerful deep learning techniques. Despite years of efforts, it still remains as a challenging research problem. Thi...]]></description>
        </item>
        <item>
            <title><![CDATA[Reformulating Optical Flow to Solve Image-Based Inverse Problems and Quantify Uncertainty]]></title>
            <link>https://ieeexplore.ieee.org/document/9870569</link>
            <guid>https://ieeexplore.ieee.org/document/9870569</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[From meteorology to medical imaging and cell mechanics, many scientific domains use inverse problems (IPs) to extract physical measurements from image movement. To this end, motion estimation methods such as optical flow (OF) pre-process images into motion data to feed the IP, which then inverts for the measurements through a physical model. However, this combined OFIP pipeline exacerbates the ill...]]></description>
        </item>
        <item>
            <title><![CDATA[Robust Online Tracking With Meta-Updater]]></title>
            <link>https://ieeexplore.ieee.org/document/9870567</link>
            <guid>https://ieeexplore.ieee.org/document/9870567</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[In a sequence, the appearance of both the target and background often changes dramatically. Offline-trained models may not handle huge appearance variations well, causing tracking failures. Most discriminative trackers address this issue by introducing an online update scheme, making the model dynamically adapt the changes of the target and background. Although the online update scheme plays an im...]]></description>
        </item>
        <item>
            <title><![CDATA[Kernel-Based Generalized Median Computation for Consensus Learning]]></title>
            <link>https://ieeexplore.ieee.org/document/9869722</link>
            <guid>https://ieeexplore.ieee.org/document/9869722</guid>
            <pubDate>Thu, 27 Apr 2023 04:15:42 GMT</pubDate>
            <description><![CDATA[Computing a consensus object from a set of given objects is a core problem in machine learning and pattern recognition. One popular approach is to formulate it as an optimization problem using the generalized median. Previous methods like the Prototype and Distance-Preserving Embedding methods transform objects into a vector space, solve the generalized median problem in this space, and inversely ...]]></description>
        </item>
    </channel>
</rss>